{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\r\n",
    "import json\r\n",
    "import argparse\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_io as tfio\r\n",
    "from collections import Counter\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\r\n",
    "\r\n",
    "from tensorflow.keras import Model, Sequential\r\n",
    "from tensorflow.keras.layers import (\r\n",
    "    LSTM, Bidirectional, Dense, Embedding)\r\n",
    "\r\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\r\n",
    "\r\n",
    "d = pd.read_csv(\"Datasets\\TIMIT-dataset\\data.csv\")\r\n",
    "d"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SA1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SA2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI1573_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI1573_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI2203.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX172.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6858</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX262.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6859</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX352.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6860</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX442.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX82.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6862 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              wav_paths\n",
       "0         Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SA1.wav\n",
       "1         Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SA2.wav\n",
       "2     Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI1573_1...\n",
       "3     Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI1573_2...\n",
       "4      Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI2203.wav\n",
       "...                                                 ...\n",
       "6857    Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX172.wav\n",
       "6858    Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX262.wav\n",
       "6859    Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX352.wav\n",
       "6860    Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX442.wav\n",
       "6861     Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX82.wav\n",
       "\n",
       "[6862 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def ArgParser():\r\n",
    "    parser = argparse.ArgumentParser()\r\n",
    "    \r\n",
    "    parser.add_argument(\"--n_splits\", dest=\"n_splits\", type=int, default=5)\r\n",
    "    parser.add_argument(\"--sample_rate\", dest=\"sample_rate\", type=int, default=16000)\r\n",
    "    parser.add_argument(\"--n_fft\", dest=\"n_fft\", type=int, default=2048)\r\n",
    "    parser.add_argument(\"--window_size\", dest=\"window_size\", type=int, default=400)\r\n",
    "    parser.add_argument(\"--hop_length\", dest=\"hop_length\", type=int, default=160) # 160 samples = 10ms\r\n",
    "    parser.add_argument(\"--n_mels\", dest=\"n_mels\", type=int, default=64)\r\n",
    "    parser.add_argument(\"--max_samples\", dest=\"max_samples\", type=int, default=70000)\r\n",
    "    \r\n",
    "    args = parser.parse_known_args()[0]\r\n",
    "    seq_len = int(np.ceil(args.max_samples / args.hop_length))\r\n",
    "    parser.add_argument(\"--seq_len\", type=int, default=seq_len)\r\n",
    "    return parser.parse_known_args()[0]\r\n",
    "\r\n",
    "args = ArgParser()\r\n",
    "args"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Namespace(hop_length=160, max_samples=70000, n_fft=2048, n_mels=64, n_splits=5, sample_rate=16000, seq_len=438, window_size=400)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class TFRWriter():\r\n",
    "    def __init__(self, args):\r\n",
    "        self.samples = d['wav_paths'].tolist()\r\n",
    "        self.args = args\r\n",
    "        self.fmin = 0\r\n",
    "        self.fmax = 8000\r\n",
    "        self.top_db = 80\r\n",
    "        self.dict_path = \"Datasets\\TIMIT-dataset\\phoneme_dict.json\"\r\n",
    "        self.phoneme_dict = self.get_dict()\r\n",
    "\r\n",
    "\r\n",
    "    def _bytes_feature(self, value):\r\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n",
    "        if isinstance(value, type(tf.constant(0))):\r\n",
    "            value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\r\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n",
    "\r\n",
    "\r\n",
    "    def serialize_example(self, *args):\r\n",
    "        feature = {\r\n",
    "            'audio': self._bytes_feature(args[0]),\r\n",
    "            'phonemes': self._bytes_feature(args[1]),\r\n",
    "            'frames': self._bytes_feature(args[2]),\r\n",
    "            'filename': self._bytes_feature(args[3])}\r\n",
    "\r\n",
    "        example_proto = tf.train.Example(\r\n",
    "            features=tf.train.Features(feature=feature))\r\n",
    "        return example_proto.SerializeToString()\r\n",
    "\r\n",
    "\r\n",
    "    def get_shards(self):\r\n",
    "        speaker_id = [sample.split('\\\\')[4] for sample in self.samples]\r\n",
    "        skf = StratifiedKFold(\r\n",
    "            n_splits=self.args.n_splits, shuffle=True, random_state=42)\r\n",
    "        return [\r\n",
    "            list(map(lambda x: self.samples[x], j)) \r\n",
    "            for i, j in skf.split(self.samples, speaker_id)]\r\n",
    "\r\n",
    "\r\n",
    "    def get_dict(self):\r\n",
    "        phonemes = set()\r\n",
    "        for sample in self.samples:\r\n",
    "            base_path = os.path.splitext(sample)[0]\r\n",
    "            with open(base_path + '.phn', \"r\") as f:\r\n",
    "                for line in f.readlines():\r\n",
    "                    phonemes.add(line.split()[-1])\r\n",
    "        phonemes = sorted(Counter(phonemes), key=Counter(phonemes).get, reverse=True)\r\n",
    "        phonemes_dict = {v: i for i, v in enumerate(phonemes)}\r\n",
    "        with open(self.dict_path, \"w\") as f:\r\n",
    "            json.dump(phonemes_dict, f, sort_keys=False, indent=4)\r\n",
    "        return phonemes_dict\r\n",
    "   \r\n",
    "    \r\n",
    "    def get_shard_data(self, samples, shard):\r\n",
    "        for sample in tqdm(\r\n",
    "                samples, total=len(samples), desc=f\"Writing shard {shard}\"):\r\n",
    "            base_path = os.path.splitext(sample)[0]\r\n",
    "            p_frames, phonemes = [0], []\r\n",
    "            with open(base_path + \".phn\") as f:\r\n",
    "                for line in f.readlines():\r\n",
    "                    p_frame, phoneme = line.split()[1::]\r\n",
    "                    p_frames.append(int(p_frame) // self.args.hop_length)\r\n",
    "                    phonemes.append(str(phoneme))\r\n",
    "            phonemes = list(map(self.phoneme_dict.get, phonemes))\r\n",
    "            waveform = tf.io.read_file(base_path + \".wav\")\r\n",
    "            filename = str.encode(\"/\".join(sample.split('\\\\')[-3::]))\r\n",
    "            yield {\r\n",
    "                \"audio\": waveform,\r\n",
    "                \"phonemes\": tf.io.serialize_tensor(phonemes),\r\n",
    "                \"frames\": tf.io.serialize_tensor(p_frames),\r\n",
    "                \"filename\": filename}\r\n",
    "\r\n",
    "\r\n",
    "    def write(self):\r\n",
    "        for shard, samples in enumerate(self.get_shards()):\r\n",
    "            with tf.io.TFRecordWriter(\r\n",
    "                    f\"Datasets/TIMIT-dataset/tfrec_data/train_{shard+1}.tfrec\") as f:\r\n",
    "                for sample in self.get_shard_data(samples, shard+1):\r\n",
    "                    example = self.serialize_example(\r\n",
    "                        sample['audio'], sample['phonemes'], \r\n",
    "                        sample['frames'], sample['filename'])\r\n",
    "                    f.write(example)\r\n",
    "\r\n",
    "# TFRWriter(args).write()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "class TIMITDataset():\r\n",
    "    def __init__(self, args):\r\n",
    "        self.files = [os.path.join(args.main_dir, f) for f in os.listdir(args.main_dir)]\r\n",
    "        self.AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
    "        self.args = args\r\n",
    "        self.train_files, self.test_files = train_test_split(\r\n",
    "            self.files, test_size=args.test_size, shuffle=True)\r\n",
    "\r\n",
    "    def decode_audio(self, audio):\r\n",
    "        audio = tf.audio.decode_wav(audio)[0]\r\n",
    "        return tf.squeeze(audio, axis=-1)\r\n",
    "\r\n",
    "    def read_tfrecord(self, example):\r\n",
    "        feature_description = {\r\n",
    "            'spectrogram': tf.io.FixedLenFeature([], tf.string),\r\n",
    "            'framewise_label': tf.io.FixedLenFeature([], tf.string),\r\n",
    "            'binary_label': tf.io.FixedLenFeature([], tf.string),\r\n",
    "            'filename': tf.io.FixedLenFeature([], tf.string)}\r\n",
    "        \r\n",
    "        example = tf.io.parse_single_example(example, feature_description)\r\n",
    "        example['spectrogram'] = tf.io.parse_tensor(\r\n",
    "            example['spectrogram'], out_type=tf.float32)\r\n",
    "        example['framewise_label'] = tf.io.parse_tensor(\r\n",
    "            example['framewise_label'], out_type=tf.int32)\r\n",
    "        example['binary_label'] = tf.io.parse_tensor(\r\n",
    "            example['binary_label'], out_type=tf.int32)\r\n",
    "        return example\r\n",
    "\r\n",
    "\r\n",
    "    def load_dataset(self, files):\r\n",
    "        ignore_order = tf.data.Options()\r\n",
    "        ignore_order.experimental_deterministic = False\r\n",
    "        dataset = tf.data.TFRecordDataset(files)\r\n",
    "        dataset = dataset.with_options(ignore_order)\r\n",
    "        dataset = dataset.map(self.read_tfrecord, num_parallel_calls=self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "\r\n",
    "\r\n",
    "    def SpecAugment(self, sample):\r\n",
    "        spectrogram = sample['spectrogram']\r\n",
    "        spectrogram = tfio.audio.freq_mask(spectrogram, param=10)\r\n",
    "        spectrogram = tfio.audio.time_mask(spectrogram, param=10)\r\n",
    "        sample['spectrogram'] = spectrogram\r\n",
    "        return sample\r\n",
    "\r\n",
    "\r\n",
    "    def train(self):\r\n",
    "        dataset = self.load_dataset(self.train_files)\r\n",
    "        dataset = dataset.map(self.SpecAugment, num_parallel_calls=self.AUTOTUNE)\r\n",
    "        dataset = dataset.repeat()\r\n",
    "        dataset = dataset.shuffle(self.args.buffer_size)\r\n",
    "        dataset = dataset.batch(self.args.batch_size)\r\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "\r\n",
    "\r\n",
    "    def test(self):\r\n",
    "        dataset = self.load_dataset(self.test_files)\r\n",
    "        dataset = dataset.shuffle(self.args.buffer_size)\r\n",
    "        dataset = dataset.batch(self.args.batch_size)\r\n",
    "        dataset = dataset.cache()\r\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "\r\n",
    "dataset = TIMITDataset(args).train()\r\n",
    "binary_label, filename, framewise_label, spectrogram = list(next(iter(dataset)).values())\r\n",
    "\r\n",
    "print(\"spectrogram shape:\", spectrogram.shape)\r\n",
    "print(\"binary_label shape:\", binary_label.shape)\r\n",
    "print(\"framewise_label shape:\", framewise_label.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "spectrogram shape: (2, 438, 64)\n",
      "binary_label shape: (2, 438)\n",
      "framewise_label shape: (2, 438)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "model = Sequential([\r\n",
    "    \r\n",
    "    Bidirectional(LSTM(100, return_sequences=True), input_shape=[438, 64], name=\"layer_1\"),\r\n",
    "    Bidirectional(LSTM(25), name=\"layer_2\"),\r\n",
    "    Dense(2, activation=\"softmax\", name='layer_3')])\r\n",
    "\r\n",
    "model.compile(optimizer='adam')\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_1 (Bidirectional)      (None, 438, 200)          132000    \n",
      "_________________________________________________________________\n",
      "layer_2 (Bidirectional)      (None, 50)                45200     \n",
      "_________________________________________________________________\n",
      "layer_3 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 177,302\n",
      "Trainable params: 177,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('tf-gpu': conda)"
  },
  "interpreter": {
   "hash": "b851d2923cfa3a2562599062e05fd9893d86a7c009c64d8ad3756552e4dd5f41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}