{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import glob\r\n",
    "import json\r\n",
    "import subprocess\r\n",
    "import soundfile as sf\r\n",
    "import argparse\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import librosa\r\n",
    "import scipy.io.wavfile\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from collections import Counter\r\n",
    "from functools import partial\r\n",
    "\r\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_io as tfio\r\n",
    "\r\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\r\n",
    "\r\n",
    "main_dir = r\"Datasets\\TIMIT-dataset\\data\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# wav_paths = [path for path in glob.glob(main_dir + \"/*/*/*.wav\") \r\n",
    "#     if not (path.endswith(\"_1.wav\") or path.endswith(\"_2.wav\"))]\r\n",
    "# frames = [len(librosa.load(wav_path, sr=16000)[0]) for wav_path in tqdm(wav_paths)]\r\n",
    "# print(\"Max frames:\", np.max(frames))\r\n",
    "\r\n",
    "# plt.figure(figsize=(10,4))\r\n",
    "# sns.histplot(data=frames)\r\n",
    "# plt.axvline(x=np.mean(frames), color='red')\r\n",
    "# plt.xlabel(\"Number of frames per sample\")\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# cutoff_limit = 70000\r\n",
    "# outlier, split_files, frames = [], [], []\r\n",
    "# for wav_path in tqdm(wav_paths, desc='Split'):\r\n",
    "#     y = librosa.load(wav_path, sr=16000)[0]\r\n",
    "#     n_frames = len(y)\r\n",
    "#     frames.append(n_frames)\r\n",
    "#     if n_frames >= cutoff_limit:\r\n",
    "#         phn_path = wav_path.replace(\"wav\", \"phn\")\r\n",
    "#         lines = open(phn_path, \"r\").readlines()\r\n",
    "#         end = np.array([int(line.split()[1]) for line in lines])\r\n",
    "#         try: \r\n",
    "#             idx = np.where(end < n_frames//2)[0][-1]\r\n",
    "#             lines_1 = lines[:idx]\r\n",
    "#             lines_2 = lines[idx:]\r\n",
    "#             factor = int(lines_2[0].split()[0])\r\n",
    "#             for i, line in enumerate(lines_2):\r\n",
    "#                 start, end, phoneme = line.split()\r\n",
    "#                 start = int(start) - factor\r\n",
    "#                 end = int(end) - factor\r\n",
    "#                 line = \" \".join([str(start), str(end), phoneme + \"\\n\"])\r\n",
    "#                 lines_2[i] = line\r\n",
    "#             f1_path = os.path.splitext(phn_path)[0] + \"_1.phn\"\r\n",
    "#             f2_path = os.path.splitext(phn_path)[0] + \"_2.phn\"\r\n",
    "#             for path, lines in zip([f1_path, f2_path], [lines_1, lines_2]):\r\n",
    "#                 with open(path, \"w\") as f:\r\n",
    "#                     f.writelines(lines)    \r\n",
    "#             sf.write(f1_path.replace(\"phn\", \"wav\"), y[:factor], 16000)\r\n",
    "#             sf.write(f2_path.replace(\"phn\", \"wav\"), y[factor:], 16000)\r\n",
    "#             split_files.append(wav_path)\r\n",
    "#         except:\r\n",
    "#             outlier.append(wav_path)\r\n",
    "#             pass\r\n",
    "\r\n",
    "# print(\"Outliers:\\n\", outlier)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# wav_paths = glob.glob(main_dir + \"/*/*/*.wav\")\r\n",
    "# wav_paths = [path for path in wav_paths if not path in (split_files + outlier)]\r\n",
    "# frames = []\r\n",
    "# for wav_path in wav_paths:\r\n",
    "#     y = librosa.load(wav_path, sr=16000)[0]\r\n",
    "#     n_frames = len(y)\r\n",
    "#     frames.append(n_frames)\r\n",
    "\r\n",
    "# plt.figure(figsize=(10,4))\r\n",
    "# sns.histplot(data=frames)\r\n",
    "# plt.axvline(x=np.mean(frames), color='red')\r\n",
    "# plt.xlabel(\"Number of frames per sample\")\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Padding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# wav_paths = glob.glob(main_dir + \"/*/*/*.wav\")\r\n",
    "# wav_paths = [path for path in wav_paths \r\n",
    "#     if not path in (split_files + outlier)]\r\n",
    "    \r\n",
    "# for wav_path in tqdm(wav_paths, desc='Padding'):\r\n",
    "#     y = librosa.load(wav_path, sr=16000)[0]\r\n",
    "#     n_frames = len(y)\r\n",
    "#     y_sil = np.array([])\r\n",
    "#     if n_frames != cutoff_limit:\r\n",
    "#         pad_length = cutoff_limit - n_frames\r\n",
    "\r\n",
    "#         with open(wav_path.replace(\"wav\", \"phn\"), \"r\") as f:\r\n",
    "#             lines = f.readlines()\r\n",
    "#         phonemes = np.array([line.split()[-1] for line in lines])\r\n",
    "#         for i in np.where(phonemes == \"h#\")[0]:\r\n",
    "#             start_sil, end_sil = list(map(int, lines[i].split()[:-1]))\r\n",
    "#             y_sil = np.concatenate([y_sil, y[start_sil:end_sil]])\r\n",
    "        \r\n",
    "#         if len(y_sil) >= pad_length:\r\n",
    "#             y_sil = y_sil[:pad_length]\r\n",
    "#         else:\r\n",
    "#             extension = pad_length - len(y_sil)\r\n",
    "#             y_sil = np.pad(y_sil, (0, extension), mode='wrap')\r\n",
    "        \r\n",
    "#         np.random.shuffle(y_sil)\r\n",
    "#         y = np.concatenate([y, y_sil])\r\n",
    "        \r\n",
    "#         start, end, phoneme = lines.pop(-1).split()\r\n",
    "#         if lines[-1].split()[-1] == \"h#\":\r\n",
    "#             line = \" \".join([end, str(cutoff_limit), phoneme])\r\n",
    "#         else:\r\n",
    "#             line = \" \".join([start, str(cutoff_limit), \"h#\\n\"])\r\n",
    "#         lines.append(line)\r\n",
    "\r\n",
    "#         with open(wav_path.replace(\"wav\", \"phn\"), \"w\") as f:\r\n",
    "#             f.writelines(lines)\r\n",
    "\r\n",
    "#         sf.write(wav_path, y, 16000)\r\n",
    "\r\n",
    "#     else:\r\n",
    "#         pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "d = pd.read_csv(\"Datasets\\TIMIT-dataset\\data.csv\")\r\n",
    "d"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SA1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SA2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI1573_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI1573_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI2203.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX172.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6858</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX262.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6859</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX352.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6860</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX442.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861</th>\n",
       "      <td>Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX82.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6862 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              wav_paths\n",
       "0         Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SA1.wav\n",
       "1         Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SA2.wav\n",
       "2     Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI1573_1...\n",
       "3     Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI1573_2...\n",
       "4      Datasets\\TIMIT-dataset\\data\\DR1\\FAKS0\\SI2203.wav\n",
       "...                                                 ...\n",
       "6857    Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX172.wav\n",
       "6858    Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX262.wav\n",
       "6859    Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX352.wav\n",
       "6860    Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX442.wav\n",
       "6861     Datasets\\TIMIT-dataset\\data\\DR8\\MTCS0\\SX82.wav\n",
       "\n",
       "[6862 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TFrecords\r\n",
    "\r\n",
    "## Write"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "def ArgParser():\r\n",
    "    parser = argparse.ArgumentParser()\r\n",
    "    \r\n",
    "    parser.add_argument(\"--n_splits\", dest=\"n_splits\", type=int, default=5)\r\n",
    "    parser.add_argument(\"--sample_rate\", dest=\"sample_rate\", type=int, default=16000)\r\n",
    "    parser.add_argument(\"--n_fft\", dest=\"n_fft\", type=int, default=2048)\r\n",
    "    parser.add_argument(\"--window_size\", dest=\"window_size\", type=int, default=400)\r\n",
    "    parser.add_argument(\"--hop_length\", dest=\"hop_length\", type=int, default=160) # 160 samples = 10ms\r\n",
    "    parser.add_argument(\"--n_mels\", dest=\"n_mels\", type=int, default=64)\r\n",
    "    parser.add_argument(\"--max_samples\", dest=\"max_samples\", type=int, default=70000)\r\n",
    "    parser.add_argument(\"--main_dir\", dest='main_dir', type=str, default=\"Datasets/TIMIT-dataset/tfrec_data\")\r\n",
    "\r\n",
    "    \r\n",
    "    args = parser.parse_known_args()[0]\r\n",
    "    seq_len = int(np.ceil(args.max_samples / args.hop_length))\r\n",
    "    parser.add_argument(\"--seq_len\", type=int, default=seq_len)\r\n",
    "    return parser.parse_known_args()[0]\r\n",
    "\r\n",
    "args = ArgParser()\r\n",
    "args"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Namespace(hop_length=160, main_dir='Datasets/TIMIT-dataset/tfrec_data', max_samples=70000, n_fft=2048, n_mels=64, n_splits=5, sample_rate=16000, seq_len=438, window_size=400)"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "class TFRWriter():\r\n",
    "    def __init__(self, args):\r\n",
    "        self.samples = d['wav_paths'].tolist()\r\n",
    "        self.args = args\r\n",
    "        self.fmin = 0\r\n",
    "        self.fmax = 8000\r\n",
    "        self.top_db = 80\r\n",
    "        self.dict_path = \"Datasets\\TIMIT-dataset\\phoneme_dict.json\"\r\n",
    "        self.phoneme_dict = self.get_dict()\r\n",
    "\r\n",
    "\r\n",
    "    def _bytes_feature(self, value):\r\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n",
    "        if isinstance(value, type(tf.constant(0))):\r\n",
    "            value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\r\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n",
    "\r\n",
    "\r\n",
    "    def serialize_example(self, *args):\r\n",
    "        feature = {\r\n",
    "            'audio': self._bytes_feature(args[0]),\r\n",
    "            'phonemes': self._bytes_feature(args[1]),\r\n",
    "            'frames': self._bytes_feature(args[2]),\r\n",
    "            'filename': self._bytes_feature(args[3])}\r\n",
    "\r\n",
    "        example_proto = tf.train.Example(\r\n",
    "            features=tf.train.Features(feature=feature))\r\n",
    "        return example_proto.SerializeToString()\r\n",
    "\r\n",
    "\r\n",
    "    def get_shards(self):\r\n",
    "        speaker_id = [sample.split('\\\\')[4] for sample in self.samples]\r\n",
    "        skf = StratifiedKFold(\r\n",
    "            n_splits=self.args.n_splits, shuffle=True, random_state=42)\r\n",
    "        return [\r\n",
    "            list(map(lambda x: self.samples[x], j)) \r\n",
    "            for i, j in skf.split(self.samples, speaker_id)]\r\n",
    "\r\n",
    "\r\n",
    "    def get_dict(self):\r\n",
    "        # phonemes = set()\r\n",
    "        phonemes = set()\r\n",
    "        markers = ['h#', 'pau', 'epi']\r\n",
    "        for sample in self.samples:\r\n",
    "            base_path = os.path.splitext(sample)[0]\r\n",
    "            with open(base_path + '.phn', \"r\") as f:\r\n",
    "                for line in f.readlines():\r\n",
    "                    phoneme = line.split()[-1]\r\n",
    "                    if not phoneme in markers:\r\n",
    "                        phonemes.add(phoneme)\r\n",
    "        phonemes = markers + sorted(Counter(phonemes), key=Counter(phonemes).get, reverse=True)\r\n",
    "        phonemes_dict = {v: i+1 for i, v in enumerate(phonemes)}\r\n",
    "        with open(self.dict_path, \"w\") as f:\r\n",
    "            json.dump(phonemes_dict, f, sort_keys=False, indent=4)\r\n",
    "        return phonemes_dict\r\n",
    "   \r\n",
    "    \r\n",
    "    def get_shard_data(self, samples, shard):\r\n",
    "        for sample in tqdm(\r\n",
    "                samples, total=len(samples), desc=f\"Writing shard {shard}\"):\r\n",
    "            base_path = os.path.splitext(sample)[0]\r\n",
    "            p_frames, phonemes = [0], []\r\n",
    "            with open(base_path + \".phn\") as f:\r\n",
    "                for line in f.readlines():\r\n",
    "                    p_frame, phoneme = line.split()[1::]\r\n",
    "                    p_frames.append(int(p_frame) // self.args.hop_length)\r\n",
    "                    phonemes.append(str(phoneme))\r\n",
    "            phonemes = list(map(self.phoneme_dict.get, phonemes))\r\n",
    "            waveform = tf.io.read_file(base_path + \".wav\")\r\n",
    "            filename = str.encode(\"/\".join(sample.split('\\\\')[-3::]))\r\n",
    "            yield {\r\n",
    "                \"audio\": waveform,\r\n",
    "                \"phonemes\": tf.io.serialize_tensor(phonemes),\r\n",
    "                \"frames\": tf.io.serialize_tensor(p_frames),\r\n",
    "                \"filename\": filename}\r\n",
    "\r\n",
    "\r\n",
    "    def write(self):\r\n",
    "        for shard, samples in enumerate(self.get_shards()):\r\n",
    "            with tf.io.TFRecordWriter(\r\n",
    "                    f\"Datasets/TIMIT-dataset/tfrec_data/train_{shard+1}.tfrec\") as f:\r\n",
    "                for sample in self.get_shard_data(samples, shard+1):\r\n",
    "                    example = self.serialize_example(\r\n",
    "                        sample['audio'], sample['phonemes'], \r\n",
    "                        sample['frames'], sample['filename'])\r\n",
    "                    f.write(example)\r\n",
    "\r\n",
    "TFRWriter(args).write()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "625aa4e3c7e44743a5c5c495ab910530"
      },
      "text/plain": [
       "Writing shard 1:   0%|          | 0/1373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec4e75dc1e9047d8a0ac12a0fdfb6875"
      },
      "text/plain": [
       "Writing shard 2:   0%|          | 0/1373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93f3f3796e9d4044b8b89e3e15acb30f"
      },
      "text/plain": [
       "Writing shard 3:   0%|          | 0/1372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50c69afc4a9a4401952b94f33995a6f4"
      },
      "text/plain": [
       "Writing shard 4:   0%|          | 0/1372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f005ab4fb90442b79244d99ba567e5c3"
      },
      "text/plain": [
       "Writing shard 5:   0%|          | 0/1372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "def decode_audio(string):\r\n",
    "    audio = tf.audio.decode_wav(string, desired_samples=args.max_samples)[0]\r\n",
    "    return tf.squeeze(audio, axis=-1)\r\n",
    "\r\n",
    "def get_spectrogram(waveform):\r\n",
    "    waveform /= 32678\r\n",
    "    spectrogram = tf.abs(tfio.audio.spectrogram(\r\n",
    "        waveform, nfft=args.n_fft, window=args.window_size, \r\n",
    "        stride=args.hop_length))\r\n",
    "    mel_spectrogram = tfio.audio.melscale(\r\n",
    "        spectrogram, rate=args.sample_rate, mels=args.n_mels, \r\n",
    "        fmin=0, fmax=8000)\r\n",
    "    mel_spectrogram = tfio.audio.dbscale(\r\n",
    "        mel_spectrogram, top_db=80)\r\n",
    "    return mel_spectrogram\r\n",
    "\r\n",
    "def get_framewise_labels(p_frames, phonemes):\r\n",
    "    labels = []\r\n",
    "    for i in range(1, len(p_frames)):\r\n",
    "        for j in range(p_frames[i-1], p_frames[i]):\r\n",
    "            labels.append(phonemes[i-1])\r\n",
    "    labels = tf.convert_to_tensor(labels)\r\n",
    "    padding = tf.zeros([args.seq_len-labels.shape[0]], dtype=tf.int32)\r\n",
    "    return tf.concat([labels, padding], axis=0)\r\n",
    "\r\n",
    "def get_binary_labels(p_frames):\r\n",
    "    labels = tf.tensor_scatter_nd_update(\r\n",
    "        tensor=tf.zeros([p_frames[-1]+1], dtype=tf.int32), \r\n",
    "        indices=tf.expand_dims(p_frames, axis=1), \r\n",
    "        updates=tf.ones([p_frames.shape[0]], dtype=tf.int32))\r\n",
    "    padding = tf.zeros([args.seq_len-labels.shape[0]], dtype=tf.int32)\r\n",
    "    return tf.concat([labels, padding], axis=0)\r\n",
    "\r\n",
    "def read_tfrecord(example):\r\n",
    "    feature_description = {\r\n",
    "        'audio': tf.io.FixedLenFeature([], tf.string),\r\n",
    "        'phonemes': tf.io.FixedLenFeature([], tf.string),\r\n",
    "        'frames': tf.io.FixedLenFeature([], tf.string),\r\n",
    "        'filename': tf.io.FixedLenFeature([], tf.string)}\r\n",
    "    \r\n",
    "    example = tf.io.parse_single_example(example, feature_description)\r\n",
    "    example['audio'] = decode_audio(example['audio'])\r\n",
    "    example['frames'] = tf.io.parse_tensor(example['frames'], out_type=tf.int32)\r\n",
    "    example['phonemes'] = tf.io.parse_tensor(example['phonemes'], out_type=tf.int32)\r\n",
    "    example['binary_labels'] = get_binary_labels(example['frames'])\r\n",
    "    example['framewise_labels'] = get_framewise_labels(example['frames'], example['phonemes'])\r\n",
    "    example['attention_mask'] = tf.constant(\r\n",
    "        [True if i < example['frames'][-1] else False for i in range(args.seq_len)])\r\n",
    "    del(example['frames'], example['phonemes'])\r\n",
    "    return example\r\n",
    "\r\n",
    "tfr_path = r\"Datasets/TIMIT-dataset/tfrec_data/train_1.tfrec\"\r\n",
    "raw_dataset = tf.data.TFRecordDataset(tfr_path)\r\n",
    "\r\n",
    "for raw_record in raw_dataset.take(1):\r\n",
    "    example = read_tfrecord(raw_record)\r\n",
    "    print(example['framewise_labels'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1 27 23 23 23 23 23 23 23 23 23 23 23  4  4\n",
      "  4  4  4 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 22 22 22 22 22 22\n",
      " 22 22 22 22  3  3  3  3  3  3  3  3 13 13 13 30 30 30 30 30 30 30 30 30\n",
      " 55 55 55 55 42 31 31 31 31 31  7  7  7  7 16 16 16 16 16 16 44 44 44 44\n",
      " 44 44 44 44 44 44 44 35 35 35 35 35 35 35 35 35 35 35 35 30 30 30 30 30\n",
      " 30 30 30 31 31 31 31 31  4  4  4  4  4  4  4 59 59 59 59 59 59 59 59 59\n",
      " 59 59 59 59 59 59 59 59 59 41 41 41 41 41 41 41 41 41 30 30 30 30 30 30\n",
      " 30 30 30 30 35 35 35 35 35 35 35 35 35 35 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 57 57 57 57 57 57 49 49 49 41 41 41 41 41 41 26 26\n",
      " 26 26 26 26 26 26 26 26  7  7  7  7  7 16 16 16 16 16 54 54 54 54 54 54\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0], shape=(438,), dtype=int32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "t = tf.zeros([5], dtype=tf.int32)\r\n",
    "t"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 0])>"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "tf.tensor_scatter_nd_add(t, [[t.shape[0]-1]], [1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 1])>"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "class TIMITDataset():\r\n",
    "    def __init__(self, args):\r\n",
    "        self.files = [os.path.join(args.main_dir, f) for f in os.listdir(args.main_dir)]\r\n",
    "        self.args = args\r\n",
    "        self.AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
    "        self.BUFFER_SIZE = 512\r\n",
    "        self.BATCH_SIZE = 16\r\n",
    "        self.train_files, self.test_files = train_test_split(\r\n",
    "            self.files, test_size=0.2, shuffle=True)\r\n",
    "\r\n",
    "    def decode_audio(self, string):\r\n",
    "        audio = tf.audio.decode_wav(string, desired_samples=args.max_samples)[0]\r\n",
    "        return tf.squeeze(audio, axis=-1)\r\n",
    "\r\n",
    "    def load_dataset(self, files):\r\n",
    "        ignore_order = tf.data.Options()\r\n",
    "        ignore_order.experimental_deterministic = False\r\n",
    "        dataset = tf.data.TFRecordDataset(files)\r\n",
    "        dataset = dataset.with_options(ignore_order)\r\n",
    "        dataset = dataset.map(self.read_tfrecord, num_parallel_calls=self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "\r\n",
    "    def get_spectrogram(self, waveform): # TODO\r\n",
    "        waveform /= 32678\r\n",
    "        spectrogram = tf.abs(tfio.audio.spectrogram(\r\n",
    "            waveform, nfft=self.args.n_fft, window=self.args.window_size, \r\n",
    "            stride=self.args.hop_length))\r\n",
    "        mel_spectrogram = tfio.audio.melscale(\r\n",
    "            spectrogram, rate=self.args.sample_rate, mels=self.args.n_mels, \r\n",
    "            fmin=0, fmax=8000)\r\n",
    "        mel_spectrogram = tfio.audio.dbscale(mel_spectrogram, top_db=80)\r\n",
    "        return mel_spectrogram\r\n",
    "\r\n",
    "    def get_binary_labels(self, p_frames): # TODO\r\n",
    "        tf.tensor_scatter_nd_add(p_frames, [[-1]], [1])\r\n",
    "        print(p_frames)\r\n",
    "\r\n",
    "        labels = tf.tensor_scatter_nd_update(\r\n",
    "            tensor=tf.zeros([p_frames[-1]+1], dtype=tf.int32), \r\n",
    "            indices=tf.expand_dims(p_frames, axis=1), \r\n",
    "            updates=tf.ones([p_frames.shape[0]], dtype=tf.int32))\r\n",
    "        padding = tf.zeros([self.args.seq_len-len(labels)], dtype=tf.int32)\r\n",
    "        return tf.concat([labels, padding], axis=0)\r\n",
    "\r\n",
    "    def get_framewise_labels(self, p_frames, phonemes): # TODO\r\n",
    "        labels = []\r\n",
    "        for i in range(1, len(p_frames)):\r\n",
    "            for j in range(p_frames[i-1], p_frames[i]):\r\n",
    "                labels.append(phonemes[i-1])\r\n",
    "        labels = tf.convert_to_tensor(labels)\r\n",
    "        print(labels)\r\n",
    "        # padding = tf.zeros([self.args.seq_len-len(labels)], dtype=tf.int32)\r\n",
    "        # return tf.concat([labels, padding], axis=0)\r\n",
    "        return\r\n",
    "\r\n",
    "    def read_tfrecord(self, example):\r\n",
    "        feature_description = {\r\n",
    "            'audio': tf.io.FixedLenFeature([], tf.string),\r\n",
    "            'phonemes': tf.io.FixedLenFeature([], tf.string),\r\n",
    "            'frames': tf.io.FixedLenFeature([], tf.string),\r\n",
    "            'filename': tf.io.FixedLenFeature([], tf.string)}\r\n",
    "        \r\n",
    "        example = tf.io.parse_single_example(example, feature_description)\r\n",
    "        example['audio'] = self.decode_audio(example['audio'])\r\n",
    "        example['frames'] = tf.io.parse_tensor(example['frames'], out_type=tf.int32)\r\n",
    "        example['phonemes'] = tf.io.parse_tensor(example['phonemes'], out_type=tf.int32)\r\n",
    "        example['binary_labels'] = self.get_binary_labels(example['frames'])\r\n",
    "        example['framewise_labels'] = self.get_framewise_labels(example['frames'], example['phonemes'])\r\n",
    "        example['attention_mask'] = tf.constant(\r\n",
    "            [True if i < example['frames'][-1] else False for i in range(self.args.seq_len)])\r\n",
    "        del(example['frames'], example['phonemes'])\r\n",
    "        return example\r\n",
    " \r\n",
    "    def SpecAugment(self, sample):\r\n",
    "        waveform = sample['audio']\r\n",
    "        spectrogram = tfio.audio.freq_mask(spectrogram, param=10)\r\n",
    "        spectrogram = tfio.audio.time_mask(spectrogram, param=10)\r\n",
    "        sample['audio'] = spectrogram\r\n",
    "        return sample\r\n",
    "\r\n",
    "\r\n",
    "    def train(self):\r\n",
    "        dataset = self.load_dataset(self.train_files)\r\n",
    "        dataset = dataset.map(self.SpecAugment, num_parallel_calls=self.AUTOTUNE)\r\n",
    "        dataset = dataset.repeat()\r\n",
    "        dataset = dataset.shuffle(self.BUFFER_SIZE)\r\n",
    "        dataset = dataset.batch(self.BATCH_SIZE)\r\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "\r\n",
    "\r\n",
    "    def test(self):\r\n",
    "        dataset = self.load_dataset(self.test_files)\r\n",
    "        dataset = dataset.shuffle(self.BUFFER_SIZE)\r\n",
    "        dataset = dataset.batch(self.BATCH_SIZE)\r\n",
    "        dataset = dataset.cache()\r\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "\r\n",
    "train = TIMITDataset(args).train()\r\n",
    "train"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor(\"ParseTensor:0\", dtype=int32)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "in user code:\n\n    <ipython-input-108-cd4347262d25>:67 read_tfrecord  *\n        example['binary_labels'] = self.get_binary_labels(example['frames'])\n    <ipython-input-108-cd4347262d25>:38 get_binary_labels  *\n        labels = tf.tensor_scatter_nd_update(\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3225 ones\n        shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163 wrapped\n        return func(*args, **kwargs)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:346 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271 constant\n        return _constant_impl(value, dtype, shape, name, verify_shape=False,\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:288 _constant_impl\n        tensor_util.make_tensor_proto(\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:457 make_tensor_proto\n        _AssertCompatible(values, dtype)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:336 _AssertCompatible\n        raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\n    TypeError: Expected int32, got None of type 'NoneType' instead.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-cd4347262d25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTIMITDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-117-cd4347262d25>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpecAugment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-117-cd4347262d25>\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(self, files)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_tfrecord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[0;32m   1861\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1863\u001b[1;33m       return ParallelMapDataset(\n\u001b[0m\u001b[0;32m   1864\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1865\u001b[0m           \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   5018\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5019\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5020\u001b[1;33m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   5021\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5022\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   4216\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4218\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4219\u001b[0m     \u001b[1;31m# There is no graph to add in eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4220\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3148\u001b[0m          \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3149\u001b[0m     \"\"\"\n\u001b[1;32m-> 3150\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3151\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3152\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3114\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3115\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4193\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   4194\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4195\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4196\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4197\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4123\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4124\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4125\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4126\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4127\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-108-cd4347262d25>:67 read_tfrecord  *\n        example['binary_labels'] = self.get_binary_labels(example['frames'])\n    <ipython-input-108-cd4347262d25>:38 get_binary_labels  *\n        labels = tf.tensor_scatter_nd_update(\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3225 ones\n        shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163 wrapped\n        return func(*args, **kwargs)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:346 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271 constant\n        return _constant_impl(value, dtype, shape, name, verify_shape=False,\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:288 _constant_impl\n        tensor_util.make_tensor_proto(\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:457 make_tensor_proto\n        _AssertCompatible(values, dtype)\n    E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:336 _AssertCompatible\n        raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\n    TypeError: Expected int32, got None of type 'NoneType' instead.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import librosa.display\r\n",
    "\r\n",
    "spectrogram = list(next(iter(train)).values())[-1]\r\n",
    "\r\n",
    "plt.figure(figsize=(10, 7))\r\n",
    "n_samples = spectrogram.shape[0]\r\n",
    "row = 4; col = int(n_samples / 4)\r\n",
    "\r\n",
    "for i in range(n_samples):\r\n",
    "    plt.subplot(row, col, i+1)\r\n",
    "    plt.axis(\"off\")\r\n",
    "    librosa.display.specshow(spectrogram[i].numpy().T)\r\n",
    "\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "binary = list(next(iter(train)).values())[0]\r\n",
    "binary[0]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('tf-gpu': conda)"
  },
  "interpreter": {
   "hash": "b851d2923cfa3a2562599062e05fd9893d86a7c009c64d8ad3756552e4dd5f41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}