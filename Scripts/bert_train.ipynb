{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import regex as re\n",
    "import ast\n",
    "import glob\n",
    "import random\n",
    "import cutlet\n",
    "import argparse\n",
    "from itertools import groupby\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from convert_romaji import Romaji2Kana\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, TimeDistributed)\n",
    "\n",
    "from transformers import (\n",
    "    BertJapaneseTokenizer,\n",
    "    TFBertModel,\n",
    "    logging)\n",
    "\n",
    "def seed_everything(SEED):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    print(\"Random seed set.\")\n",
    "\n",
    "seed_everything(42)\n",
    "tf.get_logger().setLevel('FATAL')\n",
    "logging.set_verbosity_error()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=64, buffer_size=1024, epochs=25, learning_rate=5e-05, lr_max=5e-05, lr_min=1e-12, lr_start=1e-09, main_dir='E://Datasets/Decoder_model', n_cycles=0.5, n_samples=1000000, n_shards=10, n_train=900000, n_val=100000, random_state=42, sustain_epochs=0, test_size=0.1, train_steps=14063, val_steps=1563, vocab_size=4000, warmup_epochs=3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ArgParser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Dataset\n",
    "    parser.add_argument(\"--main_dir\", default=\"E://Datasets/Decoder_model\")\n",
    "    parser.add_argument(\"--random_state\", default=42)\n",
    "    parser.add_argument(\"--n_shards\", default=10)\n",
    "    parser.add_argument(\"--n_samples\", default=1000000)\n",
    "    parser.add_argument(\"--test_size\", default=0.1)\n",
    "    parser.add_argument(\"--vocab_size\", default=4000)\n",
    "    parser.add_argument(\"--batch_size\", default=64)\n",
    "    parser.add_argument(\"--buffer_size\", default=1024)\n",
    "\n",
    "    # Scheduler\n",
    "    parser.add_argument(\"--epochs\", default=25)\n",
    "    parser.add_argument(\"--learning_rate\", default=5e-5)\n",
    "    parser.add_argument(\"--lr_start\", default=1e-9)\n",
    "    parser.add_argument(\"--lr_min\", default=1e-12)\n",
    "    parser.add_argument(\"--lr_max\", default=5e-5)\n",
    "    parser.add_argument(\"--n_cycles\", default=0.5)\n",
    "    parser.add_argument(\"--warmup_epochs\", default=3)\n",
    "    parser.add_argument(\"--sustain_epochs\", default=0)\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    n_train = int(args.n_samples * (1 - args.test_size))\n",
    "    n_val = int(args.n_samples * args.test_size)\n",
    "    train_steps = int(np.ceil(n_train / args.batch_size))\n",
    "    val_steps = int(np.ceil(n_val / args.batch_size))\n",
    "    \n",
    "    # Trainer\n",
    "    parser.add_argument(\"--n_train\", default=n_train)\n",
    "    parser.add_argument(\"--n_val\", default=n_val)\n",
    "    parser.add_argument(\"--train_steps\", default=train_steps)  \n",
    "    parser.add_argument(\"--val_steps\", default=val_steps)\n",
    "\n",
    "    return parser.parse_known_args()[0]\n",
    "\n",
    "args = ArgParser()\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset:\n",
    "    def __init__(self):\n",
    "        self.main_dir = \"D:\\School-stuff\\Sem-2\\PR-Project\\HoloASR\\Datasets\"\n",
    "        opus_ja_paths = glob.glob(f\"{self.main_dir}\\OPUS100-dataset\\*.ja\")\n",
    "        tatoeba_ja_paths = glob.glob(f\"{self.main_dir}\\Tatoeba-dataset\\*.ja\")\n",
    "        self.ja_paths = opus_ja_paths + tatoeba_ja_paths\n",
    "        self.jesc_path = f\"{self.main_dir}/JESC-dataset/raw\"\n",
    "        self.cc100_path = f\"{self.main_dir}/cc_100.txt\"\n",
    "        self.kanji_unicode = self.get_kanji_unicode()\n",
    "        self.katsu = cutlet.Cutlet()\n",
    "        self.katsu.use_foreign_spelling = False\n",
    "\n",
    "        tqdm.pandas()\n",
    "        self.data = pd.DataFrame({\"raw_text\": self.get_data()})\n",
    "\n",
    "        # Remove rows that contains non-kanji characters\n",
    "        self.data = self.data[self.data['raw_text'].progress_apply(self.check_kanji)]   \n",
    "\n",
    "        # Remove words within parenthesis\n",
    "        parenthesis =  r\"\\（.*\\）|\\(.*\\)|\\「.*\\」|\\『.*\\』\"\n",
    "        self.data = self.data[~self.data['raw_text'].str.contains(parenthesis)]\n",
    "\n",
    "        # Remove punctuations from sentences\n",
    "        self.data['raw_text'] = self.data['raw_text'].progress_apply(self.clean_kanji)\n",
    "\n",
    "        # Converts kanji to hiragana sentences\n",
    "        self.data['hira_text'] = self.data['raw_text'].progress_apply(self.kanji2hira)\n",
    "\n",
    "        # Remove null rows\n",
    "        self.data = self.data[~(self.data['raw_text']==\"\") | ~(self.data['hira_text']==\"\")]\n",
    "        self.data = self.data[\n",
    "            (~self.data['raw_text'].duplicated()) & \n",
    "            (~self.data['hira_text'].duplicated())]\n",
    "        self.data = self.data.dropna().reset_index(drop=True)\n",
    "\n",
    "        # Generate vocab file\n",
    "        self.vocab_file = r\"E:\\Datasets\\Decoder_model\\bert_vocab.txt\"\n",
    "        self.get_vocab(self.data)\n",
    "\n",
    "        # Construct tokenizer\n",
    "        self.tokenizer = BertJapaneseTokenizer(\n",
    "            vocab_file=self.vocab_file,\n",
    "            do_lower_case=False,\n",
    "            do_word_tokenize=True,\n",
    "            do_subword_tokenize=True,\n",
    "            word_tokenizer_type=\"mecab\",\n",
    "            subword_tokenizer_type=\"character\")\n",
    "\n",
    "        # Tokenize inputs and labels\n",
    "        self.data['input_ids'] = self.data['hira_text'].progress_apply(\n",
    "            lambda x: self.tokenizer(x).input_ids)\n",
    "        self.data['label_ids'] = self.data['raw_text'].progress_apply(\n",
    "            lambda x: self.tokenizer(x).input_ids)\n",
    "\n",
    "        # Apply padding to either input or labels to same length\n",
    "        new_input_ids, new_label_ids = [], []\n",
    "        for row_idx in tqdm(range(len(self.data)), total=len(self.data)):\n",
    "            input_ids, label_ids = self.pad_longest(row_idx)\n",
    "            new_input_ids.append(input_ids)\n",
    "            new_label_ids.append(label_ids)\n",
    "\n",
    "        self.data['input_ids'] = new_input_ids\n",
    "        self.data['label_ids'] = new_label_ids\n",
    "        self.data['input_len'] = self.data['input_ids'].apply(len)\n",
    "\n",
    "        # Save to csv\n",
    "        self.data.to_csv(\n",
    "            r\"E:\\Datasets\\Decoder_model\\bert_data.csv\", \n",
    "            encoding=\"utf-8\", index=False)\n",
    "\n",
    "    def get_kanji_unicode(self):\n",
    "        vocab = set()\n",
    "        with open(f\"{self.main_dir}\\kanji_unicode.txt\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                for char in line.split()[1:]:\n",
    "                    vocab.add(char)\n",
    "        return \"|\".join(sorted(vocab))\n",
    "\n",
    "    def get_data(self):\n",
    "        ja_lines = []\n",
    "        for ja_path in self.ja_paths:\n",
    "            with open(ja_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f.readlines():\n",
    "                    line = line.strip(\"\\n| \")\n",
    "                    ja_lines.append(line)\n",
    "        with open(self.jesc_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            texts = [text.split(\"\\t\") for text in f.readlines()]\n",
    "            for _, line in texts:\n",
    "                line = line.strip(\"\\n| \")\n",
    "                ja_lines.append(line)\n",
    "        with open(self.cc100_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            texts = random.sample(f.readlines(), 7000000)\n",
    "            for line in texts:\n",
    "                line = line.strip(\"\\n| \")\n",
    "                ja_lines.append(line)            \n",
    "        return ja_lines\n",
    "\n",
    "    def check_kanji(self, sentence):\n",
    "        pattern = f\"[^{self.kanji_unicode}]\"\n",
    "        match = re.findall(pattern, sentence)\n",
    "        if match != []:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def clean_kanji(self, sentence):\n",
    "        sentence = \"\".join(sentence.split())\n",
    "        pattern = f\"[^{self.kanji_unicode}]\"\n",
    "        sentence = re.sub(pattern, \"\", sentence)\n",
    "        return sentence\n",
    "\n",
    "    def kanji2hira(self, sentence):\n",
    "        try:\n",
    "            sentence = self.katsu.romaji(sentence)\n",
    "            sentence = sentence.replace(\" \", \"\")\n",
    "            sentence = sentence.replace(\"。\", \"\").lower()\n",
    "            sentence = Romaji2Kana(sentence)\n",
    "        except:\n",
    "            sentence = None\n",
    "        return sentence\n",
    "\n",
    "    def get_vocab(self, data):\n",
    "        vocab = []\n",
    "        texts = data['raw_text'].tolist() + data['hira_text'].tolist()\n",
    "        for text in tqdm(texts):\n",
    "            for char in text:\n",
    "                vocab.append(char)\n",
    "\n",
    "        tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\"]\n",
    "        \n",
    "        for i in Counter(vocab).most_common():\n",
    "            if i[0] in self.kanji_unicode:\n",
    "                tokens.append(i[0])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        with open(self.vocab_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for token in tokens[:args.vocab_size]:\n",
    "                f.write(token + \"\\n\")    \n",
    "\n",
    "    def pad_longest(self, row):\n",
    "        input_len = len(self.data['input_ids'][row])\n",
    "        label_len = len(self.data['label_ids'][row])\n",
    "        input_ids = self.data['input_ids'][row]\n",
    "        label_ids = self.data['label_ids'][row]\n",
    "        if label_len > input_len:\n",
    "            pad_width = label_len - input_len\n",
    "            input_ids = np.pad(\n",
    "                self.data['input_ids'][row], pad_width=(0, pad_width)).tolist()\n",
    "        elif label_len < input_len:\n",
    "            pad_width = input_len - label_len\n",
    "            label_ids = np.pad(\n",
    "                self.data['label_ids'][row], pad_width=(0, pad_width)).tolist()\n",
    "        return input_ids, label_ids\n",
    "\n",
    "# data = BertDataset().data\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = pd.read_csv(r\"E:\\Datasets\\Decoder_model\\bert_datav2.csv\")\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 4))\n",
    "# sns.countplot(x=d['input_len'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_char(text):\n",
    "#     for i, char in enumerate(vocab):\n",
    "#         if char in text:\n",
    "#             return int(i)\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "# with open(r\"E:\\Datasets\\Decoder_model\\bert_vocab.txt\", encoding=\"utf-8\") as f:\n",
    "#     vocab = [v.strip(\"\\n\") for v in f.readlines()[4:][::-1]]\n",
    "\n",
    "# tqdm.pandas()\n",
    "# data = pd.read_csv(r\"E:\\Datasets\\Decoder_model\\bert_data.csv\", encoding=\"utf-8\")\n",
    "# data = data.dropna().reset_index(drop=True)\n",
    "# q1 = data['input_len'].quantile(0.1)\n",
    "# q2 = data['input_len'].quantile(0.9)\n",
    "# data = data[data['input_len'].between(q1, q2)]\n",
    "# # data['char'] = data['raw_text'].progress_apply(get_char)\n",
    "# # data = data.query(\"raw_text != hira_text\")\n",
    "# # data = data.sort_values(by=\"char\").reset_index(drop=True)[:-70000]\n",
    "# data.to_csv(r\"E:\\Datasets\\Decoder_model\\bert_datav2.csv\", index=False, encoding=\"utf-8\")\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(r\"E:\\Datasets\\Decoder_model\\bert_datav2.csv\", encoding=\"utf-8\")\n",
    "# data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# uniq = []\n",
    "# for text in tqdm(data['raw_text'][:500000]):\n",
    "#     for char in text:\n",
    "#         if char in vocab:\n",
    "#             uniq.append(char)\n",
    "\n",
    "# Counter(uniq).most_common()[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFRWriter():\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.vocab = self.get_vocab()\n",
    "        self.data = self.get_data()\n",
    "\n",
    "    def get_data(self):\n",
    "        tqdm.pandas()\n",
    "        data = pd.read_csv(f\"{self.args.main_dir}/bert_datav2.csv\")\n",
    "        data = data.dropna().reset_index(drop=True)\n",
    "        data = data.sample(n=self.args.n_samples, random_state=self.args.random_state)\n",
    "        data['input_ids'] = data['input_ids'].progress_apply(ast.literal_eval)\n",
    "        data['label_ids'] = data['label_ids'].progress_apply(ast.literal_eval)\n",
    "        data = data.sort_values(by=\"input_len\", ascending=True, ignore_index=True)\n",
    "        data.to_csv(f\"{self.args.main_dir}/bert_datav3.csv\", index=False, encoding=\"utf-8\")\n",
    "        return data[['input_ids', 'label_ids']]\n",
    "\n",
    "    def get_vocab(self):\n",
    "        with open(r\"E:\\Datasets\\Decoder_model\\bert_vocab.txt\", encoding=\"utf-8\") as f:\n",
    "            vocab = {k.strip(\"\\n\"): 0 for k in f.readlines()[4:]}\n",
    "\n",
    "    def _bytes_feature(self, value):\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy()\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def serialize_example(self, *args):\n",
    "        feature = {\n",
    "            'input_ids': self._bytes_feature(args[0]),\n",
    "            'attention_mask': self._bytes_feature(args[1]),\n",
    "            'label_ids': self._bytes_feature(args[2])}\n",
    "\n",
    "        example_proto = tf.train.Example(\n",
    "            features=tf.train.Features(feature=feature))\n",
    "        return example_proto.SerializeToString()\n",
    "\n",
    "    def get_shards(self):\n",
    "        skf = KFold(n_splits=self.args.n_shards)\n",
    "        return [j for i,j in skf.split(self.data)]\n",
    "\n",
    "    def get_shard_data(self, samples):\n",
    "        for sample in samples:\n",
    "            input_ids = tf.convert_to_tensor(\n",
    "                self.data['input_ids'][sample], dtype=tf.int32)\n",
    "            attention_mask = tf.where(input_ids != 0, x=1, y=0)\n",
    "            label_ids = tf.convert_to_tensor(\n",
    "                self.data['label_ids'][sample], dtype=tf.int32)\n",
    "            yield {\n",
    "                \"input_ids\": tf.io.serialize_tensor(input_ids),\n",
    "                \"attention_mask\": tf.io.serialize_tensor(attention_mask),\n",
    "                \"label_ids\": tf.io.serialize_tensor(label_ids)}\n",
    "\n",
    "    def write(self):\n",
    "        for shard, samples in tqdm(enumerate(self.get_shards()), total=self.args.n_shards):\n",
    "            with tf.io.TFRecordWriter(f\"{self.args.main_dir}/bert_tfrec/shard_{shard+1}.tfrec\") as f:\n",
    "                for sample in self.get_shard_data(samples):\n",
    "                    example = self.serialize_example(\n",
    "                        sample['input_ids'],\n",
    "                        sample['attention_mask'],\n",
    "                        sample['label_ids'])\n",
    "                    f.write(example)\n",
    "\n",
    "# TFRWriter(args).write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, args):\n",
    "        self.files = glob.glob(args.main_dir + \"/bert_tfrec/*.tfrec\")\n",
    "        self.args = args\n",
    "        self.AUTOTUNE = tf.data.AUTOTUNE\n",
    "        self.train_files, self.val_files = train_test_split(\n",
    "            self.files, test_size=args.test_size, shuffle=True,\n",
    "            random_state=args.random_state)\n",
    "        self.train = self.get_train()\n",
    "        self.val = self.get_val()\n",
    "\n",
    "    def read_tfrecord(self, example):\n",
    "        feature_description = {\n",
    "            'input_ids': tf.io.FixedLenFeature([], tf.string),\n",
    "            'attention_mask': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label_ids': tf.io.FixedLenFeature([], tf.string)}\n",
    "        \n",
    "        example = tf.io.parse_single_example(example, feature_description)\n",
    "        example['input_ids'] = tf.io.parse_tensor(\n",
    "            example['input_ids'], out_type=tf.int32)\n",
    "        example['attention_mask'] = tf.io.parse_tensor(\n",
    "            example['attention_mask'], out_type=tf.int32) \n",
    "        example['label_ids'] = tf.io.parse_tensor(\n",
    "            example['label_ids'], out_type=tf.int32)\n",
    "        return example\n",
    "\n",
    "    def load_dataset(self, files):\n",
    "        ignore_order = tf.data.Options()\n",
    "        ignore_order.experimental_deterministic = False\n",
    "        dataset = tf.data.TFRecordDataset(files)\n",
    "        dataset = dataset.with_options(ignore_order)\n",
    "        dataset = dataset.map(self.read_tfrecord, num_parallel_calls=self.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    def get_train(self):\n",
    "        dataset = self.load_dataset(self.train_files)\n",
    "        dataset = dataset.padded_batch(\n",
    "            self.args.batch_size,\n",
    "            padded_shapes={\n",
    "                'input_ids': [None],\n",
    "                'attention_mask': [None],\n",
    "                'label_ids': [None]},\n",
    "            padding_values={\n",
    "                'input_ids': tf.constant(0, dtype=tf.int32),\n",
    "                'attention_mask': tf.constant(0, dtype=tf.int32),\n",
    "                'label_ids': tf.constant(0, dtype=tf.int32)})        \n",
    "        dataset = dataset.shuffle(self.args.buffer_size)\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    def get_val(self):\n",
    "        dataset = self.load_dataset(self.val_files)\n",
    "        dataset = dataset.padded_batch(\n",
    "            self.args.batch_size,\n",
    "            padded_shapes={\n",
    "                'input_ids': [None],\n",
    "                'attention_mask': [None],\n",
    "                'label_ids': [None]},\n",
    "            padding_values={\n",
    "                'input_ids': tf.constant(0, dtype=tf.int32),\n",
    "                'attention_mask': tf.constant(0, dtype=tf.int32),\n",
    "                'label_ids': tf.constant(0, dtype=tf.int32)})\n",
    "        dataset = dataset.shuffle(self.args.buffer_size)\n",
    "        dataset = dataset.cache()\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "# train = DataLoader(args).train\n",
    "# inputs = next(iter(train))\n",
    "# print(\"input_ids shape:\", inputs['input_ids'].shape)\n",
    "# print(\"attention_mask shape:\", inputs['attention_mask'].shape)\n",
    "# print(\"label_ids shape:\", inputs['label_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CERMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"CER\", **kwargs):\n",
    "        super(CERMetric, self).__init__(name=name,  **kwargs)\n",
    "        self.accumulator = self.add_weight(name=\"total_cer\", initializer=\"zeros\")\n",
    "        self.counter = self.add_weight(name=\"cer_count\", initializer=\"zeros\")    \n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        hypothesis = tf.cast(tf.sparse.from_dense(y_pred), dtype=tf.int32)\n",
    "\n",
    "        # Convert dense to sparse tensor for edit_distance function\n",
    "        truth = tf.RaggedTensor.from_tensor(y_true, padding=0).to_sparse()\n",
    "\n",
    "        # Calculate Levenshtein distance\n",
    "        distance = tf.edit_distance(hypothesis, truth, normalize=True)\n",
    "\n",
    "        # Add distance and number of samples to variables\n",
    "        self.accumulator.assign_add(tf.reduce_sum(distance))\n",
    "        self.counter.assign_add(len(y_true))\n",
    "\n",
    "    def result(self):\n",
    "        # Divides accumulated distance scores against number of samples passed,\n",
    "        # mimics mean reduction over batch\n",
    "        return tf.math.divide_no_nan(self.accumulator, self.counter)   \n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.accumulator.assign(0.0)\n",
    "        self.counter.assign(0.0)\n",
    "\n",
    "class CosineDecayWithWarmup(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "    def __call__(self, epoch):  \n",
    "        if epoch < self.args.warmup_epochs:\n",
    "            lr = ((self.args.lr_max - self.args.lr_start) / self.args.warmup_epochs) * epoch + self.args.lr_start\n",
    "        elif epoch < (self.args.warmup_epochs + self.args.sustain_epochs):\n",
    "            lr = self.args.lr_max\n",
    "        else:\n",
    "            progress = ((epoch - self.args.warmup_epochs - self.args.sustain_epochs) / \n",
    "            (self.args.epochs - self.args.warmup_epochs - self.args.sustain_epochs))\n",
    "            lr = (self.args.lr_max-self.args.lr_min) * (0.5 * (1.0 + tf.math.cos((22/7) * \n",
    "                self.args.n_cycles * 2.0 * progress)))\n",
    "            if self.args.lr_min is not None:\n",
    "                lr = tf.math.maximum(self.args.lr_min, lr)\n",
    "        return lr\n",
    "\n",
    "    def plot(self):\n",
    "        epochs = range(self.args.epochs+1)\n",
    "        lr = [self(epoch) for epoch in epochs]\n",
    "        plt.plot(epochs, lr)\n",
    "        plt.xlabel(\"learning_rate\")\n",
    "        plt.ylabel(\"epochs\")\n",
    "        plt.show()\n",
    "\n",
    "CosineDecayWithWarmup(args).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Kana2Kanji\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(64, None)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(64, None)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_model (TFBertModel)        TFBaseModelOutputWit 119111424   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (64, None, 768)      0           bert_model[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (64, None, 4000)     3076000     dropout[0][0]                    \n",
      "                                                                 attention_mask[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 122,187,424\n",
      "Trainable params: 122,187,424\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def Kana2Kanji(args):\n",
    "    input_ids = Input(type_spec=tf.TensorSpec(\n",
    "        shape=(args.batch_size, None), dtype=tf.int32), name=\"input_ids\")\n",
    "    mask = Input(type_spec=tf.TensorSpec(\n",
    "        shape=(args.batch_size, None), dtype=tf.int32), name=\"attention_mask\")\n",
    "\n",
    "    bert = TFBertModel.from_pretrained(\n",
    "        \"cl-tohoku/bert-base-japanese-char-v2\",\n",
    "        output_hidden_states=False,\n",
    "        output_attentions=False,\n",
    "        num_attention_heads=16,\n",
    "        num_hidden_layers=16,\n",
    "        name=\"bert_model\")\n",
    "\n",
    "    x = bert(input_ids=input_ids, attention_mask=mask).last_hidden_state\n",
    "    x = Dropout(0.1, name=\"dropout\")(x)\n",
    "    x = TimeDistributed(\n",
    "        Dense(\n",
    "            args.vocab_size, \n",
    "            activation=\"softmax\",\n",
    "            name='output'\n",
    "            ))(x, mask=mask)\n",
    "    return tf.keras.Model(inputs=[input_ids, mask], outputs=x, name=\"Kana2Kanji\")\n",
    "\n",
    "model = Kana2Kanji(args)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.train_dataset = DataLoader(args).train\n",
    "        self.val_dataset = DataLoader(args).val\n",
    "\n",
    "        self.tokenizer = BertJapaneseTokenizer(\n",
    "            vocab_file=f\"{self.args.main_dir}/bert_vocab.txt\",\n",
    "            do_lower_case=False,\n",
    "            do_word_tokenize=True,\n",
    "            do_subword_tokenize=True,\n",
    "            word_tokenizer_type=\"mecab\",\n",
    "            subword_tokenizer_type=\"character\")\n",
    "        \n",
    "        self.model = self.Kana2Kanji(args)\n",
    "        \n",
    "        schedule = CosineDecayWithWarmup(args)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(schedule)\n",
    "        self.loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=False)\n",
    "        self.cer_metric = CERMetric()\n",
    "\n",
    "        self.model_name = f\"model_{int(self.args.n_samples/1000)}k_v5\"\n",
    "        self.log_path = f\"{self.args.main_dir}/bert_model_weights/{self.model_name}.csv\"\n",
    "        if not os.path.exists(self.log_path):\n",
    "            print(\"Log file created.\")\n",
    "            columns = \"epoch,loss,cer,val_loss,val_cer\\n\"\n",
    "            with open(self.log_path, \"a\") as f:\n",
    "                f.write(columns)\n",
    "\n",
    "    def Kana2Kanji(self, args):\n",
    "        input_ids = Input(type_spec=tf.TensorSpec(\n",
    "            shape=(args.batch_size, None), dtype=tf.int32), name=\"input_ids\")\n",
    "        mask = Input(type_spec=tf.TensorSpec(\n",
    "            shape=(args.batch_size, None), dtype=tf.int32), name=\"attention_mask\")\n",
    "\n",
    "        bert = TFBertModel.from_pretrained(\n",
    "            \"cl-tohoku/bert-base-japanese-char-v2\",\n",
    "            output_hidden_states=False,\n",
    "            output_attentions=False,\n",
    "            name=\"bert_model\")\n",
    "\n",
    "        x = bert(input_ids=input_ids, attention_mask=mask).last_hidden_state\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = TimeDistributed(\n",
    "            Dense(\n",
    "                args.vocab_size, \n",
    "                activation=\"softmax\"), \n",
    "            name=\"output\")(x, mask=mask)\n",
    "        return tf.keras.Model(inputs=[input_ids, mask], outputs=x, name=\"Kana2Kanji\")\n",
    "\n",
    "    def display(self, t_labels, t_logits, v_labels, v_logits):\n",
    "        t_labels = self.tokenizer.batch_decode(t_labels, skip_special_tokens=True)\n",
    "        t_logits = self.tokenizer.batch_decode(t_logits, skip_special_tokens=True)\n",
    "        v_labels = self.tokenizer.batch_decode(v_labels, skip_special_tokens=True)\n",
    "        v_logits = self.tokenizer.batch_decode(v_logits, skip_special_tokens=True)\n",
    "\n",
    "        print(\"-\" * 129)\n",
    "        print(\"Training\")\n",
    "        for y_true, y_pred in zip(t_labels[:4], t_logits[:4]):\n",
    "            print(f\"Target:    {y_true.replace(' ', '')}\")\n",
    "            print(f\"Predicted: {y_pred.replace(' ', '')}\")\n",
    "\n",
    "        print(\"\\nValidation\")\n",
    "        for y_true, y_pred in zip(v_labels[:4], v_logits[:4]):\n",
    "            print(f\"Target:    {y_true.replace(' ', '')}\")\n",
    "            print(f\"Predicted: {y_pred.replace(' ', '')}\")\n",
    "        print(\"-\" * 129)\n",
    "        \n",
    "    def fit(self):\n",
    "        # Checkpointing\n",
    "        self.ckpt_dir = f\"{self.args.main_dir}/bert_checkpoints\"\n",
    "        self.ckpt = tf.train.Checkpoint(self.model)\n",
    "        self.ckpt_manager = tf.train.CheckpointManager(\n",
    "            checkpoint=self.ckpt, directory=self.ckpt_dir, max_to_keep=5)\n",
    "\n",
    "        if self.ckpt_manager.latest_checkpoint:\n",
    "            self.start_epoch = int(self.ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
    "            self.ckpt.restore(self.ckpt_manager.latest_checkpoint)\n",
    "            print(f\"Resuming from epoch {self.start_epoch}...\")\n",
    "        else:\n",
    "            self.start_epoch = 0\n",
    "            print(\"Starting from epoch 0...\")\n",
    "\n",
    "        for epoch in range(self.start_epoch, self.args.epochs+1):\n",
    "            print(f\"Epoch {epoch}/{self.args.epochs}: Learning rate @ {self.optimizer.lr(epoch):.2e}\")\n",
    "            stateful_metrics = [\"loss\", \"cer\", \"val_loss\", \"val_cer\"]\n",
    "            progbar = tf.keras.utils.Progbar(\n",
    "                self.args.train_steps, interval=0.05,\n",
    "                stateful_metrics=stateful_metrics)\n",
    "\n",
    "            # Training loop\n",
    "            for step, t_batch in enumerate(self.train_dataset):\n",
    "                t_input_ids = t_batch['input_ids']\n",
    "                t_attention_mask = t_batch['attention_mask']\n",
    "                t_labels = t_batch['label_ids']\n",
    "                with tf.GradientTape() as tape:\n",
    "                    t_logits = self.model(\n",
    "                        [t_input_ids, t_attention_mask],\n",
    "                        training=True)                 \n",
    "                    t_loss = self.loss_fn(\n",
    "                        t_labels, t_logits, sample_weight=t_attention_mask)\n",
    "                gradients = tape.gradient(t_loss, self.model.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(gradients, self.model.trainable_weights))\n",
    "                t_logits = tf.argmax(t_logits, axis=-1)\n",
    "                self.cer_metric.update_state(t_labels, t_logits)\n",
    "                t_cer = self.cer_metric.result()\n",
    "                t_values = [(\"loss\", t_loss), (\"cer\", t_cer)]\n",
    "                progbar.update(step, values=t_values, finalize=False)\n",
    "            \n",
    "            self.cer_metric.reset_state()\n",
    "\n",
    "            # Validation loop\n",
    "            for v_batch in self.val_dataset:\n",
    "                v_input_ids = v_batch['input_ids']\n",
    "                v_attention_mask = v_batch['attention_mask']\n",
    "                v_labels = v_batch['label_ids']\n",
    "                v_logits = self.model(\n",
    "                    [v_input_ids, v_attention_mask],\n",
    "                    training=False)\n",
    "                v_loss = self.loss_fn(\n",
    "                    v_labels, v_logits, sample_weight=v_attention_mask)\n",
    "                v_logits = tf.argmax(v_logits, axis=-1)    \n",
    "                self.cer_metric.update_state(v_labels, v_logits)\n",
    "                \n",
    "            v_cer = self.cer_metric.result()\n",
    "            v_values = [\n",
    "                (\"loss\", t_loss),\n",
    "                (\"cer\", t_cer),\n",
    "                (\"val_loss\", v_loss),\n",
    "                (\"val_cer\", v_cer)]\n",
    "            progbar.update(self.args.train_steps, values=v_values, finalize=True)\n",
    "            self.cer_metric.reset_state()\n",
    "\n",
    "            # Print sample transcriptions for both loops\n",
    "            self.display(t_labels, t_logits, v_labels, v_logits)\n",
    "\n",
    "            # Checkpointing\n",
    "            self.ckpt.save(file_prefix=f\"{self.ckpt_dir}/{self.model_name}\")\n",
    "\n",
    "            # Logging\n",
    "            log = f\"{epoch},{t_loss},{t_cer},{v_loss},{v_cer}\\n\"\n",
    "            with open(self.log_path, \"a\") as f:\n",
    "                f.write(log)\n",
    "\n",
    "            save_path = f\"{self.args.main_dir}/bert_model_weights\"\n",
    "            self.model.save_weights(f\"{save_path}/{self.model_name}_{epoch}.h5\")\n",
    "\n",
    "# Trainer(args).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv(r\"E:\\Datasets\\Decoder_model\\bert_model_weights\\model_1000k_v5.csv\", index_col='epoch')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(x=history.index, y=history['cer'], label=\"cer\")\n",
    "sns.lineplot(x=history.index, y=history['val_cer'], label=\"val_cer\")\n",
    "# ax2.axvline(x=9, ymin=0, ymax=0.05, color='red', linestyle=\"--\")\n",
    "plt.suptitle(\"Decoder model\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b851d2923cfa3a2562599062e05fd9893d86a7c009c64d8ad3756552e4dd5f41"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tf-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
