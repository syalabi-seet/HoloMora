{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import regex as re\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import groupby\n",
    "from convert_romaji import Romaji2Kana\n",
    "\n",
    "import cutlet\n",
    "import jiwer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2Processor,\n",
    "    TFWav2Vec2ForCTC,\n",
    "    logging)\n",
    "\n",
    "from convert_romaji import Romaji2Kana\n",
    "\n",
    "def seed_everything(SEED):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    print(\"Random seed set.\")\n",
    "\n",
    "seed_everything(42)\n",
    "tf.get_logger().setLevel('FATAL')\n",
    "logging.set_verbosity_error()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=4, buffer_size=512, epochs=15, learning_rate=5e-05, lr_max=5e-05, lr_min=1e-10, lr_start=1e-08, main_dir='E://Datasets/Acoustic_model', model_name='facebook/wav2vec2-base', n_cycles=0.5, n_samples=50000, n_shards=40, n_train=45000, n_val=5000, random_state=42, sample_rate=16000, sustain_epochs=0, test_size=0.1, train_steps=11250, val_steps=1250, vocab_size=37, warmup_epochs=3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ArgParser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # DataLoader\n",
    "    parser.add_argument(\"--main_dir\", default=\"E://Datasets/Acoustic_model\")\n",
    "    parser.add_argument(\"--sample_rate\", default=16000)\n",
    "    parser.add_argument(\"--test_size\", default=0.1)\n",
    "    parser.add_argument(\"--random_state\", default=42)\n",
    "    parser.add_argument(\"--batch_size\", default=4)\n",
    "    parser.add_argument(\"--n_shards\", default=40)\n",
    "    parser.add_argument(\"--buffer_size\", default=512)\n",
    "    parser.add_argument(\"--n_samples\", default=50000)\n",
    "\n",
    "    # Trainer\n",
    "    parser.add_argument(\"--model_name\", default=\"facebook/wav2vec2-base\")\n",
    "    parser.add_argument(\"--epochs\", default=15)\n",
    "\n",
    "    # Scheduler\n",
    "    parser.add_argument(\"--learning_rate\", default=5e-5)\n",
    "    parser.add_argument(\"--lr_start\", default=1e-8)\n",
    "    parser.add_argument(\"--lr_min\", default=1e-10)\n",
    "    parser.add_argument(\"--lr_max\", default=5e-5)\n",
    "    parser.add_argument(\"--n_cycles\", default=0.5)\n",
    "    parser.add_argument(\"--warmup_epochs\", default=3)\n",
    "    parser.add_argument(\"--sustain_epochs\", default=0)\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    with open(f\"{args.main_dir}/vocab.json\", \"r\") as f:\n",
    "        vocab_size = len(json.load(f))\n",
    "   \n",
    "    n_train = int(args.n_samples * (1 - args.test_size))\n",
    "    n_val = int(args.n_samples * args.test_size)\n",
    "    train_steps = int(np.ceil(n_train / args.batch_size))\n",
    "    val_steps = int(np.ceil(n_val / args.batch_size))\n",
    "\n",
    "    parser.add_argument(\"--vocab_size\", default=vocab_size)\n",
    "    parser.add_argument(\"--n_train\", default=n_train)\n",
    "    parser.add_argument(\"--n_val\", default=n_val)\n",
    "    parser.add_argument(\"--train_steps\", default=train_steps)  \n",
    "    parser.add_argument(\"--val_steps\", default=val_steps)\n",
    "    \n",
    "    return parser.parse_known_args()[0]\n",
    "\n",
    "args = ArgParser()\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7696/7696 [00:01<00:00, 4627.88it/s]\n",
      "100%|██████████| 21026/21026 [00:07<00:00, 2703.08it/s]\n",
      "100%|██████████| 68764/68764 [00:04<00:00, 14762.41it/s]\n",
      "100%|██████████| 68764/68764 [00:11<00:00, 6249.63it/s]\n",
      "100%|██████████| 68764/68764 [00:18<00:00, 3717.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>corpus</th>\n",
       "      <th>romaji</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_ja_22635900.wav</td>\n",
       "      <td>ろく</td>\n",
       "      <td>common_voice</td>\n",
       "      <td>roku</td>\n",
       "      <td>11703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_ja_22635908.wav</td>\n",
       "      <td>に</td>\n",
       "      <td>common_voice</td>\n",
       "      <td>ni</td>\n",
       "      <td>12539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_ja_22635869.wav</td>\n",
       "      <td>いいえ</td>\n",
       "      <td>common_voice</td>\n",
       "      <td>iie</td>\n",
       "      <td>13375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_ja_22635878.wav</td>\n",
       "      <td>はい</td>\n",
       "      <td>common_voice</td>\n",
       "      <td>hai</td>\n",
       "      <td>13375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_ja_22635852.wav</td>\n",
       "      <td>いち</td>\n",
       "      <td>common_voice</td>\n",
       "      <td>ichi</td>\n",
       "      <td>13793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68759</th>\n",
       "      <td>garasudono-uchi-by-natsume-soseki-00436.wav</td>\n",
       "      <td>しかしその時の私はとうてい富士登山の図などに賛をする勇気をもっていなかった私の気分がそんな事...</td>\n",
       "      <td>kokoro</td>\n",
       "      <td>shikashisonotokinowatakushiwatouteifujitozanno...</td>\n",
       "      <td>239816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68760</th>\n",
       "      <td>BASIC5000_4195.wav</td>\n",
       "      <td>教皇庁教理聖省長官にして教会軍総司令官教皇宮殿付神学顧問と数の要職を歴任しており苛烈かつ強引...</td>\n",
       "      <td>jsut</td>\n",
       "      <td>kyoukouchoukyourishoushouchoukannishitekyoukai...</td>\n",
       "      <td>251360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68761</th>\n",
       "      <td>BASIC5000_0617.wav</td>\n",
       "      <td>唯一人生に意味を与えてくれるような芸術作品の中に美しい人生と言うものも含めて考える事によって...</td>\n",
       "      <td>jsut</td>\n",
       "      <td>yuiitsujinseiniimiwoataetekureruyounageijutsus...</td>\n",
       "      <td>255840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68762</th>\n",
       "      <td>TRAVEL1000_0822.wav</td>\n",
       "      <td>カードの番号は</td>\n",
       "      <td>jsut</td>\n",
       "      <td>kaadonobangouwa</td>\n",
       "      <td>261440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68763</th>\n",
       "      <td>BASIC5000_4497.wav</td>\n",
       "      <td>農業経営安定勘定食糧管理勘定農業共済再保険勘定漁船再保険勘定漁業共済保険勘定各事業勘定に共通...</td>\n",
       "      <td>jsut</td>\n",
       "      <td>nougyoukeieianteikanjoushokuryoukanrikanjounou...</td>\n",
       "      <td>261920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68764 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path  \\\n",
       "0                     common_voice_ja_22635900.wav   \n",
       "1                     common_voice_ja_22635908.wav   \n",
       "2                     common_voice_ja_22635869.wav   \n",
       "3                     common_voice_ja_22635878.wav   \n",
       "4                     common_voice_ja_22635852.wav   \n",
       "...                                            ...   \n",
       "68759  garasudono-uchi-by-natsume-soseki-00436.wav   \n",
       "68760                           BASIC5000_4195.wav   \n",
       "68761                           BASIC5000_0617.wav   \n",
       "68762                          TRAVEL1000_0822.wav   \n",
       "68763                           BASIC5000_4497.wav   \n",
       "\n",
       "                                                sentence        corpus  \\\n",
       "0                                                     ろく  common_voice   \n",
       "1                                                      に  common_voice   \n",
       "2                                                    いいえ  common_voice   \n",
       "3                                                     はい  common_voice   \n",
       "4                                                     いち  common_voice   \n",
       "...                                                  ...           ...   \n",
       "68759  しかしその時の私はとうてい富士登山の図などに賛をする勇気をもっていなかった私の気分がそんな事...        kokoro   \n",
       "68760  教皇庁教理聖省長官にして教会軍総司令官教皇宮殿付神学顧問と数の要職を歴任しており苛烈かつ強引...          jsut   \n",
       "68761  唯一人生に意味を与えてくれるような芸術作品の中に美しい人生と言うものも含めて考える事によって...          jsut   \n",
       "68762                                            カードの番号は          jsut   \n",
       "68763  農業経営安定勘定食糧管理勘定農業共済再保険勘定漁船再保険勘定漁業共済保険勘定各事業勘定に共通...          jsut   \n",
       "\n",
       "                                                  romaji  length  \n",
       "0                                                   roku   11703  \n",
       "1                                                     ni   12539  \n",
       "2                                                    iie   13375  \n",
       "3                                                    hai   13375  \n",
       "4                                                   ichi   13793  \n",
       "...                                                  ...     ...  \n",
       "68759  shikashisonotokinowatakushiwatouteifujitozanno...  239816  \n",
       "68760  kyoukouchoukyourishoushouchoukannishitekyoukai...  251360  \n",
       "68761  yuiitsujinseiniimiwoataetekureruyounageijutsus...  255840  \n",
       "68762                                    kaadonobangouwa  261440  \n",
       "68763  nougyoukeieianteikanjoushokuryoukanrikanjounou...  261920  \n",
       "\n",
       "[68764 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.data_dir = \"E:/Datasets/Acoustic_model/raw_data\"\n",
    "        self.data = pd.concat([\n",
    "            self.get_kokoro(),\n",
    "            self.get_jsut(),\n",
    "            self.get_commonvoice()], \n",
    "            ignore_index=True)\n",
    "        self.kanji_unicode = self.get_kanji_unicode()\n",
    "        self.katsu = cutlet.Cutlet()\n",
    "        self.katsu.use_foreign_spelling = False\n",
    "        self.vocab = self.get_vocab()\n",
    "    \n",
    "        tqdm.pandas()\n",
    "        # Remove words within parenthesis\n",
    "        parenthesis =  r\"\\（.*\\）|\\(.*\\)|\\「.*\\」|\\『.*\\』\"\n",
    "        self.data = self.data[~self.data['sentence'].str.contains(parenthesis)]\n",
    "\n",
    "        # Remove punctuations from sentences\n",
    "        self.data['sentence'] = self.data['sentence'].progress_apply(self.clean_kanji)\n",
    "        self.data['romaji'] = self.data['sentence'].progress_apply(self.kanji2romaji)\n",
    "        self.data['length'] = self.data['path'].progress_apply(self.get_length)\n",
    "        # self.data = self.data[self.data['length'].between(48000, 95000)]\n",
    "        self.data = self.data.reset_index(drop=True)\n",
    "        # self.data = self.data.sample(n=self.args.n_samples, random_state=42, ignore_index=True)\n",
    "        self.data.sort_values(by=\"length\", axis=0, ascending=True, inplace=True, ignore_index=True)\n",
    "        self.data.to_csv(\n",
    "            f\"{self.args.main_dir}/ASRDataset_main.csv\", \n",
    "            encoding=\"utf-8\", index=False)\n",
    "\n",
    "    def get_vocab(self):\n",
    "        with open(r\"E:\\Datasets\\Acoustic_model\\vocab.json\") as f:\n",
    "            vocab = \"|\".join(list(json.load(f).keys())[4:])\n",
    "        return vocab\n",
    "\n",
    "    def get_kokoro(self):\n",
    "        data = []\n",
    "        transcript_path = f\"{self.data_dir}/KOKORO-dataset/transcripts/*.metadata.txt\"\n",
    "        for transcript in glob.glob(transcript_path):\n",
    "            with open(transcript, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f.readlines():\n",
    "                    data.append(line.split(\"|\"))\n",
    "\n",
    "        data = pd.DataFrame(\n",
    "            data, columns=[\n",
    "                'text_id', 'path', 'start_idx', \n",
    "                'end_idx', 'sentence', 'phonemes'])       \n",
    "\n",
    "        # paths = data['path'].unique()\n",
    "        # for path in tqdm(paths, total=len(paths)):\n",
    "        #     folder_name = path.split(\"_\", 1)[0]\n",
    "        #     in_path = os.path.join(f\"{self.data_dir}/KOKORO-dataset\", folder_name, path)\n",
    "        #     y, sr = librosa.load(in_path, sr=None)\n",
    "        #     for text_id in data.loc[data['path']==path, 'text_id']:\n",
    "        #         out_path = os.path.join(self.args.main_dir, 'wav_cleaned', text_id) + \".wav\"\n",
    "        #         if not os.path.exists(out_path):\n",
    "        #             start_idx = int(data.loc[data['text_id']==text_id, 'start_idx'].item())\n",
    "        #             end_idx = int(data.loc[data['text_id']==text_id, 'end_idx'].item())\n",
    "        #             y_slice = librosa.resample(\n",
    "        #                 y[start_idx:end_idx], orig_sr=sr, target_sr=self.args.sample_rate)\n",
    "        #             sf.write(out_path, y_slice, samplerate=self.args.sample_rate, subtype='PCM_16')\n",
    "\n",
    "        data = data[['text_id', 'sentence']]\n",
    "        data['text_id'] = data['text_id'].apply(lambda x: x + \".wav\")\n",
    "        data.columns = ['path', 'sentence']\n",
    "        data['corpus'] = ['kokoro'] * len(data)\n",
    "        return data\n",
    "\n",
    "    def get_jsut(self):\n",
    "        filenames, sentences = [], []\n",
    "        for transcript in glob.glob(f\"{self.data_dir}/JSUT-dataset/*/transcript_utf8.txt\"):\n",
    "            file_path = transcript.rsplit(\"\\\\\", 1)[0]\n",
    "            with open(transcript, \"r\", encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines: \n",
    "                    filename, sentence = line.split(\":\")\n",
    "                    filenames.append(os.path.join(file_path, \"wav\", filename) + \".wav\")\n",
    "                    sentences.append(sentence.strip(\"\\n\"))\n",
    "        data = pd.DataFrame({'path': filenames, 'sentence': sentences}) \n",
    "        data['corpus'] = ['jsut'] * len(data)\n",
    "        for i, in_path in tqdm(enumerate(data['path']), total=len(data['path'])):\n",
    "            in_path = in_path.replace(\"\\\\\", \"/\")\n",
    "            out_path = f\"{self.args.main_dir}\\wav_cleaned\"\n",
    "            filename = in_path.rsplit(\"/\", 1)[-1]\n",
    "            out_path = os.path.join(out_path, filename)\n",
    "            if not os.path.exists(out_path):\n",
    "                subprocess.call([\n",
    "                    \"ffmpeg\", \"-i\", in_path,\"-acodec\", \"pcm_s16le\", \n",
    "                    \"-ar\", str(self.args.sample_rate), out_path])\n",
    "            data['path'][i] = filename\n",
    "        return data\n",
    "\n",
    "    def get_commonvoice(self):\n",
    "        data = pd.read_csv(f\"{self.data_dir}/CommonVoice-dataset/validated.tsv\", sep=\"\\t\")\n",
    "        data = data[['path', 'sentence']]    \n",
    "        data['path'] = data['path'].apply(\n",
    "            lambda x: f\"{self.data_dir}/CommonVoice-dataset/clips/\" + x)\n",
    "        data['corpus'] = ['common_voice'] * len(data)\n",
    "        for i, in_path in tqdm(enumerate(data['path']), total=len(data['path'])):\n",
    "            in_path = in_path.replace(\"\\\\\", \"/\")\n",
    "            out_path = f\"{self.args.main_dir}\\wav_cleaned\"\n",
    "            filename = in_path.rsplit(\"/\", 1)[-1]\n",
    "            filename = filename.replace(\"mp3\", \"wav\")\n",
    "            out_path = os.path.join(out_path, filename)\n",
    "            if not os.path.exists(out_path):\n",
    "                subprocess.call([\n",
    "                    \"ffmpeg\", \"-i\", in_path,\"-acodec\", \"pcm_s16le\", \n",
    "                    \"-ar\", str(self.args.sample_rate), out_path])\n",
    "            data['path'][i] = filename\n",
    "        return data\n",
    "\n",
    "    def get_kanji_unicode(self):\n",
    "        vocab = set()\n",
    "        with open(\n",
    "            f\"{self.data_dir}/kanji_unicode.txt\", \n",
    "            encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                for char in line.split()[1:]:\n",
    "                    vocab.add(char)\n",
    "        return \"\".join(sorted(vocab))\n",
    "        \n",
    "    def clean_kanji(self, sentence):\n",
    "        sentence = \"\".join(sentence.split())\n",
    "        pattern = f\"[^{self.kanji_unicode}]\"\n",
    "        sentence = re.sub(pattern, \"\", sentence)\n",
    "        return sentence\n",
    "\n",
    "    def kanji2romaji(self, sentence):\n",
    "        try:\n",
    "            sentence = self.katsu.romaji(sentence)\n",
    "            sentence = \" \".join(sentence.split())\n",
    "            sentence = re.sub(r\"'|-| \", \"\", sentence).lower()\n",
    "        except:\n",
    "            sentence = None\n",
    "        return sentence\n",
    "\n",
    "    def get_length(self, path):\n",
    "        path = os.path.join(self.args.main_dir, 'wav_cleaned', path)\n",
    "        y = librosa.load(path, sr=None)[0]\n",
    "        return len(y)\n",
    "\n",
    "data = Dataset(args).data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(r\"E:\\Datasets\\Acoustic_model\\ASRDataset_main.csv\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(x=data['length'], hue=data['corpus'])\n",
    "# plt.axvline(x=0, ymin=0, ymax=1, color='red', linestyle=\"--\")\n",
    "plt.axvline(x=48000, ymin=0, ymax=1, color='red', linestyle=\"--\")\n",
    "plt.axvline(x=95000, ymin=0, ymax=1, color='blue', linestyle=\"--\")\n",
    "# plt.axvline(x=260000, ymin=0, ymax=1, color='blue', linestyle=\"--\")\n",
    "plt.axvspan(xmax=48000, xmin=0, ymax=1, ymin=0.95, alpha=0.4, color='red')\n",
    "plt.axvspan(xmax=95000, xmin=48000, ymax=1, ymin=0.95, alpha=0.4, color='green')\n",
    "plt.axvspan(xmax=260000, xmin=95000, ymax=1, ymin=0.95, alpha=0.4, color='blue')\n",
    "plt.text(x=14000, y=1325, s=\"dropped\")\n",
    "plt.text(x=58000, y=1325, s=\"train + val\")\n",
    "plt.text(x=170000, y=1325, s=\"test\")\n",
    "plt.xlim(0, 260000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"E:\\Datasets\\Acoustic_model\\vocab.json\") as f:\n",
    "#     vocab = list(json.load(f).keys())[5:]\n",
    "\n",
    "# double_consonants = set()\n",
    "# for romaji in data['romaji']:\n",
    "#     for i in range(len(romaji)):\n",
    "#         if i < len(romaji) - 1:\n",
    "#             if romaji[i] == romaji[i+1]:\n",
    "#                 double_consonants.add(romaji[i])\n",
    "\n",
    "# double_consonants = list(double_consonants)\n",
    "# print(double_consonants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, args):\n",
    "        tokenizer = Wav2Vec2CTCTokenizer(\n",
    "            vocab_file=f\"{args.main_dir}/vocab.json\",\n",
    "            do_lower_case=False)\n",
    "\n",
    "        feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "            feature_size=1,\n",
    "            sampling_rate=args.sample_rate,\n",
    "            padding_value=0.0,\n",
    "            do_normalize=False,\n",
    "            return_attention_mask=False)\n",
    "\n",
    "        self.processor = Wav2Vec2Processor(\n",
    "            feature_extractor=feature_extractor,\n",
    "            tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFRWriter():\n",
    "    def __init__(self, args):\n",
    "        self.data = pd.read_csv(os.path.join(args.main_dir, \"ASRDataset.csv\"), encoding=\"utf-8\")\n",
    "        self.args = args\n",
    "        self.config = Config(args)\n",
    "\n",
    "    def _bytes_feature(self, value):\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy()\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def _int64_feature(self, value):\n",
    "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "    def _float_feature(self, value):\n",
    "        \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "    def serialize_example(self, *args):\n",
    "        feature = {\n",
    "            'input_values': self._bytes_feature(args[0]),\n",
    "            'labels': self._bytes_feature(args[1])}\n",
    "\n",
    "        example_proto = tf.train.Example(\n",
    "            features=tf.train.Features(feature=feature))\n",
    "        return example_proto.SerializeToString()\n",
    "\n",
    "    def get_labels(self, sample):\n",
    "        labels = self.data.loc[self.data['path']==sample, \"romaji\"].item()\n",
    "        labels = (self.config.processor.tokenizer.bos_token + labels + \n",
    "            self.config.processor.tokenizer.eos_token)\n",
    "        labels = self.config.processor.tokenizer(labels, is_split_into_words=False).input_ids\n",
    "        return tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "\n",
    "    def get_audio(self, sample):\n",
    "        path = os.path.join(self.args.main_dir, \"wav_cleaned\", sample)\n",
    "        audio = librosa.load(path, sr=None)[0]\n",
    "        return tf.convert_to_tensor(audio, dtype=tf.float32)\n",
    "\n",
    "    def get_shards(self):\n",
    "        skf = KFold(n_splits=self.args.n_shards, shuffle=False)\n",
    "        return [\n",
    "            list(map(lambda x: self.data['path'][x], j))\n",
    "            for _, j in skf.split(self.data['path'])]\n",
    "\n",
    "    def get_shard_data(self, samples):\n",
    "        for sample in samples:\n",
    "            audio = self.get_audio(sample)\n",
    "            labels = self.get_labels(sample)\n",
    "            yield {\n",
    "                'input_values': tf.io.serialize_tensor(audio),\n",
    "                'labels': tf.io.serialize_tensor(labels)}\n",
    "\n",
    "    def write(self):\n",
    "        for shard, samples in tqdm(enumerate(self.get_shards()), total=self.args.n_shards):\n",
    "            with tf.io.TFRecordWriter(f\"{self.args.main_dir}/wav2vec2_tfrec/shard_{shard+1}.tfrec\") as f:\n",
    "                for sample in self.get_shard_data(samples):\n",
    "                    example = self.serialize_example(\n",
    "                        sample['input_values'],\n",
    "                        sample['labels'])\n",
    "                    f.write(example)\n",
    "\n",
    "# TFRWriter(args).write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, args):\n",
    "        self.files = glob.glob(args.main_dir + \"/wav2vec2_tfrec/*.tfrec\")\n",
    "        self.args = args\n",
    "        self.AUTOTUNE = tf.data.AUTOTUNE\n",
    "        self.train_files, self.val_files = train_test_split(\n",
    "            self.files, test_size=args.test_size, shuffle=True, \n",
    "            random_state=args.random_state)\n",
    "        self.train = self.get_train()\n",
    "        self.val = self.get_val()\n",
    "\n",
    "    def read_tfrecord(self, example):\n",
    "        feature_description = {\n",
    "            'input_values': tf.io.FixedLenFeature([], tf.string),\n",
    "            'labels': tf.io.FixedLenFeature([], tf.string)}\n",
    "        \n",
    "        example = tf.io.parse_single_example(example, feature_description)\n",
    "        example['input_values'] = tf.io.parse_tensor(\n",
    "            example['input_values'], out_type=tf.float32)\n",
    "        example['labels'] = tf.io.parse_tensor(\n",
    "            example['labels'], out_type=tf.int32)\n",
    "        return example\n",
    "\n",
    "    def load_dataset(self, files):\n",
    "        ignore_order = tf.data.Options()\n",
    "        ignore_order.experimental_deterministic = False\n",
    "        dataset = tf.data.TFRecordDataset(files)\n",
    "        dataset = dataset.with_options(ignore_order)\n",
    "        dataset = dataset.map(self.read_tfrecord, num_parallel_calls=self.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    def get_train(self):\n",
    "        dataset = self.load_dataset(self.train_files)\n",
    "        dataset = dataset.padded_batch(\n",
    "            self.args.batch_size,\n",
    "            padded_shapes={\n",
    "                'input_values': [None],\n",
    "                'labels': [None]},\n",
    "            padding_values={\n",
    "                'input_values': tf.constant(0, dtype=tf.float32), \n",
    "                'labels': tf.constant(-100, dtype=tf.int32)})        \n",
    "        dataset = dataset.shuffle(self.args.buffer_size)\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    def get_val(self):\n",
    "        dataset = self.load_dataset(self.val_files)\n",
    "        dataset = dataset.padded_batch(\n",
    "            self.args.batch_size,\n",
    "            padded_shapes={\n",
    "                'input_values': [None],\n",
    "                'labels': [None]},\n",
    "            padding_values={\n",
    "                'input_values': tf.constant(0, dtype=tf.float32),\n",
    "                'labels': tf.constant(-100, dtype=tf.int32)})\n",
    "        dataset = dataset.shuffle(self.args.buffer_size)\n",
    "        dataset = dataset.cache()\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "train = DataLoader(args).train\n",
    "output = next(iter(train))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16,10))\n",
    "# for i, array in enumerate(train.take(16)):\n",
    "#     plt.subplot(4, 4, i+1)\n",
    "#     y = array['input_values'].numpy()\n",
    "#     librosa.display.waveplot(y=y, sr=16000)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PERMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"PER\", **kwargs):\n",
    "        super(PERMetric, self).__init__(name=name,  **kwargs)\n",
    "        self.accumulator = self.add_weight(name=\"total_per\", initializer=\"zeros\")\n",
    "        self.counter = self.add_weight(name=\"per_count\", initializer=\"zeros\")    \n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        hypothesis = tf.cast(tf.sparse.from_dense(y_pred), dtype=tf.int32)\n",
    "\n",
    "        # Convert dense to sparse tensor for edit_distance function\n",
    "        truth = tf.RaggedTensor.from_tensor(y_true, padding=0).to_sparse()\n",
    "\n",
    "        # Calculate Levenshtein distance\n",
    "        distance = tf.edit_distance(hypothesis, truth, normalize=True)\n",
    "\n",
    "        # Add distance and number of samples to variables\n",
    "        self.accumulator.assign_add(tf.reduce_sum(distance))\n",
    "        self.counter.assign_add(len(y_true))\n",
    "\n",
    "    def result(self):\n",
    "        # Divides accumulated distance scores against number of samples passed,\n",
    "        # mimics mean reduction over batch\n",
    "        return tf.math.divide_no_nan(self.accumulator, self.counter)   \n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.accumulator.assign(0.0)\n",
    "        self.counter.assign(0.0)\n",
    "\n",
    "class SentencesToListOfCharacters(jiwer.AbstractTransform):\n",
    "    def process_string(self, s):\n",
    "        return list(s)\n",
    "\n",
    "    def process_list(self, inp):\n",
    "        chars = []\n",
    "        for sentence in inp:\n",
    "            chars.extend(self.process_string(sentence))\n",
    "        return chars\n",
    "\n",
    "class CERMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"CER\", **kwargs):\n",
    "        super(CERMetric, self).__init__(name=name,  **kwargs)\n",
    "        self.transform = jiwer.Compose([\n",
    "            jiwer.RemoveMultipleSpaces(),\n",
    "            jiwer.Strip(),\n",
    "            SentencesToListOfCharacters(),\n",
    "            jiwer.RemoveEmptyStrings(),\n",
    "        ])\n",
    "        self.accumulator = self.add_weight(name=\"total_cer\", initializer=\"zeros\")\n",
    "        self.counter = self.add_weight(name=\"cer_count\", initializer=\"zeros\")    \n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        cer = jiwer.wer(\n",
    "            truth=y_true, hypothesis=y_pred, \n",
    "            truth_transform=self.transform, hypothesis_transform=self.transform)\n",
    "\n",
    "        # Add distance and number of samples to variables\n",
    "        self.accumulator.assign_add(cer)\n",
    "        self.counter.assign_add(1)\n",
    "\n",
    "    def result(self):\n",
    "        # Divides accumulated distance scores against number of samples passed,\n",
    "        # mimics mean reduction over batch\n",
    "        return tf.math.divide_no_nan(self.accumulator, self.counter)   \n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.accumulator.assign(0.0)\n",
    "        self.counter.assign(0.0)\n",
    "\n",
    "class CosineDecayWithWarmup(LearningRateSchedule):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "    def __call__(self, epoch):  \n",
    "        if epoch < self.args.warmup_epochs:\n",
    "            lr = ((self.args.lr_max - self.args.lr_start) / self.args.warmup_epochs) * epoch + self.args.lr_start\n",
    "        elif epoch < (self.args.warmup_epochs + self.args.sustain_epochs):\n",
    "            lr = self.args.lr_max\n",
    "        else:\n",
    "            progress = ((epoch - self.args.warmup_epochs - self.args.sustain_epochs) / \n",
    "            (self.args.epochs - self.args.warmup_epochs - self.args.sustain_epochs))\n",
    "            lr = (self.args.lr_max-self.args.lr_min) * (0.5 * (1.0 + tf.math.cos((22/7) * \n",
    "                self.args.n_cycles * 2.0 * progress)))\n",
    "            if self.args.lr_min is not None:\n",
    "                lr = tf.math.maximum(self.args.lr_min, lr)\n",
    "        return lr\n",
    "\n",
    "    def plot(self):\n",
    "        epochs = range(self.args.epochs+1)\n",
    "        lr = [self(epoch) for epoch in epochs]\n",
    "        plt.plot(epochs, lr)\n",
    "        plt.xlabel(\"learning_rate\")\n",
    "        plt.ylabel(\"epochs\")\n",
    "        plt.show()\n",
    "\n",
    "CosineDecayWithWarmup(args).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.config = Config(args)\n",
    "        self.train_dataset = DataLoader(args).train\n",
    "        self.val_dataset = DataLoader(args).val\n",
    "        schedule = CosineDecayWithWarmup(args)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(schedule)\n",
    "        self.per_metrics = PERMetric()\n",
    "        self.cer_metrics = CERMetric()\n",
    "        self.model = TFWav2Vec2ForCTC.from_pretrained(\n",
    "            args.model_name,\n",
    "            from_pt=True,\n",
    "            ctc_loss_reduction=\"mean\",\n",
    "            gradient_checkpointing=True,\n",
    "            pad_token_id=self.config.processor.tokenizer.pad_token_id,\n",
    "            vocab_size=len(self.config.processor.tokenizer))\n",
    "        self.model.freeze_feature_extractor()\n",
    "        \n",
    "        self.model_name = f\"model_{int(self.args.n_samples/1000)}k_v1\"\n",
    "        self.log_path = f\"{self.args.main_dir}/model_weights/{self.model_name}.csv\"\n",
    "        if not os.path.exists(self.log_path):\n",
    "            print(\"Log file created.\")\n",
    "            columns = \"epoch,loss,per,cer,val_loss,val_per,val_cer\\n\"\n",
    "            with open(self.log_path, \"a\") as f:\n",
    "                f.write(columns)\n",
    "\n",
    "    def group_tokens(self, text):\n",
    "        new_text = []\n",
    "        doubles = ['t', 'k', 'p', 's']\n",
    "        for token, group in groupby(text):\n",
    "            group = list(group)\n",
    "            if group[0] in doubles:\n",
    "                token = \"\".join(group[:2])\n",
    "            new_text.append(token)\n",
    "        return Romaji2Kana(\"\".join(new_text))\n",
    "    \n",
    "    def decoder(self, labels, logits):\n",
    "        labels = self.config.processor.batch_decode(\n",
    "            labels, skip_special_tokens=True, group_tokens=False)\n",
    "        labels = list(map(Romaji2Kana, labels))\n",
    "        logits = self.config.processor.batch_decode(\n",
    "            logits, skip_special_tokens=True, group_tokens=False)\n",
    "        logits = list(map(self.group_tokens, logits))\n",
    "        return labels, logits\n",
    "\n",
    "    def display(self, t_labels, t_logits, v_labels, v_logits):       \n",
    "        print(\"-\" * 129)\n",
    "        print(\"Training\")\n",
    "        for y_true, y_pred in zip(t_labels, t_logits):\n",
    "            print(f\"Target:    {y_true}\")\n",
    "            print(f\"Predicted: {y_pred}\") \n",
    "\n",
    "        print(\"\\nValidation\")\n",
    "        for y_true, y_pred in zip(v_labels, v_logits):\n",
    "            print(f\"Target:    {y_true}\")\n",
    "            print(f\"Predicted: {y_pred}\")\n",
    "        print(\"-\" * 129)\n",
    "\n",
    "    def fit(self):\n",
    "        # Checkpoint manager\n",
    "        self.ckpt_dir = f\"{self.args.main_dir}/checkpoints\"\n",
    "        self.ckpt = tf.train.Checkpoint(self.model)\n",
    "        self.ckpt_manager = tf.train.CheckpointManager(\n",
    "            checkpoint=self.ckpt, directory=self.ckpt_dir, max_to_keep=5)\n",
    "\n",
    "        if self.ckpt_manager.latest_checkpoint:\n",
    "            self.start_epoch = int(self.ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
    "            self.ckpt.restore(self.ckpt_manager.latest_checkpoint)\n",
    "            print(f\"Resuming from epoch {self.start_epoch + 1}...\")\n",
    "        else:\n",
    "            self.start_epoch = 0\n",
    "            print(\"Starting from epoch 1...\")\n",
    "\n",
    "        for epoch in range(self.start_epoch, self.args.epochs+1):\n",
    "            print(f\"Epoch {epoch+1}/{self.args.epochs}: Learning rate @ {self.optimizer.lr(epoch):.2e}\")\n",
    "            stateful_metrics = [\"loss\", \"per\", \"cer\", \"val_loss\", \"val_per\", \"val_cer\"]\n",
    "            progbar = tf.keras.utils.Progbar(\n",
    "                self.args.train_steps, interval=0.05,\n",
    "                stateful_metrics=stateful_metrics)\n",
    "\n",
    "            # Training loop\n",
    "            for step, t_batch in enumerate(self.train_dataset):\n",
    "                t_inputs = t_batch['input_values']\n",
    "                t_labels = t_batch['labels']\n",
    "                with tf.GradientTape() as tape:\n",
    "                    t_loss, t_logits = self.model(\n",
    "                        input_values=t_inputs, labels=t_labels, training=True)[:2]\n",
    "                gradients = tape.gradient(t_loss, self.model.trainable_weights)  \n",
    "                self.optimizer.apply_gradients(zip(gradients, self.model.trainable_weights))  \n",
    "                t_labels = tf.where(t_labels == -100, x=0, y=t_labels)\n",
    "                t_logits = tf.argmax(t_logits, axis=-1)\n",
    "                self.per_metrics.update_state(t_labels, t_logits)\n",
    "                t_labels, t_logits = self.decoder(t_labels, t_logits)\n",
    "                self.cer_metrics.update_state(t_labels, t_logits) \n",
    "                t_per = self.per_metrics.result()\n",
    "                t_cer = self.cer_metrics.result()\n",
    "                t_values = [(\"loss\", t_loss), (\"per\", t_per), (\"cer\", t_cer)]\n",
    "                progbar.update(step, values=t_values, finalize=False)\n",
    "            self.per_metrics.reset_states()\n",
    "            self.cer_metrics.reset_states()\n",
    "            \n",
    "            # Validation loop\n",
    "            for v_batch in self.val_dataset:\n",
    "                v_inputs = v_batch['input_values']\n",
    "                v_labels = v_batch['labels']\n",
    "                v_loss, v_logits = self.model(\n",
    "                    input_values=v_inputs, labels=v_labels, training=False)[:2]  \n",
    "                v_labels = tf.where(v_labels == -100, x=0, y=v_labels)\n",
    "                v_logits = tf.argmax(v_logits, axis=-1)     \n",
    "                self.per_metrics.update_state(v_labels, v_logits)\n",
    "                v_labels, v_logits = self.decoder(v_labels, v_logits)         \n",
    "                self.cer_metrics.update_state(v_labels, v_logits)\n",
    "\n",
    "            v_per = self.per_metrics.result()\n",
    "            v_cer = self.cer_metrics.result()\n",
    "            v_values = [\n",
    "                (\"loss\", t_loss), (\"per\", t_per), (\"cer\", t_cer), (\"val_loss\", v_loss),\n",
    "                (\"val_per\", v_per), (\"val_cer\", v_cer)]\n",
    "            progbar.update(self.args.train_steps, values=v_values, finalize=True)\n",
    "            self.per_metrics.reset_states()\n",
    "            self.cer_metrics.reset_states()\n",
    "\n",
    "            # Print sample transcriptions for both loops\n",
    "            self.display(t_labels, t_logits, v_labels, v_logits)\n",
    "\n",
    "            # Checkpointing\n",
    "            self.ckpt.save(file_prefix=f\"{self.ckpt_dir}/{self.model_name}\")\n",
    "\n",
    "            # Logging\n",
    "            log = f\"{epoch+1},{t_loss},{t_per},{t_cer},{v_loss},{v_per},{v_cer}\\n\"\n",
    "            with open(self.log_path, \"a\") as f:\n",
    "                f.write(log)\n",
    "\n",
    "            save_path = f\"{self.args.main_dir}/model_weights\"\n",
    "            self.model.save_weights(f\"{save_path}/{self.model_name}_{epoch+1}.h5\")\n",
    "\n",
    "# Trainer(args).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv(\"E:\\Datasets\\Acoustic_model\\model_weights\\model_50k_v1.csv\", index_col='epoch')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=history.index, y=history['per'], label=\"per\", ax=ax1)\n",
    "sns.lineplot(x=history.index, y=history['cer'], label=\"cer\", ax=ax2)\n",
    "sns.lineplot(x=history.index, y=history['val_per'], label=\"val_per\", ax=ax1)\n",
    "sns.lineplot(x=history.index, y=history['val_cer'], label=\"val_cer\", ax=ax2)\n",
    "ax2.axvline(x=9, ymin=0, ymax=0.05, color='red', linestyle=\"--\")\n",
    "plt.suptitle(\"Acoustic model\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b851d2923cfa3a2562599062e05fd9893d86a7c009c64d8ad3756552e4dd5f41"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tf-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
