{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import re\r\n",
    "import glob\r\n",
    "import json\r\n",
    "import random\r\n",
    "import argparse\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import librosa\r\n",
    "import soundfile as sf\r\n",
    "\r\n",
    "from tqdm import tqdm\r\n",
    "import subprocess\r\n",
    "from functools import partial\r\n",
    "from collections import Counter\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "import MeCab\r\n",
    "import cutlet\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split, KFold\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from dataclasses import dataclass, field\r\n",
    "from typing import Any, Dict, List, Optional, Union\r\n",
    "\r\n",
    "from transformers import (\r\n",
    "    Wav2Vec2Config,\r\n",
    "    TFWav2Vec2Model,\r\n",
    "    Wav2Vec2CTCTokenizer, \r\n",
    "    Wav2Vec2FeatureExtractor,\r\n",
    "    Wav2Vec2Processor)\r\n",
    "\r\n",
    "from transformers.modeling_tf_outputs import (\r\n",
    "    TFCausalLMOutput\r\n",
    ")\r\n",
    "\r\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def seed_everything(SEED):\r\n",
    "    random.seed(SEED)\r\n",
    "    np.random.seed(SEED)\r\n",
    "    tf.random.set_seed(SEED)\r\n",
    "    print(\"Random seed set.\")\r\n",
    "\r\n",
    "def ArgParser():\r\n",
    "    parser = argparse.ArgumentParser()\r\n",
    "\r\n",
    "    # DataLoader\r\n",
    "    parser.add_argument(\"--main_dir\", default=\"E://Datasets/ASR-dataset\")\r\n",
    "    parser.add_argument(\"--sample_rate\", default=16000)\r\n",
    "    parser.add_argument(\"--test_size\", default=0.2)\r\n",
    "    parser.add_argument(\"--random_state\", default=42)\r\n",
    "    parser.add_argument(\"--batch_size\", default=4)\r\n",
    "    parser.add_argument(\"--n_shards\", default=20)\r\n",
    "    parser.add_argument(\"--buffer_size\", default=512)\r\n",
    "\r\n",
    "    # Trainer\r\n",
    "    parser.add_argument(\"--model_name\", default=\"facebook/wav2vec2-base-960h\")\r\n",
    "    parser.add_argument(\"--epochs\", default=30)\r\n",
    "    parser.add_argument(\"--learning_rate\", default=3e-4)\r\n",
    "    parser.add_argument(\"--vocab_size\", default=37)\r\n",
    "\r\n",
    "    args = parser.parse_known_args()[0]\r\n",
    "\r\n",
    "    input_shape = (args.max_samples)\r\n",
    "    parser.add_argument(\"--input_shape\", default=input_shape)\r\n",
    "\r\n",
    "    seed_everything(args.random_state)\r\n",
    "    return parser.parse_known_args()[0]\r\n",
    "\r\n",
    "args = ArgParser()\r\n",
    "args"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random seed set.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Namespace(batch_size=4, buffer_size=512, epochs=30, input_shape=150000, learning_rate=0.0003, main_dir='E://Datasets/ASR-dataset', max_labels=150, max_samples=150000, model_name='facebook/wav2vec2-base-960h', n_shards=20, random_state=42, sample_rate=16000, test_size=0.2, vocab_size=37)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "class Dataset:\r\n",
    "    def __init__(self, args):\r\n",
    "        self.args = args\r\n",
    "        self.data = pd.concat([\r\n",
    "            self.get_kokoro(),\r\n",
    "            self.get_jsut(),\r\n",
    "            self.get_commonvoice()], \r\n",
    "            ignore_index=True)\r\n",
    "        self.katsu = cutlet.Cutlet()\r\n",
    "        self.wakati = MeCab.Tagger(\"-Owakati\")\r\n",
    "        tqdm.pandas()\r\n",
    "        self.data['sentence'] = self.data['sentence'].progress_apply(self.clean_kanji)\r\n",
    "        self.data['romaji'] = self.data['sentence'].progress_apply(self.katsu.romaji)\r\n",
    "        self.data['romaji'] = self.data['romaji'].progress_apply(self.clean_romaji)\r\n",
    "        self.data['romaji'] = self.data['romaji'].str.lower()\r\n",
    "        self.data['length'] = self.data['path'].progress_apply(self.get_length)\r\n",
    "        self.data.query(\"(length >= 32000) & (length <= 150000)\", inplace=True)\r\n",
    "        self.data = self.data[self.data['sentence'].apply(list).apply(len)>=5]\r\n",
    "        self.data = self.data.dropna().reset_index(drop=True)\r\n",
    "        self.data.sort_values(by=\"length\", axis=0, inplace=True, ignore_index=True)\r\n",
    "        self.data.to_csv(f\"{self.args.main_dir}/ASRDataset.csv\", encoding=\"utf-8\", index=False)\r\n",
    "\r\n",
    "    def get_kokoro(self):\r\n",
    "        in_dir = \"Datasets\\Full-KOKORO-dataset\"\r\n",
    "\r\n",
    "        data = []\r\n",
    "        transcript_path = f\"{in_dir}/transcripts/*.metadata.txt\"\r\n",
    "        for transcript in glob.glob(transcript_path):\r\n",
    "            with open(transcript, \"r\", encoding=\"utf-8\") as f:\r\n",
    "                for line in f.readlines():\r\n",
    "                    data.append(line.split(\"|\"))\r\n",
    "\r\n",
    "        data = pd.DataFrame(\r\n",
    "            data, columns=[\r\n",
    "                'text_id', 'path', 'start_idx', \r\n",
    "                'end_idx', 'sentence', 'phonemes'])       \r\n",
    "\r\n",
    "        # paths = data['path'].unique()\r\n",
    "        # for path in tqdm(paths, total=len(paths)):\r\n",
    "        #     folder_name = path.split(\"_\", 1)[0]\r\n",
    "        #     in_path = os.path.join(in_dir, folder_name, path)\r\n",
    "        #     y, sr = librosa.load(in_path, sr=None)\r\n",
    "        #     for text_id in data.loc[data['path']==path, 'text_id']:\r\n",
    "        #         out_path = os.path.join(self.args.main_dir, 'wav_cleaned', text_id) + \".wav\"\r\n",
    "        #         if not os.path.exists(out_path):\r\n",
    "        #             start_idx = int(data.loc[data['text_id']==text_id, 'start_idx'].item())\r\n",
    "        #             end_idx = int(data.loc[data['text_id']==text_id, 'end_idx'].item())\r\n",
    "        #             y_slice = librosa.resample(\r\n",
    "        #                 y[start_idx:end_idx], orig_sr=sr, target_sr=self.args.sample_rate)\r\n",
    "        #             sf.write(out_path, y_slice, samplerate=self.args.sample_rate, subtype='PCM_16')\r\n",
    "\r\n",
    "        data = data[['text_id', 'sentence']]\r\n",
    "        data['text_id'] = data['text_id'].apply(lambda x: x + \".wav\")\r\n",
    "        data.columns = ['path', 'sentence']\r\n",
    "        data['corpus'] = ['kokoro'] * len(data)\r\n",
    "        return data\r\n",
    "\r\n",
    "    def get_jsut(self):\r\n",
    "        filenames, sentences = [], []\r\n",
    "        for transcript in glob.glob(r\"Datasets/JSUT-dataset/*/transcript_utf8.txt\"):\r\n",
    "            file_path = transcript.rsplit(\"\\\\\", 1)[0]\r\n",
    "            with open(transcript, \"r\", encoding=\"utf-8\") as f:\r\n",
    "                lines = f.readlines()\r\n",
    "                for line in lines: \r\n",
    "                    filename, sentence = line.split(\":\")\r\n",
    "                    filenames.append(os.path.join(file_path, \"wav\", filename) + \".wav\")\r\n",
    "                    sentences.append(sentence.strip(\"\\n\"))\r\n",
    "        data = pd.DataFrame({'path': filenames, 'sentence': sentences}) \r\n",
    "        data['corpus'] = ['jsut'] * len(data)\r\n",
    "        for i, in_path in tqdm(enumerate(data['path']), total=len(data['path'])):\r\n",
    "            in_path = in_path.replace(\"\\\\\", \"/\")\r\n",
    "            out_path = f\"{self.args.main_dir}\\wav_cleaned\"\r\n",
    "            filename = in_path.rsplit(\"/\", 1)[-1]\r\n",
    "            out_path = os.path.join(out_path, filename)\r\n",
    "            if not os.path.exists(out_path):\r\n",
    "                subprocess.call([\r\n",
    "                    \"ffmpeg\", \"-i\", in_path,\"-acodec\", \"pcm_s16le\", \r\n",
    "                    \"-ar\", str(self.args.sample_rate), out_path])\r\n",
    "            data['path'][i] = filename\r\n",
    "        return data \r\n",
    "\r\n",
    "    def get_commonvoice(self):\r\n",
    "        data = pd.read_csv(r\"Datasets/CommonVoice-dataset/validated.tsv\", sep=\"\\t\")\r\n",
    "        data = data[['path', 'sentence']]    \r\n",
    "        data['path'] = data['path'].apply(\r\n",
    "            lambda x: r\"Datasets/CommonVoice-dataset/mp3/\" + x)\r\n",
    "        data['corpus'] = ['common_voice'] * len(data)\r\n",
    "        for i, in_path in tqdm(enumerate(data['path']), total=len(data['path'])):\r\n",
    "            in_path = in_path.replace(\"\\\\\", \"/\")\r\n",
    "            out_path = f\"{self.args.main_dir}\\wav_cleaned\"\r\n",
    "            filename = in_path.rsplit(\"/\", 1)[-1]\r\n",
    "            filename = filename.replace(\"mp3\", \"wav\")\r\n",
    "            out_path = os.path.join(out_path, filename)\r\n",
    "            if not os.path.exists(out_path):\r\n",
    "                subprocess.call([\r\n",
    "                    \"ffmpeg\", \"-i\", in_path,\"-acodec\", \"pcm_s16le\", \r\n",
    "                    \"-ar\", str(self.args.sample_rate), out_path])\r\n",
    "            data['path'][i] = filename       \r\n",
    "        return data\r\n",
    "\r\n",
    "    def clean_kanji(self, sentence):\r\n",
    "        symbols = r\"[（.*?）！-～.,;..._。、-〿・■（）：ㇰ-ㇿ㈠-㉃㊀-㋾㌀-㍿「」『』→ー -~‘–※π—ゐ’“”]\"\r\n",
    "        sentence = re.sub(symbols, \"\", sentence)\r\n",
    "        sentence = self.wakati.parse(sentence).strip(\"\\n\")          \r\n",
    "        return sentence\r\n",
    "\r\n",
    "    def clean_romaji(self, sentence):\r\n",
    "        return re.sub(r'[.,\"\\'\\/?]', \"\", sentence)\r\n",
    "\r\n",
    "    def get_length(self, path):\r\n",
    "        path = os.path.join(args.main_dir, 'wav_cleaned', path)\r\n",
    "        y, sr = librosa.load(path, sr=None)\r\n",
    "        return len(y)\r\n",
    "\r\n",
    "data = Dataset(args).data\r\n",
    "data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 7696/7696 [00:01<00:00, 4110.78it/s]\n",
      "100%|██████████| 21026/21026 [00:06<00:00, 3253.73it/s]\n",
      "100%|██████████| 71975/71975 [00:01<00:00, 47607.47it/s]\n",
      " 19%|█▉        | 13734/71975 [00:02<00:11, 4855.34it/s]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10, 3))\r\n",
    "sns.histplot(x=data['length'], hue=data['corpus'], ax=ax, palette=\"bright\")\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Config:\r\n",
    "    def __init__(self, args):\r\n",
    "        self.tokenizer = Wav2Vec2CTCTokenizer(\r\n",
    "            f\"{args.main_dir}/vocab.json\",\r\n",
    "            word_delimiter_token=' ',\r\n",
    "            do_lower_case=False)\r\n",
    "\r\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\r\n",
    "            args.model_name)\r\n",
    "\r\n",
    "        self.processor = Wav2Vec2Processor(\r\n",
    "            feature_extractor=self.feature_extractor, \r\n",
    "            tokenizer=self.tokenizer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class TFRWriter():\r\n",
    "    def __init__(self, args):\r\n",
    "        self.data = pd.read_csv(os.path.join(args.main_dir, \"ASRDataset.csv\"))\r\n",
    "        self.args = args\r\n",
    "        self.processor = Config(args).processor\r\n",
    "\r\n",
    "    def _bytes_feature(self, value):\r\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n",
    "        if isinstance(value, type(tf.constant(0))):\r\n",
    "            value = value.numpy()\r\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n",
    "\r\n",
    "    def _int64_feature(self, value):\r\n",
    "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\r\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n",
    "\r\n",
    "    def serialize_example(self, *args):\r\n",
    "        feature = {\r\n",
    "            'input_values': self._bytes_feature(args[0]),\r\n",
    "            'input_length': self._int64_feature(args[1]),\r\n",
    "            'label_ids': self._bytes_feature(args[2]),\r\n",
    "            'label_length': self._int64_feature(args[3])}\r\n",
    "\r\n",
    "        example_proto = tf.train.Example(\r\n",
    "            features=tf.train.Features(feature=feature))\r\n",
    "        return example_proto.SerializeToString()\r\n",
    "\r\n",
    "    def get_labels(self, sample):\r\n",
    "        labels = self.data.loc[self.data['path']==sample, \"romaji\"].item()\r\n",
    "        labels = (self.processor.tokenizer.bos_token + labels + \r\n",
    "            self.processor.tokenizer.eos_token)\r\n",
    "        labels = self.processor.tokenizer(\r\n",
    "            labels)['input_ids'][:self.args.max_labels]\r\n",
    "        label_length = len(labels)\r\n",
    "        return (\r\n",
    "            tf.convert_to_tensor(labels, dtype=tf.int32),\r\n",
    "            tf.convert_to_tensor(label_length, dtype=tf.int32)\r\n",
    "        )\r\n",
    "\r\n",
    "    def get_audio(self, sample):\r\n",
    "        path = os.path.join(self.args.main_dir, \"wav_cleaned\", sample)\r\n",
    "        audio = librosa.load(path, sr=None)[0]\r\n",
    "        return tf.convert_to_tensor(audio, dtype=tf.float32)\r\n",
    "\r\n",
    "    def get_shards(self):\r\n",
    "        skf = KFold(n_splits=self.args.n_shards, shuffle=False)\r\n",
    "        return [\r\n",
    "            list(map(lambda x: self.data['path'][x], j))\r\n",
    "            for i, j in skf.split(self.data['path'])\r\n",
    "        ]\r\n",
    "\r\n",
    "    def get_shard_data(self, samples):\r\n",
    "        longest_length = self.data.loc[self.data['path'].isin(samples), 'length'].max()\r\n",
    "        for sample in samples:\r\n",
    "            audio = self.get_audio(sample)\r\n",
    "            labels, label_length = self.get_labels(sample)\r\n",
    "            audio_length = self.data.loc[self.data['path']==sample, \"length\"].item()\r\n",
    "            yield {\r\n",
    "                'input_values': tf.io.serialize_tensor(audio),\r\n",
    "                'input_length': audio_length,\r\n",
    "                'label_ids': tf.io.serialize_tensor(labels),\r\n",
    "                'label_length': label_length\r\n",
    "            }\r\n",
    "\r\n",
    "    def write(self):\r\n",
    "        for shard, samples in tqdm(enumerate(self.get_shards()), total=self.args.n_shards):\r\n",
    "            with tf.io.TFRecordWriter(f\"{self.args.main_dir}/tfrec_data/shard_{shard+1}.tfrec\") as f:\r\n",
    "                for sample in self.get_shard_data(samples):\r\n",
    "                    example = self.serialize_example(\r\n",
    "                        sample['input_values'], sample['input_length'],\r\n",
    "                        sample['label_ids'], sample['label_length'])\r\n",
    "                    f.write(example)\r\n",
    "\r\n",
    "# TFRWriter(args).write()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [20:50<00:00, 62.53s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class DataLoader:\r\n",
    "    def __init__(self, args):\r\n",
    "        self.files = glob.glob(args.main_dir + \"/tfrec_data/*.tfrec\")\r\n",
    "        self.args = args\r\n",
    "        self.AUTOTUNE = tf.data.AUTOTUNE\r\n",
    "        self.train_files, self.val_files = train_test_split(\r\n",
    "            self.files, test_size=args.test_size, shuffle=True, \r\n",
    "            random_state=args.random_state)\r\n",
    "        self.train = self.train()\r\n",
    "        self.val = self.val()\r\n",
    "   \r\n",
    "    def read_tfrecord(self, example):\r\n",
    "        feature_description = {\r\n",
    "            'input_values': tf.io.FixedLenFeature([], tf.string),\r\n",
    "            'input_length': tf.io.FixedLenFeature([], tf.int64),\r\n",
    "            'label_ids': tf.io.FixedLenFeature([], tf.string),\r\n",
    "            'label_length': tf.io.FixedLenFeature([], tf.int64)}\r\n",
    "        \r\n",
    "        example = tf.io.parse_single_example(example, feature_description)\r\n",
    "        example['input_values'] = tf.io.parse_tensor(\r\n",
    "            example['input_values'], out_type=tf.float32)\r\n",
    "        example['label_ids'] = tf.io.parse_tensor(\r\n",
    "            example['label_ids'], out_type=tf.int32)\r\n",
    "        example['input_length'] = tf.cast(example['input_length'], dtype=tf.int32)\r\n",
    "        example['label_length'] = tf.cast(example['label_length'], dtype=tf.int32)\r\n",
    "        return example\r\n",
    "\r\n",
    "    def load_dataset(self, files):\r\n",
    "        ignore_order = tf.data.Options()\r\n",
    "        ignore_order.experimental_deterministic = False\r\n",
    "        dataset = tf.data.TFRecordDataset(files)\r\n",
    "        dataset = dataset.with_options(ignore_order)\r\n",
    "        dataset = dataset.map(self.read_tfrecord, num_parallel_calls=self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "    \r\n",
    "    def split(self, dataset):\r\n",
    "        return (\r\n",
    "            {\r\n",
    "                \"input_values\": dataset[\"input_values\"],\r\n",
    "                \"input_length\": dataset[\"input_length\"] \r\n",
    "            },\r\n",
    "            {\r\n",
    "                \"label_ids\": dataset[\"label_ids\"],\r\n",
    "                \"label_length\": dataset[\"label_length\"]\r\n",
    "            }\r\n",
    "        )\r\n",
    "\r\n",
    "    def train(self):\r\n",
    "        dataset = self.load_dataset(self.train_files)\r\n",
    "        dataset = dataset.padded_batch(\r\n",
    "            self.args.batch_size,\r\n",
    "            padded_shapes={\r\n",
    "                'input_values': [None],\r\n",
    "                'input_length': [],\r\n",
    "                'label_ids': [None],\r\n",
    "                'label_length': []},\r\n",
    "            padding_values={\r\n",
    "                'input_values': tf.constant(0, dtype=tf.float32), \r\n",
    "                'input_length': None,\r\n",
    "                'label_ids': tf.constant(-100, dtype=tf.int32),\r\n",
    "                'label_length': None})\r\n",
    "        dataset = dataset.map(self.split, num_parallel_calls=self.AUTOTUNE)\r\n",
    "        dataset = dataset.shuffle(self.args.buffer_size)\r\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "\r\n",
    "    def val(self):\r\n",
    "        dataset = self.load_dataset(self.val_files)\r\n",
    "        dataset = dataset.padded_batch(\r\n",
    "            self.args.batch_size,\r\n",
    "            padded_shapes={\r\n",
    "                'input_values': [None],\r\n",
    "                'input_length': [],\r\n",
    "                'label_ids': [None],\r\n",
    "                'label_length': []},\r\n",
    "            padding_values={\r\n",
    "                'input_values': tf.constant(0, dtype=tf.float32), \r\n",
    "                'input_length': None,\r\n",
    "                'label_ids': tf.constant(-100, dtype=tf.int32),\r\n",
    "                'label_length': None})\r\n",
    "        dataset = dataset.map(self.split, num_parallel_calls=self.AUTOTUNE)\r\n",
    "        dataset = dataset.cache()\r\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\r\n",
    "        return dataset"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "({'input_values': <tf.Tensor: shape=(4, 98267), dtype=float32, numpy=\n",
      "array([[ 3.0517578e-05, -6.1035156e-05, -1.8310547e-04, ...,\n",
      "         3.0517578e-05,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-6.1035156e-05, -1.5258789e-04, -2.1362305e-04, ...,\n",
      "         6.1035156e-05,  3.0517578e-05,  0.0000000e+00],\n",
      "       [-6.1035156e-05,  0.0000000e+00,  6.1035156e-05, ...,\n",
      "         6.1035156e-05,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 0.0000000e+00,  3.0517578e-05,  3.0517578e-05, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, 'input_length': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([98267, 98267, 98267, 98267])>}, {'label_ids': <tf.Tensor: shape=(4, 103), dtype=int32, numpy=\n",
      "array([[   1,   12,    6,   11,    7,    6,    4,   19,    5,    4,   15,\n",
      "           6,   13,   10,    4,   19,    6,    4,   22,    7,   11,    7,\n",
      "          17,    5,   16,    7,   12,    5,    4,    6,    9,    9,    5,\n",
      "           4,    9,    6,    4,    9,    5,   23,    8,   11,    5,   16,\n",
      "           7,    7,    4,    5,   21,    8,   13,    5,    4,    9,    6,\n",
      "           4,    9,    7,    6,    7,    4,   12,    6,    4,    5,   15,\n",
      "          10,    4,    9,    6,    4,    9,    7,    6,    7,    4,   12,\n",
      "           6,    4,   18,    5,    4,    7,    7,    2, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100],\n",
      "       [   1,   11,    5,   11,   10,    6,   25,    7,    4,   14,    6,\n",
      "           9,    6,    4,    9,    7,    4,    9,    5,   13,    8,    4,\n",
      "          20,    6,   13,    7,    4,   22,    6,   11,    5,    4,    9,\n",
      "           7,   16,    7,   11,    5,   12,    5,    4,   18,    5,    4,\n",
      "           9,    5,    7,   24,    5,    4,    9,    5,    7,    4,   11,\n",
      "           5,    4,    6,   25,    7,   23,    8,   11,   10,    9,    5,\n",
      "           7,    4,    9,    6,    4,   19,    5,    4,   11,    7,   14,\n",
      "           7,    4,   21,    5,   11,    5,   13,    7,    4,   24,    5,\n",
      "           4,    9,    5,    7,    2, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100],\n",
      "       [   1,   12,    6,   11,    6,   13,    6,    4,   18,    5,    4,\n",
      "          17,    5,   13,   10,    4,   14,    6,    4,   11,    8,   25,\n",
      "           7,    4,   19,    6,    4,   22,    7,   13,    5,   11,    8,\n",
      "           4,   14,    6,    9,    6,    4,   18,    5,    4,    9,    5,\n",
      "           7,    4,   22,    5,   11,    8,   21,    8,   23,    8,    4,\n",
      "           9,    6,   29,    6,    8,   16,    7,    4,   19,    5,    4,\n",
      "          17,    5,    7,    7,   25,    7,   29,    6,    8,   24,    6,\n",
      "           8,    4,    9,    6,    4,   20,    5,    9,   10,    4,    9,\n",
      "           7,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100],\n",
      "       [   1,   14,    5,   17,    5,    4,   10,   17,    6,    4,   12,\n",
      "           6,    4,    7,   12,   12,    5,    4,   24,    7,   21,    8,\n",
      "           9,    4,    9,    6,    4,    7,   25,    7,   18,    5,   20,\n",
      "           5,    4,   17,   10,    4,    8,   14,    5,   13,   10,   12,\n",
      "           5,    4,    6,    9,    9,    5,    4,    9,    5,    4,    9,\n",
      "           6,    4,   17,   10,    4,    6,   11,    8,   15,    5,    9,\n",
      "           4,   19,    5,    4,   24,    6,    8,   17,    5,    9,    4,\n",
      "          22,    5,    9,   21,    8,    9,    4,   15,    6,    8,    4,\n",
      "           7,   12,   12,    5,    4,    9,    6,    4,   17,   10,    4,\n",
      "           5,   13,    8,    2]])>, 'label_length': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 85,  93,  90, 103])>})\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class TFWav2Vec2ForCTC(tf.keras.Model):\r\n",
    "    def __init__(self, args):\r\n",
    "        super(TFWav2Vec2ForCTC, self).__init__()\r\n",
    "        self.args = args\r\n",
    "        self.config = Wav2Vec2Config.from_pretrained(\r\n",
    "            args.model_name, vocab_size=args.vocab_size,\r\n",
    "            output_hidden_states=True)\r\n",
    "        self.base_layer = TFWav2Vec2Model.from_pretrained(\r\n",
    "            args.model_name, config=self.config, name=\"wav2vec2\")\r\n",
    "        self.dropout = tf.keras.layers.Dropout(0.1, name=\"dropout\")\r\n",
    "        self.lm_head = tf.keras.layers.Dense(\r\n",
    "            args.vocab_size, activation=\"softmax\", name=\"lm_head\")\r\n",
    "\r\n",
    "    def call(self, inputs, labels, training):\r\n",
    "        outputs = self.base_layer(input_values=inputs['input_values'])\r\n",
    "        x = outputs.last_hidden_state\r\n",
    "        x = self.dropout(x, training)\r\n",
    "        logits = self.lm_head(x)\r\n",
    "        \r\n",
    "        if labels is not None:\r\n",
    "            if tf.reduce_max(labels['label_ids']) >= self.config.vocab_size:\r\n",
    "                raise ValueError(f\"Label values must be <= vocab_size: {self.config.vocab_size}\")\r\n",
    "    \r\n",
    "            loss = tf.nn.ctc_loss(\r\n",
    "                logits=logits,\r\n",
    "                labels=labels['label_ids'],\r\n",
    "                logit_length=inputs['input_length'],\r\n",
    "                label_length=labels['label_length'],\r\n",
    "                blank_index=self.config.pad_token_id,\r\n",
    "                logits_time_major=False\r\n",
    "            )\r\n",
    "            \r\n",
    "            if self.config.ctc_loss_reduction == \"sum\":\r\n",
    "                loss = tf.reduce_sum(loss)\r\n",
    "            elif self.config.ctc_loss_reduction == \"mean\":\r\n",
    "                loss = tf.reduce_mean(loss)\r\n",
    "            else:\r\n",
    "                raise ValueError(f\"ctc_loss_reduction must be either sum or mean.\")\r\n",
    "        else:\r\n",
    "            loss = None\r\n",
    "                        \r\n",
    "        return TFCausalLMOutput(\r\n",
    "            loss=loss,\r\n",
    "            logits=logits,\r\n",
    "            hidden_states=outputs.hidden_states,\r\n",
    "            attentions=outputs.attentions)\r\n",
    "\r\n",
    "    def serving_output(self, output: TFCausalLMOutput) -> TFCausalLMOutput:\r\n",
    "        if self.config.output_hidden_states:\r\n",
    "            hs = tf.convert_to_tensor(output.hidden_states)\r\n",
    "        else:\r\n",
    "            hs = None\r\n",
    "        if self.config.output_attentions:\r\n",
    "            attns = tf.convert_to_tensor(output.attentions)\r\n",
    "        else:\r\n",
    "            attns = None\r\n",
    "        \r\n",
    "        return TFCausalLMOutput(\r\n",
    "            logits=output.logits, hidden_states=hs, attentions=attns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some layers from the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing TFWav2Vec2Model: ['dropout_50', 'lm_head']\n",
      "- This IS expected if you are initializing TFWav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFWav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFWav2Vec2Model were initialized from the model checkpoint at facebook/wav2vec2-base-960h.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFWav2Vec2Model for predictions without further training.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TFCausalLMOutput(loss=<tf.Tensor: shape=(), dtype=float32, numpy=3327.6733>, logits=<tf.Tensor: shape=(4, 300, 37), dtype=float32, numpy=\n",
       "array([[[0.02022143, 0.03404899, 0.03513526, ..., 0.04620755,\n",
       "         0.04047517, 0.01683033],\n",
       "        [0.02023644, 0.03418202, 0.03534433, ..., 0.04626592,\n",
       "         0.04071999, 0.01663663],\n",
       "        [0.02049548, 0.0344748 , 0.0350819 , ..., 0.04604213,\n",
       "         0.04065494, 0.01681461],\n",
       "        ...,\n",
       "        [0.02002366, 0.03326676, 0.03247846, ..., 0.04860095,\n",
       "         0.03537069, 0.01772717],\n",
       "        [0.02026852, 0.03218693, 0.0346241 , ..., 0.04436938,\n",
       "         0.04196112, 0.01634735],\n",
       "        [0.02034456, 0.03194546, 0.03485507, ..., 0.04412682,\n",
       "         0.04173673, 0.01638306]],\n",
       "\n",
       "       [[0.02305269, 0.03395809, 0.03489815, ..., 0.04970449,\n",
       "         0.03807245, 0.0180183 ],\n",
       "        [0.023111  , 0.03414403, 0.03468358, ..., 0.04959102,\n",
       "         0.03777518, 0.01819889],\n",
       "        [0.02311776, 0.03380324, 0.0348853 , ..., 0.0496993 ,\n",
       "         0.03831502, 0.01820125],\n",
       "        ...,\n",
       "        [0.02307185, 0.03195244, 0.03370062, ..., 0.04860127,\n",
       "         0.03753566, 0.01820154],\n",
       "        [0.02310899, 0.03190076, 0.03370025, ..., 0.04851815,\n",
       "         0.0375383 , 0.01817819],\n",
       "        [0.02308856, 0.03211918, 0.0336921 , ..., 0.04833641,\n",
       "         0.03723684, 0.01824373]],\n",
       "\n",
       "       [[0.02170235, 0.03235553, 0.030181  , ..., 0.04881264,\n",
       "         0.04114521, 0.01971539],\n",
       "        [0.02173914, 0.03258206, 0.03034759, ..., 0.0486658 ,\n",
       "         0.0410662 , 0.01967379],\n",
       "        [0.02217777, 0.03152846, 0.03027567, ..., 0.0488291 ,\n",
       "         0.04096377, 0.01952646],\n",
       "        ...,\n",
       "        [0.02084956, 0.03280467, 0.03081597, ..., 0.04791502,\n",
       "         0.04294211, 0.01932308],\n",
       "        [0.02082519, 0.03247191, 0.03071597, ..., 0.0476757 ,\n",
       "         0.04252824, 0.01937794],\n",
       "        [0.02085673, 0.03242008, 0.03068305, ..., 0.04768813,\n",
       "         0.04233983, 0.01942337]],\n",
       "\n",
       "       [[0.02051559, 0.03181205, 0.0311883 , ..., 0.0520331 ,\n",
       "         0.03928722, 0.01616184],\n",
       "        [0.02047323, 0.03180355, 0.03109573, ..., 0.05172285,\n",
       "         0.0394139 , 0.01613608],\n",
       "        [0.0204473 , 0.03198596, 0.03094851, ..., 0.0519144 ,\n",
       "         0.03931487, 0.01614971],\n",
       "        ...,\n",
       "        [0.02047737, 0.03104769, 0.02789119, ..., 0.05357238,\n",
       "         0.03533613, 0.01603157],\n",
       "        [0.020012  , 0.03094915, 0.03082026, ..., 0.05155332,\n",
       "         0.03973635, 0.01585138],\n",
       "        [0.01999866, 0.03062591, 0.03072464, ..., 0.05156717,\n",
       "         0.03951323, 0.01592187]]], dtype=float32)>, hidden_states=(<tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.56177056,  0.22555724,  0.13724758, ...,  0.06377999,\n",
       "          0.6576458 , -0.00833946],\n",
       "        [ 0.35112202,  0.03010862,  0.33948576, ...,  0.34736955,\n",
       "          0.37423587,  0.04888946],\n",
       "        [ 0.3998725 ,  0.1381154 ,  0.5496714 , ...,  0.2356509 ,\n",
       "          0.5751699 ,  0.18047777],\n",
       "        ...,\n",
       "        [-0.14732343, -0.03696594,  0.06615659, ..., -0.58324236,\n",
       "         -0.21920577,  0.41776323],\n",
       "        [-0.28476104,  0.17884785,  0.03377932, ..., -0.54385865,\n",
       "         -0.27033663,  0.31476113],\n",
       "        [ 0.02236539, -0.21946535, -0.00620077, ..., -0.2169337 ,\n",
       "         -0.4079005 , -0.05391724]],\n",
       "\n",
       "       [[-0.11732596, -0.12854542,  0.29353225, ...,  0.23564959,\n",
       "          0.04949939,  0.7580929 ],\n",
       "        [ 0.02931634,  0.07468563,  0.1126938 , ...,  0.29741305,\n",
       "         -0.01175395,  0.60449004],\n",
       "        [-0.01693022, -0.01226401,  0.33684522, ...,  0.00620469,\n",
       "          0.12006432,  0.56130636],\n",
       "        ...,\n",
       "        [ 0.09921114, -0.06314083,  0.14242244, ...,  0.29418665,\n",
       "         -0.45433867,  0.52377963],\n",
       "        [ 0.28751823,  0.28154862,  0.42419615, ...,  0.27053842,\n",
       "          0.22856362,  0.40185225],\n",
       "        [-0.5565938 ,  0.23252378,  0.4454955 , ...,  0.4694514 ,\n",
       "          0.2752472 ,  0.56844014]],\n",
       "\n",
       "       [[ 0.45216155, -0.0079001 ,  0.08646782, ...,  0.21934047,\n",
       "          0.38246834,  0.04844736],\n",
       "        [ 0.20904838,  0.23775977,  0.09041362, ...,  0.0219761 ,\n",
       "          0.52021617,  0.13410845],\n",
       "        [ 0.35691285,  0.2857699 ,  0.0355761 , ...,  0.16645895,\n",
       "          0.51274675,  0.27038532],\n",
       "        ...,\n",
       "        [-0.24600261,  0.29791105,  0.2536431 , ...,  0.32962987,\n",
       "          0.19054556,  0.5600248 ],\n",
       "        [-0.00743995,  0.6220943 ,  0.22672105, ...,  0.22199473,\n",
       "         -0.03288562,  0.33715963],\n",
       "        [-0.1935282 ,  0.6039922 ,  0.18166351, ...,  0.22992441,\n",
       "          0.40131694,  0.36670613]],\n",
       "\n",
       "       [[-0.10709875,  0.43922785,  0.13994339, ..., -0.04439727,\n",
       "          0.20350039,  0.16591927],\n",
       "        [ 0.23732053,  0.01710033,  0.22600752, ..., -0.04648356,\n",
       "         -0.22075039,  0.48089266],\n",
       "        [ 0.378948  , -0.00644642,  0.39461935, ...,  0.03025591,\n",
       "          0.03840056,  0.801847  ],\n",
       "        ...,\n",
       "        [-0.05016951, -0.65499425,  0.2236934 , ...,  0.02972017,\n",
       "         -0.31767908,  1.047163  ],\n",
       "        [-0.10857046, -0.14455928, -0.27797854, ..., -0.19328013,\n",
       "          0.01305519,  0.8537408 ],\n",
       "        [-0.24997963, -0.10807131,  0.15373649, ..., -0.02816184,\n",
       "         -0.1285629 ,  0.7509066 ]]], dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.34171504,  0.3446325 ,  0.03141111, ...,  0.00675996,\n",
       "          0.07575724,  0.14354025],\n",
       "        [ 0.02806053,  0.29558557,  0.14720845, ...,  0.5179144 ,\n",
       "         -0.02721327,  0.34454423],\n",
       "        [ 0.12915304,  0.34990403, -0.04971315, ...,  0.16623291,\n",
       "          0.11797986,  0.17056412],\n",
       "        ...,\n",
       "        [-0.13097206,  0.03283845, -0.25069413, ..., -0.07962238,\n",
       "         -0.14008892,  0.06795946],\n",
       "        [-0.15521228,  0.29385844, -0.24683902, ..., -0.04444727,\n",
       "         -0.31513172,  0.05900447],\n",
       "        [-0.06237906,  0.01267526, -0.27178475, ..., -0.10268848,\n",
       "         -0.51424587,  0.02920037]],\n",
       "\n",
       "       [[-0.06078497,  0.10527675, -0.06845352, ...,  0.22703007,\n",
       "         -0.03978518,  0.39904037],\n",
       "        [ 0.08685542,  0.04226012, -0.16810216, ...,  0.20745757,\n",
       "         -0.12705848,  0.4737528 ],\n",
       "        [ 0.02614451,  0.10916748, -0.00563348, ...,  0.02447146,\n",
       "          0.05209048,  0.2694527 ],\n",
       "        ...,\n",
       "        [ 0.127412  ,  0.07920673, -0.18538553, ...,  0.3560319 ,\n",
       "         -0.41103742,  0.31712088],\n",
       "        [ 0.23627418,  0.18232445, -0.14290223, ...,  0.00251961,\n",
       "         -0.08343354,  0.31973767],\n",
       "        [ 0.01954385,  0.18930173, -0.1197558 , ...,  0.1622865 ,\n",
       "         -0.06784412,  0.28915572]],\n",
       "\n",
       "       [[ 0.31341806,  0.1466167 ,  0.01476507, ...,  0.33985084,\n",
       "          0.11319047,  0.23797747],\n",
       "        [ 0.18781945,  0.18981282,  0.07436208, ...,  0.23225555,\n",
       "          0.0152384 ,  0.37616435],\n",
       "        [ 0.1565135 ,  0.13658704,  0.03595497, ...,  0.1322819 ,\n",
       "         -0.00271532,  0.20292032],\n",
       "        ...,\n",
       "        [-0.21082194,  0.1388036 , -0.12055402, ...,  0.23084667,\n",
       "         -0.3713697 ,  0.32251543],\n",
       "        [-0.11204831,  0.21144931, -0.15177947, ...,  0.05755456,\n",
       "         -0.33723128,  0.3131576 ],\n",
       "        [-0.05628699,  0.29196116, -0.0900854 , ...,  0.09131652,\n",
       "         -0.25945058,  0.29331994]],\n",
       "\n",
       "       [[ 0.08358333,  0.26616856,  0.17822948, ...,  0.03247266,\n",
       "         -0.02615465,  0.07650823],\n",
       "        [ 0.1396308 ,  0.07983647,  0.14141524, ...,  0.02843194,\n",
       "         -0.13737874,  0.40066108],\n",
       "        [ 0.1747081 ,  0.1352314 ,  0.05340561, ...,  0.14660883,\n",
       "         -0.10520796,  0.39889562],\n",
       "        ...,\n",
       "        [ 0.03403618, -0.24263759, -0.27179348, ...,  0.15913084,\n",
       "         -0.25728136,  0.35119626],\n",
       "        [ 0.034102  , -0.24097224, -0.26286647, ..., -0.33719748,\n",
       "         -0.23440495,  0.22732887],\n",
       "        [-0.10095485,  0.07330424, -0.0720644 , ..., -0.14670691,\n",
       "         -0.3296812 ,  0.1682649 ]]], dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.44267273,  0.11416097, -0.3878375 , ...,  0.27295128,\n",
       "         -0.07644942,  0.18176039],\n",
       "        [ 0.24819773, -0.09067998, -0.16705236, ...,  0.48967537,\n",
       "         -0.1026964 ,  0.1319584 ],\n",
       "        [ 0.13900171,  0.02011283, -0.40226805, ...,  0.3178177 ,\n",
       "         -0.05171894,  0.22033393],\n",
       "        ...,\n",
       "        [ 0.03790272,  0.01237314,  0.04985801, ...,  0.02516057,\n",
       "         -0.21924976,  0.13663682],\n",
       "        [-0.00242767,  0.08578742,  0.02639189, ...,  0.06093085,\n",
       "         -0.28295097,  0.21147451],\n",
       "        [-0.02801533,  0.08159301, -0.19628048, ..., -0.05989131,\n",
       "         -0.33104515,  0.214759  ]],\n",
       "\n",
       "       [[ 0.16992675, -0.02747782, -0.2327595 , ...,  0.30386794,\n",
       "          0.07441097,  0.27277064],\n",
       "        [ 0.08036538, -0.08827616, -0.18534414, ...,  0.3927884 ,\n",
       "          0.16619591,  0.28305262],\n",
       "        [ 0.13344902,  0.13270018, -0.00840418, ...,  0.2957593 ,\n",
       "          0.11341455,  0.27883148],\n",
       "        ...,\n",
       "        [-0.09605634,  0.12701255,  0.12782271, ...,  0.35056162,\n",
       "         -0.25576508,  0.2531853 ],\n",
       "        [-0.01643155,  0.32829398, -0.04332153, ...,  0.06688713,\n",
       "         -0.11942197,  0.31342995],\n",
       "        [ 0.04187802,  0.30012327,  0.02733742, ...,  0.13969034,\n",
       "         -0.12262926,  0.38241458]],\n",
       "\n",
       "       [[ 0.33718097, -0.04432138, -0.25984251, ...,  0.4082002 ,\n",
       "         -0.01092442,  0.17658707],\n",
       "        [ 0.33479002, -0.07594001, -0.15932718, ...,  0.45042056,\n",
       "         -0.02588239,  0.18921599],\n",
       "        [ 0.3265741 , -0.07519312, -0.29137167, ...,  0.36279708,\n",
       "         -0.0529847 ,  0.15195376],\n",
       "        ...,\n",
       "        [-0.02979246,  0.19649509, -0.03621234, ...,  0.3297486 ,\n",
       "         -0.25708032,  0.3100934 ],\n",
       "        [-0.01980374,  0.30449718, -0.16324055, ...,  0.2464084 ,\n",
       "         -0.21613932,  0.26360917],\n",
       "        [-0.12569244,  0.45685807, -0.20982456, ...,  0.20062254,\n",
       "         -0.21784544,  0.2131982 ]],\n",
       "\n",
       "       [[ 0.1694508 ,  0.04606421, -0.2386527 , ...,  0.30495697,\n",
       "          0.00264021,  0.09224828],\n",
       "        [ 0.1046429 ,  0.01502731, -0.24556571, ...,  0.25472873,\n",
       "         -0.14581472,  0.11971234],\n",
       "        [ 0.10545067,  0.03460921, -0.24510744, ...,  0.30646747,\n",
       "         -0.09811564,  0.18064766],\n",
       "        ...,\n",
       "        [ 0.10232212, -0.3038    , -0.03718253, ...,  0.29052532,\n",
       "         -0.08983245,  0.24842754],\n",
       "        [ 0.01787913, -0.09636895,  0.00894906, ...,  0.00996815,\n",
       "         -0.14792666,  0.24157217],\n",
       "        [-0.09243419, -0.08810467,  0.13077445, ...,  0.01193137,\n",
       "         -0.31859362,  0.32314557]]], dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.14470446,  0.19148707, -0.19310786, ...,  0.14512937,\n",
       "         -0.34668192,  0.08283821],\n",
       "        [ 0.09498911,  0.14792931, -0.19880395, ...,  0.36001337,\n",
       "         -0.250374  , -0.00292721],\n",
       "        [-0.00416427,  0.15418994, -0.38326892, ...,  0.11917187,\n",
       "         -0.20726264,  0.103873  ],\n",
       "        ...,\n",
       "        [-0.14299351, -0.04846798, -0.04568968, ...,  0.26237318,\n",
       "         -0.42624068,  0.13252403],\n",
       "        [-0.24261072, -0.07990162, -0.07810498, ...,  0.23562022,\n",
       "         -0.45262682,  0.19662291],\n",
       "        [-0.20418093, -0.08276231, -0.08833241, ...,  0.12152553,\n",
       "         -0.5256293 ,  0.2488414 ]],\n",
       "\n",
       "       [[ 0.10074698, -0.05323368, -0.07357524, ...,  0.19823694,\n",
       "         -0.2615232 ,  0.21573904],\n",
       "        [ 0.08335924, -0.07097451, -0.23405024, ...,  0.26399598,\n",
       "         -0.07466252,  0.22994517],\n",
       "        [-0.0494137 , -0.11373877, -0.17699473, ...,  0.2680133 ,\n",
       "         -0.16646695,  0.21500218],\n",
       "        ...,\n",
       "        [-0.09653085,  0.08206396, -0.10353795, ...,  0.33962086,\n",
       "         -0.20243642,  0.1496733 ],\n",
       "        [-0.11537879,  0.01963911, -0.1170704 , ...,  0.13202903,\n",
       "         -0.21851884,  0.18165173],\n",
       "        [-0.08100343,  0.1276032 , -0.15547484, ...,  0.21916026,\n",
       "         -0.34368825,  0.3054902 ]],\n",
       "\n",
       "       [[ 0.09993577,  0.09897278, -0.1450989 , ...,  0.3468293 ,\n",
       "         -0.31706426,  0.05259286],\n",
       "        [ 0.05264529,  0.02657736, -0.1670365 , ...,  0.47265565,\n",
       "         -0.2786997 ,  0.03658065],\n",
       "        [ 0.03464146,  0.0007711 , -0.22420797, ...,  0.39968315,\n",
       "         -0.22143792,  0.01497126],\n",
       "        ...,\n",
       "        [-0.12593074, -0.07872037, -0.00129698, ...,  0.23705311,\n",
       "         -0.13186169,  0.22478467],\n",
       "        [-0.11629096,  0.02175796, -0.03563271, ...,  0.15618233,\n",
       "         -0.24061427,  0.30392528],\n",
       "        [-0.1471253 ,  0.06649551, -0.09772111, ...,  0.07122678,\n",
       "         -0.32585406,  0.35342586]],\n",
       "\n",
       "       [[ 0.1075145 , -0.03407924, -0.0554435 , ...,  0.039881  ,\n",
       "         -0.18515614,  0.18070248],\n",
       "        [ 0.15091044, -0.09009682, -0.15826073, ...,  0.0537455 ,\n",
       "         -0.10147871,  0.17284063],\n",
       "        [ 0.0685614 , -0.07500942, -0.1934126 , ...,  0.04775   ,\n",
       "         -0.13147429,  0.216497  ],\n",
       "        ...,\n",
       "        [-0.00147673,  0.07486481, -0.11953428, ...,  0.32634634,\n",
       "         -0.26065445,  0.09089912],\n",
       "        [-0.32707006,  0.06216738, -0.10697994, ...,  0.2893464 ,\n",
       "         -0.40641618,  0.16530709],\n",
       "        [-0.34213215,  0.03014813, -0.01661877, ...,  0.20360535,\n",
       "         -0.3195269 ,  0.2134727 ]]], dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 2.69255579e-01, -2.23997921e-01, -1.50123328e-01, ...,\n",
       "          3.06362659e-01, -5.42487726e-02, -7.92347714e-02],\n",
       "        [ 2.40322679e-01, -1.94342077e-01, -6.59210086e-02, ...,\n",
       "          3.81193817e-01, -1.73118949e-01, -3.01203430e-02],\n",
       "        [ 2.31621750e-02, -2.21091688e-01, -2.35969007e-01, ...,\n",
       "          2.55676597e-01, -2.64081031e-01, -5.82457334e-03],\n",
       "        ...,\n",
       "        [-2.58403629e-01, -1.96377784e-02,  5.91302291e-02, ...,\n",
       "         -4.63452786e-02, -4.85389642e-02,  1.95792049e-01],\n",
       "        [-3.26849252e-01,  2.90958583e-03, -2.58141998e-02, ...,\n",
       "          5.39611764e-02, -7.26039931e-02,  2.74969399e-01],\n",
       "        [-2.85081923e-01,  6.44288585e-03, -3.36065143e-02, ...,\n",
       "          3.46731581e-02, -2.01011300e-01,  2.39702821e-01]],\n",
       "\n",
       "       [[ 5.62640503e-02, -1.89116865e-01,  3.33700329e-04, ...,\n",
       "          2.53806710e-01,  1.19439587e-01,  1.68398589e-01],\n",
       "        [-4.70654070e-02, -1.35820746e-01, -4.93399464e-02, ...,\n",
       "          1.85813099e-01,  1.85873061e-01,  1.56111613e-01],\n",
       "        [-1.09983116e-01, -1.93938725e-02,  6.12411909e-02, ...,\n",
       "          1.54763043e-01,  1.76368847e-01,  2.18311980e-01],\n",
       "        ...,\n",
       "        [-3.54822934e-01,  1.75213069e-02,  9.98392701e-02, ...,\n",
       "          2.06718266e-01, -7.31943399e-02,  2.72548854e-01],\n",
       "        [-3.61960679e-01,  4.75102663e-02,  2.67055444e-02, ...,\n",
       "          1.41405314e-01, -7.47363493e-02,  2.32599229e-01],\n",
       "        [-3.61721098e-01,  9.71905440e-02, -4.22550291e-02, ...,\n",
       "          1.60808459e-01, -1.79354966e-01,  3.01153779e-01]],\n",
       "\n",
       "       [[ 2.67808020e-01, -1.49032265e-01, -4.58870903e-02, ...,\n",
       "          2.04049975e-01, -1.12269446e-01,  6.69977069e-03],\n",
       "        [ 2.23215431e-01, -1.58397630e-01, -6.42552078e-02, ...,\n",
       "          1.99557617e-01, -2.17010170e-01,  8.31744969e-02],\n",
       "        [ 2.35685691e-01, -2.26594746e-01, -3.39202508e-02, ...,\n",
       "          1.43313229e-01, -2.24502102e-01,  1.19154841e-01],\n",
       "        ...,\n",
       "        [-2.77731299e-01, -6.15352318e-02,  1.18444510e-01, ...,\n",
       "         -2.90809199e-02, -1.06525674e-01,  2.40003452e-01],\n",
       "        [-2.08122760e-01, -1.00799277e-02,  8.83506238e-02, ...,\n",
       "          2.37793624e-02, -2.10042477e-01,  2.26135850e-01],\n",
       "        [-1.87255055e-01,  2.36463863e-02,  9.56172347e-02, ...,\n",
       "          4.44396995e-02, -1.85119122e-01,  2.36419499e-01]],\n",
       "\n",
       "       [[ 1.67603567e-01, -1.39350757e-01,  5.85854426e-03, ...,\n",
       "          1.71107173e-01,  1.82038292e-01, -6.26664609e-02],\n",
       "        [ 1.24524683e-01, -1.96253479e-01,  7.78143406e-02, ...,\n",
       "          2.31166363e-01,  1.87314212e-01, -1.09117776e-02],\n",
       "        [ 8.29595476e-02, -1.45967886e-01, -3.06732953e-04, ...,\n",
       "          2.39050075e-01,  1.79077938e-01, -2.41017342e-03],\n",
       "        ...,\n",
       "        [ 2.24796198e-02,  5.09010404e-02, -3.23161259e-02, ...,\n",
       "          4.94310260e-03, -1.18354306e-01, -3.27778608e-02],\n",
       "        [-3.52780133e-01,  1.53551683e-01, -4.19329107e-03, ...,\n",
       "          2.47925594e-01,  3.50319445e-02,  2.65179187e-01],\n",
       "        [-2.55895823e-01,  1.08080775e-01,  1.96038969e-02, ...,\n",
       "          1.75257415e-01,  1.16460204e-01,  2.99295068e-01]]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.20118004, -0.13027282, -0.1744001 , ...,  0.08078332,\n",
       "         -0.23048717, -0.11300997],\n",
       "        [ 0.13429247, -0.13963836, -0.07992248, ...,  0.064882  ,\n",
       "         -0.2558278 , -0.00567392],\n",
       "        [ 0.23790096, -0.10517721, -0.19313979, ...,  0.03172527,\n",
       "         -0.18436947,  0.03911476],\n",
       "        ...,\n",
       "        [ 0.00862836,  0.07084778,  0.00245472, ...,  0.0885785 ,\n",
       "         -0.06937608,  0.19270223],\n",
       "        [-0.08135709, -0.00342617,  0.02514865, ...,  0.16233231,\n",
       "         -0.0108726 ,  0.2324774 ],\n",
       "        [-0.09349818,  0.00792742,  0.01476323, ...,  0.13780704,\n",
       "         -0.06754512,  0.18720797]],\n",
       "\n",
       "       [[ 0.13113536, -0.37270653, -0.09315035, ..., -0.02649818,\n",
       "         -0.01870839,  0.06170971],\n",
       "        [ 0.14559606, -0.39232194, -0.14353862, ..., -0.0900047 ,\n",
       "          0.00045376,  0.08050901],\n",
       "        [ 0.20279625, -0.41217938,  0.02661284, ..., -0.01290415,\n",
       "          0.11650443,  0.18105942],\n",
       "        ...,\n",
       "        [-0.1163054 ,  0.03846336, -0.04262844, ...,  0.08693184,\n",
       "         -0.0616451 ,  0.21321954],\n",
       "        [-0.13027562,  0.04896004, -0.00109138, ...,  0.08107001,\n",
       "         -0.06322758,  0.2277767 ],\n",
       "        [-0.1162581 ,  0.12996086, -0.0874121 , ...,  0.05048777,\n",
       "         -0.0812609 ,  0.26200163]],\n",
       "\n",
       "       [[ 0.1287117 , -0.13598782, -0.03773147, ...,  0.16279241,\n",
       "         -0.19521584, -0.06918597],\n",
       "        [ 0.15435386, -0.14296433, -0.03395988, ...,  0.1951977 ,\n",
       "         -0.2353333 ,  0.01544248],\n",
       "        [ 0.11672103, -0.16342092, -0.0553851 , ...,  0.2517662 ,\n",
       "         -0.15143444,  0.00196301],\n",
       "        ...,\n",
       "        [-0.13053957,  0.06733928,  0.16516842, ...,  0.13688532,\n",
       "          0.07354763,  0.36069044],\n",
       "        [-0.09048906,  0.06240016,  0.1954523 , ...,  0.15490529,\n",
       "         -0.01957107,  0.36913013],\n",
       "        [-0.09778525,  0.09800465,  0.1939171 , ...,  0.161116  ,\n",
       "         -0.00852017,  0.37112638]],\n",
       "\n",
       "       [[ 0.2818374 , -0.28676614, -0.15886587, ...,  0.05745261,\n",
       "         -0.16953702, -0.06930631],\n",
       "        [ 0.29731867, -0.30708957, -0.19476333, ...,  0.01027399,\n",
       "         -0.15327445, -0.04548968],\n",
       "        [ 0.28250438, -0.26868176, -0.2227241 , ...,  0.03593569,\n",
       "         -0.14232767, -0.05716781],\n",
       "        ...,\n",
       "        [ 0.00515104,  0.06946825, -0.02461849, ...,  0.01945444,\n",
       "         -0.06827077, -0.00330392],\n",
       "        [-0.18184109,  0.1097634 ,  0.06629418, ...,  0.22696882,\n",
       "         -0.07820679,  0.23273413],\n",
       "        [-0.18421939,  0.08994072,  0.04956422, ...,  0.25207382,\n",
       "         -0.05955246,  0.24757329]]], dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.17384955,  0.00332811, -0.16645147, ...,  0.3629965 ,\n",
       "         -0.12603635, -0.06361729],\n",
       "        [ 0.13081084, -0.0089844 , -0.128839  , ...,  0.3498256 ,\n",
       "         -0.13394645,  0.01285394],\n",
       "        [ 0.2338435 ,  0.05023985, -0.11646928, ...,  0.2793082 ,\n",
       "         -0.0621457 ,  0.00969042],\n",
       "        ...,\n",
       "        [ 0.03037259,  0.02759206, -0.01620733, ...,  0.00467089,\n",
       "         -0.0588955 ,  0.00501508],\n",
       "        [ 0.092226  , -0.04387412,  0.08192816, ...,  0.06212245,\n",
       "          0.00731243,  0.03588865],\n",
       "        [ 0.09979885, -0.09023856,  0.047449  , ...,  0.08739573,\n",
       "         -0.00317195,  0.06014253]],\n",
       "\n",
       "       [[ 0.11195986, -0.1589131 , -0.05261282, ...,  0.01031729,\n",
       "         -0.04825457,  0.12279051],\n",
       "        [ 0.12023084, -0.12576413, -0.10096654, ...,  0.01600862,\n",
       "         -0.03523794,  0.13477854],\n",
       "        [ 0.07072738, -0.07419492, -0.00351985, ..., -0.12867606,\n",
       "         -0.04341047,  0.24269891],\n",
       "        ...,\n",
       "        [ 0.08488967, -0.03089248,  0.08286195, ...,  0.01841749,\n",
       "          0.06222525,  0.05595479],\n",
       "        [ 0.11551005, -0.04933723,  0.06644949, ...,  0.02161838,\n",
       "          0.04856424,  0.0731626 ],\n",
       "        [ 0.16528602,  0.03664329,  0.07448652, ...,  0.0379234 ,\n",
       "          0.10906766,  0.0700962 ]],\n",
       "\n",
       "       [[ 0.3031373 ,  0.07416932, -0.05980353, ...,  0.34510934,\n",
       "         -0.201996  , -0.17478178],\n",
       "        [ 0.29916668,  0.04304136, -0.06847337, ...,  0.29935622,\n",
       "         -0.14500108, -0.14204489],\n",
       "        [ 0.266769  ,  0.11637171, -0.05623261, ...,  0.29827213,\n",
       "         -0.15263903, -0.17189708],\n",
       "        ...,\n",
       "        [ 0.00105806, -0.04285067,  0.10497589, ..., -0.06603313,\n",
       "          0.03634085,  0.19492824],\n",
       "        [ 0.06869869, -0.09035555,  0.0975257 , ..., -0.01519823,\n",
       "         -0.02299739,  0.18880677],\n",
       "        [ 0.05313795, -0.07328557,  0.10937271, ..., -0.02089432,\n",
       "         -0.0318353 ,  0.19858618]],\n",
       "\n",
       "       [[ 0.23571914, -0.12611684, -0.15055087, ...,  0.28630382,\n",
       "         -0.06028458,  0.07000659],\n",
       "        [ 0.2151367 , -0.10299477, -0.1600709 , ...,  0.26482576,\n",
       "         -0.03048889,  0.07441959],\n",
       "        [ 0.21833634, -0.06176709, -0.1680781 , ...,  0.26127523,\n",
       "         -0.02084094,  0.05105136],\n",
       "        ...,\n",
       "        [ 0.00693649,  0.06185303, -0.0138808 , ...,  0.02430306,\n",
       "         -0.05771931,  0.0062526 ],\n",
       "        [-0.02306679,  0.00265914,  0.08905992, ...,  0.03124304,\n",
       "         -0.019269  ,  0.19055526],\n",
       "        [-0.0068335 , -0.00722068,  0.0730207 , ...,  0.1023659 ,\n",
       "          0.01116711,  0.1541998 ]]], dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 1.97150528e-01, -2.08438516e-01, -1.63954794e-01, ...,\n",
       "          1.97414204e-01,  7.64181912e-02, -7.62146711e-02],\n",
       "        [ 2.10331112e-01, -2.01560840e-01, -1.16229951e-01, ...,\n",
       "          2.13658676e-01,  8.90565962e-02, -6.07967228e-02],\n",
       "        [ 2.47086614e-01, -2.24795878e-01, -1.99594840e-01, ...,\n",
       "          2.17773169e-01,  1.67826191e-01,  2.50833444e-02],\n",
       "        ...,\n",
       "        [ 1.27822906e-03,  3.36409770e-02, -2.10244935e-02, ...,\n",
       "         -9.72662866e-03, -2.35044956e-02,  3.51918451e-02],\n",
       "        [ 1.19018085e-01, -1.77241862e-01,  1.18691009e-03, ...,\n",
       "         -1.85910091e-02,  1.75496340e-01,  1.42434761e-02],\n",
       "        [ 8.82641375e-02, -1.56192988e-01,  4.00583372e-02, ...,\n",
       "         -3.34166177e-02,  1.66603893e-01,  2.37342492e-02]],\n",
       "\n",
       "       [[ 1.13662370e-01, -3.08843106e-01,  9.10663009e-02, ...,\n",
       "         -7.55069777e-03,  1.12448037e-01,  5.74351437e-02],\n",
       "        [ 1.16510026e-01, -2.80024230e-01,  5.47905006e-02, ...,\n",
       "          1.81461871e-03,  1.23622544e-01,  7.90598020e-02],\n",
       "        [ 1.07474580e-01, -2.81675160e-01,  1.36826962e-01, ...,\n",
       "         -5.90334237e-02,  1.08447224e-01,  2.01571956e-02],\n",
       "        ...,\n",
       "        [ 1.40587345e-01,  2.99930498e-02,  1.72291249e-01, ...,\n",
       "          5.48114143e-02,  2.28499949e-01,  7.27083161e-02],\n",
       "        [ 1.38501912e-01, -9.01310518e-03,  1.90934271e-01, ...,\n",
       "          3.01380679e-02,  2.14878947e-01,  7.71132261e-02],\n",
       "        [ 1.37012884e-01,  2.23905593e-03,  1.38262853e-01, ...,\n",
       "          3.09324805e-02,  2.40222573e-01,  7.36880600e-02]],\n",
       "\n",
       "       [[ 3.86681527e-01, -8.38657245e-02, -3.77324633e-02, ...,\n",
       "          6.85084090e-02, -2.78862566e-03,  3.71129327e-02],\n",
       "        [ 3.68874699e-01, -1.14577368e-01, -7.75153413e-02, ...,\n",
       "          3.19816470e-02,  2.58748084e-02,  3.86709645e-02],\n",
       "        [ 4.04590905e-01, -7.53501207e-02, -4.20470014e-02, ...,\n",
       "          7.38391131e-02,  7.47436285e-03,  5.99247366e-02],\n",
       "        ...,\n",
       "        [ 1.42488837e-01, -1.45594209e-01,  1.76430970e-01, ...,\n",
       "          7.44775534e-02,  6.05760217e-02,  5.17919622e-02],\n",
       "        [ 1.81607991e-01, -1.34201527e-01,  1.53081089e-01, ...,\n",
       "          7.89007917e-02,  3.50655541e-02,  4.22340445e-02],\n",
       "        [ 1.96327716e-01, -1.39496982e-01,  1.33914754e-01, ...,\n",
       "          9.04341936e-02,  4.10054177e-02,  3.95924747e-02]],\n",
       "\n",
       "       [[ 1.27424881e-01, -2.85516828e-01, -4.11867350e-02, ...,\n",
       "          1.98318958e-01,  1.30819112e-01, -9.44497287e-02],\n",
       "        [ 1.23590648e-01, -2.82725692e-01, -5.76067828e-02, ...,\n",
       "          1.89332917e-01,  1.17141880e-01, -1.06675275e-01],\n",
       "        [ 1.18793614e-01, -2.61622310e-01, -6.81728944e-02, ...,\n",
       "          2.05370054e-01,  1.21758983e-01, -1.11623853e-01],\n",
       "        ...,\n",
       "        [-3.95618379e-04,  2.92727537e-02, -2.73560174e-02, ...,\n",
       "         -4.03076410e-06, -1.76680610e-02,  3.32488827e-02],\n",
       "        [ 1.21689901e-01, -3.64827774e-02,  5.87372258e-02, ...,\n",
       "          1.97254032e-01,  1.54047012e-01,  2.03572586e-02],\n",
       "        [ 1.10421926e-01, -1.08378045e-02,  8.13692883e-02, ...,\n",
       "          2.12043121e-01,  1.71094179e-01,  3.77897695e-02]]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.07888154, -0.05766252,  0.20009315, ...,  0.29116994,\n",
       "          0.2787776 ,  0.07161611],\n",
       "        [ 0.13674034,  0.00925439,  0.16354778, ...,  0.3466469 ,\n",
       "          0.31023493,  0.08628372],\n",
       "        [ 0.17030823,  0.04724402,  0.11453167, ...,  0.33587167,\n",
       "          0.2702652 ,  0.17784561],\n",
       "        ...,\n",
       "        [ 0.01048316, -0.00422371, -0.02921311, ..., -0.00137948,\n",
       "         -0.03127469, -0.00451332],\n",
       "        [ 0.02236164, -0.10226476,  0.00784017, ...,  0.32848758,\n",
       "          0.14973524,  0.17297998],\n",
       "        [ 0.051528  , -0.07348056,  0.02119715, ...,  0.323915  ,\n",
       "          0.1493573 ,  0.21422872]],\n",
       "\n",
       "       [[ 0.08770663, -0.13492164,  0.15091226, ...,  0.22872075,\n",
       "          0.39702046,  0.18549196],\n",
       "        [ 0.0872755 , -0.11634059,  0.10494271, ...,  0.23965901,\n",
       "          0.44275308,  0.18840355],\n",
       "        [ 0.21119654, -0.09493404,  0.13544264, ...,  0.3445262 ,\n",
       "          0.42508066,  0.1345854 ],\n",
       "        ...,\n",
       "        [ 0.15698981,  0.00803499, -0.14333162, ...,  0.40600407,\n",
       "          0.37397715,  0.19458804],\n",
       "        [ 0.17430699,  0.00880111, -0.11556537, ...,  0.40027085,\n",
       "          0.35553077,  0.21333852],\n",
       "        [ 0.19086689,  0.06356017, -0.1061511 , ...,  0.36487305,\n",
       "          0.41203493,  0.2358149 ]],\n",
       "\n",
       "       [[ 0.11427405,  0.05375952,  0.13581479, ...,  0.02114416,\n",
       "          0.173668  ,  0.08382851],\n",
       "        [ 0.11436793,  0.04714416,  0.07672551, ...,  0.03132152,\n",
       "          0.21665207,  0.06929895],\n",
       "        [ 0.15436417,  0.10152008,  0.02841537, ...,  0.1641728 ,\n",
       "          0.23330893,  0.05826596],\n",
       "        ...,\n",
       "        [ 0.19081032, -0.12744409,  0.06894495, ...,  0.26894987,\n",
       "          0.3320947 ,  0.06892078],\n",
       "        [ 0.19161429, -0.10294425,  0.04871428, ...,  0.2659515 ,\n",
       "          0.3061174 ,  0.0548881 ],\n",
       "        [ 0.22588536, -0.08274013,  0.04339349, ...,  0.28678432,\n",
       "          0.3226778 ,  0.0477329 ]],\n",
       "\n",
       "       [[ 0.0333675 , -0.12046735,  0.13024974, ...,  0.2386611 ,\n",
       "          0.29810572,  0.16851938],\n",
       "        [ 0.02668596, -0.13848758,  0.13838781, ...,  0.22727111,\n",
       "          0.28221896,  0.13797322],\n",
       "        [ 0.01495048, -0.13377316,  0.14640923, ...,  0.21573117,\n",
       "          0.2952416 ,  0.13922106],\n",
       "        ...,\n",
       "        [ 0.00280769,  0.00050644, -0.03615975, ..., -0.00093421,\n",
       "         -0.02499306, -0.0034628 ],\n",
       "        [ 0.05131536, -0.08753674,  0.04656639, ...,  0.3434761 ,\n",
       "          0.19941692,  0.02483067],\n",
       "        [ 0.04735827, -0.10741565,  0.0633636 , ...,  0.31331676,\n",
       "          0.22303931,  0.0222503 ]]], dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.42956725,  0.18741246, -0.04318309, ...,  0.37758443,\n",
       "          0.46476826, -0.01329621],\n",
       "        [ 0.4441658 ,  0.1918033 , -0.04872177, ...,  0.36529312,\n",
       "          0.47176754, -0.01116326],\n",
       "        [ 0.46065646,  0.22150318, -0.04573867, ...,  0.41009146,\n",
       "          0.4590907 , -0.04784447],\n",
       "        ...,\n",
       "        [-0.01848014,  0.02916317, -0.03342142, ..., -0.02527769,\n",
       "          0.00228188,  0.00851168],\n",
       "        [ 0.32082397,  0.00622879,  0.07004425, ...,  0.36773834,\n",
       "          0.457699  ,  0.1828854 ],\n",
       "        [ 0.31571552, -0.01224655,  0.07201862, ...,  0.3950517 ,\n",
       "          0.49472   ,  0.18621959]],\n",
       "\n",
       "       [[ 0.33907807,  0.04563059, -0.01522578, ...,  0.2731936 ,\n",
       "          0.4659876 ,  0.07467527],\n",
       "        [ 0.3711779 ,  0.05551521, -0.01521356, ...,  0.2530101 ,\n",
       "          0.46185938,  0.05714963],\n",
       "        [ 0.31247857, -0.00217692, -0.02361597, ...,  0.27081257,\n",
       "          0.28037366,  0.0373245 ],\n",
       "        ...,\n",
       "        [ 0.341395  ,  0.04350495, -0.02019588, ...,  0.322277  ,\n",
       "          0.41496295,  0.06941771],\n",
       "        [ 0.34779796,  0.0411608 , -0.02203935, ...,  0.3242858 ,\n",
       "          0.42565307,  0.06141687],\n",
       "        [ 0.36503336,  0.04832748,  0.00075706, ...,  0.31075206,\n",
       "          0.5048693 ,  0.0965441 ]],\n",
       "\n",
       "       [[ 0.37643763,  0.15716168,  0.13745603, ...,  0.22589111,\n",
       "          0.46971574, -0.04728812],\n",
       "        [ 0.3851845 ,  0.15439555,  0.13341358, ...,  0.25968212,\n",
       "          0.4093632 , -0.04359305],\n",
       "        [ 0.43049142,  0.18432885,  0.17045435, ...,  0.20234124,\n",
       "          0.3580644 , -0.06898238],\n",
       "        ...,\n",
       "        [ 0.18915786, -0.01344894,  0.15067337, ...,  0.4042045 ,\n",
       "          0.49593526,  0.10216966],\n",
       "        [ 0.22427636, -0.03631804,  0.19931747, ...,  0.37648973,\n",
       "          0.5278865 ,  0.10206617],\n",
       "        [ 0.21937844, -0.0223449 ,  0.18517357, ...,  0.38683578,\n",
       "          0.5366479 ,  0.10360955]],\n",
       "\n",
       "       [[ 0.3064952 ,  0.07960736, -0.02383692, ...,  0.37839708,\n",
       "          0.46435252,  0.08265989],\n",
       "        [ 0.28907472,  0.07287458, -0.00404847, ...,  0.36314866,\n",
       "          0.45717072,  0.09328444],\n",
       "        [ 0.28883684,  0.07509241, -0.00203228, ...,  0.37509948,\n",
       "          0.4513838 ,  0.08923297],\n",
       "        ...,\n",
       "        [-0.01399192,  0.02943971, -0.03725904, ..., -0.01675992,\n",
       "          0.00258756,  0.00525265],\n",
       "        [ 0.27021185, -0.01676872,  0.11326532, ...,  0.3852327 ,\n",
       "          0.54832596,  0.08220115],\n",
       "        [ 0.25551516, -0.01322524,  0.15047203, ...,  0.32103184,\n",
       "          0.5664403 ,  0.10581581]]], dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.1947078 ,  0.19994143,  0.32885084, ...,  0.06324498,\n",
       "          0.11708342,  0.08407567],\n",
       "        [ 0.17215088,  0.21417663,  0.32197207, ...,  0.07354032,\n",
       "          0.08935428,  0.09491631],\n",
       "        [ 0.1924962 ,  0.21520148,  0.3254566 , ...,  0.05276003,\n",
       "          0.12373595,  0.10099937],\n",
       "        ...,\n",
       "        [ 0.00976074,  0.0011199 ,  0.00314285, ..., -0.0371367 ,\n",
       "          0.02857668,  0.01342618],\n",
       "        [ 0.24277507,  0.22686791,  0.35190985, ..., -0.01279625,\n",
       "          0.15975375,  0.20015214],\n",
       "        [ 0.24887931,  0.2378406 ,  0.34110442, ..., -0.01855019,\n",
       "          0.19502556,  0.22711338]],\n",
       "\n",
       "       [[ 0.17226836,  0.1321116 ,  0.33487183, ...,  0.02428861,\n",
       "          0.04754175,  0.11130331],\n",
       "        [ 0.15667412,  0.14409874,  0.34333342, ...,  0.0267954 ,\n",
       "          0.02391873,  0.10370652],\n",
       "        [ 0.15472566,  0.15252881,  0.35181603, ...,  0.04300647,\n",
       "          0.02305064,  0.07483165],\n",
       "        ...,\n",
       "        [ 0.15500937,  0.17879552,  0.3973067 , ..., -0.00840177,\n",
       "          0.12176357,  0.13532223],\n",
       "        [ 0.1509719 ,  0.1759721 ,  0.40089846, ..., -0.00590046,\n",
       "          0.12064939,  0.14488727],\n",
       "        [ 0.17066652,  0.1836423 ,  0.40809983, ..., -0.00143753,\n",
       "          0.15976043,  0.15048888]],\n",
       "\n",
       "       [[ 0.2065361 ,  0.19773781,  0.35116252, ...,  0.03580346,\n",
       "          0.13002229,  0.0280908 ],\n",
       "        [ 0.21656601,  0.19873554,  0.3285697 , ...,  0.05844125,\n",
       "          0.09039544,  0.04806506],\n",
       "        [ 0.23329654,  0.21743701,  0.33377627, ...,  0.04717463,\n",
       "          0.09431947,  0.00716026],\n",
       "        ...,\n",
       "        [ 0.23962402,  0.15635875,  0.34681723, ...,  0.07768672,\n",
       "          0.11333515,  0.10824403],\n",
       "        [ 0.22510326,  0.18713076,  0.36159685, ...,  0.06609779,\n",
       "          0.15419038,  0.1014448 ],\n",
       "        [ 0.22327134,  0.17199561,  0.34581307, ...,  0.07548008,\n",
       "          0.16309191,  0.10862814]],\n",
       "\n",
       "       [[ 0.13286436,  0.17223302,  0.20451184, ...,  0.04497129,\n",
       "          0.14351766,  0.06229427],\n",
       "        [ 0.12437919,  0.16007587,  0.23322216, ...,  0.0445831 ,\n",
       "          0.13025644,  0.06454904],\n",
       "        [ 0.12743114,  0.15211056,  0.21980327, ...,  0.04551317,\n",
       "          0.13909143,  0.05961805],\n",
       "        ...,\n",
       "        [ 0.01737148, -0.00423894, -0.00278621, ..., -0.04464155,\n",
       "          0.02745693,  0.00276447],\n",
       "        [ 0.17617255,  0.16950174,  0.31118104, ...,  0.07884245,\n",
       "          0.20366357,  0.02941078],\n",
       "        [ 0.18342543,  0.16909951,  0.36955425, ...,  0.04959009,\n",
       "          0.22191097,  0.04328559]]], dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.03908931,  0.33530453,  0.27570122, ..., -0.01282055,\n",
       "          0.1703662 ,  0.04884624],\n",
       "        [ 0.03941911,  0.34117547,  0.27448398, ..., -0.01778368,\n",
       "          0.16746858,  0.05362853],\n",
       "        [ 0.0353238 ,  0.3406477 ,  0.27583387, ..., -0.01176756,\n",
       "          0.17258856,  0.05659162],\n",
       "        ...,\n",
       "        [ 0.07653885,  0.30329755,  0.23575991, ..., -0.02974343,\n",
       "          0.15374187,  0.03658669],\n",
       "        [ 0.04557768,  0.3152063 ,  0.27773786, ..., -0.01913342,\n",
       "          0.1563795 ,  0.05790663],\n",
       "        [ 0.0424985 ,  0.315788  ,  0.2801764 , ..., -0.01878659,\n",
       "          0.15436143,  0.06311342]],\n",
       "\n",
       "       [[ 0.06449364,  0.30960795,  0.25693956, ..., -0.01569732,\n",
       "          0.16041744,  0.06204968],\n",
       "        [ 0.06423417,  0.3167077 ,  0.25909328, ..., -0.01985807,\n",
       "          0.15932485,  0.06021005],\n",
       "        [ 0.06046771,  0.31384957,  0.26183814, ..., -0.01830992,\n",
       "          0.14986476,  0.05697917],\n",
       "        ...,\n",
       "        [ 0.04089687,  0.3132878 ,  0.27125847, ..., -0.02049637,\n",
       "          0.15795639,  0.08475436],\n",
       "        [ 0.04237579,  0.31566483,  0.27160424, ..., -0.01881583,\n",
       "          0.15862966,  0.08562381],\n",
       "        [ 0.03896256,  0.3187373 ,  0.27267614, ..., -0.01584187,\n",
       "          0.16078247,  0.08420745]],\n",
       "\n",
       "       [[ 0.005343  ,  0.34381613,  0.27388954, ..., -0.01821924,\n",
       "          0.1794504 ,  0.07843212],\n",
       "        [ 0.01108729,  0.3445794 ,  0.27549565, ..., -0.02075483,\n",
       "          0.17541386,  0.07495644],\n",
       "        [ 0.00199012,  0.36497897,  0.2710625 , ..., -0.01913683,\n",
       "          0.17639343,  0.07660819],\n",
       "        ...,\n",
       "        [ 0.04249068,  0.3117185 ,  0.2970373 , ..., -0.01571979,\n",
       "          0.13623455,  0.06222369],\n",
       "        [ 0.03741238,  0.3141238 ,  0.30278996, ..., -0.01576439,\n",
       "          0.13430615,  0.06508086],\n",
       "        [ 0.03755049,  0.31442955,  0.2985285 , ..., -0.01037979,\n",
       "          0.13828763,  0.06555693]],\n",
       "\n",
       "       [[ 0.04258062,  0.35938767,  0.2518161 , ..., -0.01450078,\n",
       "          0.17683645,  0.06935972],\n",
       "        [ 0.04242327,  0.360524  ,  0.25512528, ..., -0.01806813,\n",
       "          0.17117313,  0.06443129],\n",
       "        [ 0.04115326,  0.36176085,  0.2568421 , ..., -0.01828793,\n",
       "          0.17547399,  0.06547643],\n",
       "        ...,\n",
       "        [ 0.09247066,  0.31313333,  0.22394234, ..., -0.06076397,\n",
       "          0.12432113,  0.06434669],\n",
       "        [ 0.04686343,  0.34736767,  0.26078904, ..., -0.02004408,\n",
       "          0.14225036,  0.0723771 ],\n",
       "        [ 0.04821055,  0.34305754,  0.2696401 , ..., -0.02198161,\n",
       "          0.14610115,  0.07427061]]], dtype=float32)>, <tf.Tensor: shape=(4, 300, 768), dtype=float32, numpy=\n",
       "array([[[ 0.05267926,  0.02968714, -0.00882676, ..., -0.23469633,\n",
       "          0.05276081, -0.1146486 ],\n",
       "        [ 0.05765777,  0.03104239, -0.00781926, ..., -0.2356171 ,\n",
       "          0.05406647, -0.11439253],\n",
       "        [ 0.05246801,  0.02956676, -0.02172086, ..., -0.23135543,\n",
       "          0.05645919, -0.11276136],\n",
       "        ...,\n",
       "        [ 0.02227218,  0.0299487 ,  0.00453719, ..., -0.25345898,\n",
       "          0.00750398, -0.13098437],\n",
       "        [ 0.03248631,  0.03076785, -0.01159   , ..., -0.24634044,\n",
       "          0.05439865, -0.08842784],\n",
       "        [ 0.02880856,  0.03013398, -0.01384931, ..., -0.25060895,\n",
       "          0.0519243 , -0.0862319 ]],\n",
       "\n",
       "       [[-0.00704784, -0.05171959,  0.02255143, ..., -0.34447017,\n",
       "          0.0148805 , -0.13107738],\n",
       "        [-0.00542559, -0.05100825,  0.02630399, ..., -0.34204227,\n",
       "          0.01616071, -0.13600494],\n",
       "        [-0.00238571, -0.0540405 ,  0.03495546, ..., -0.33958942,\n",
       "          0.01703027, -0.13893856],\n",
       "        ...,\n",
       "        [-0.03728973, -0.05960014,  0.01475507, ..., -0.32307333,\n",
       "          0.02634899, -0.12436505],\n",
       "        [-0.03531671, -0.0580427 ,  0.01393353, ..., -0.32561994,\n",
       "          0.02582602, -0.12338258],\n",
       "        [-0.04039335, -0.05988405,  0.0107963 , ..., -0.32620436,\n",
       "          0.02392866, -0.12213389]],\n",
       "\n",
       "       [[-0.03440931, -0.06775003,  0.06412842, ..., -0.32709354,\n",
       "          0.04486717, -0.12430721],\n",
       "        [-0.02971109, -0.06637631,  0.06628231, ..., -0.3316505 ,\n",
       "          0.04340919, -0.1240153 ],\n",
       "        [-0.03252373, -0.0601513 ,  0.07199828, ..., -0.3243848 ,\n",
       "          0.04581718, -0.12990363],\n",
       "        ...,\n",
       "        [-0.02511357, -0.07889043,  0.080275  , ..., -0.36232156,\n",
       "          0.04063416, -0.11564901],\n",
       "        [-0.02952452, -0.07885055,  0.0774555 , ..., -0.36367452,\n",
       "          0.04028516, -0.11437972],\n",
       "        [-0.02785375, -0.07985128,  0.07903527, ..., -0.3617345 ,\n",
       "          0.03971542, -0.1132426 ]],\n",
       "\n",
       "       [[-0.00755452,  0.03791656, -0.01648424, ..., -0.22279015,\n",
       "          0.04477191, -0.07900602],\n",
       "        [-0.00537875,  0.03937493, -0.01599317, ..., -0.22485822,\n",
       "          0.04461705, -0.08191831],\n",
       "        [-0.00799142,  0.0389852 , -0.01614574, ..., -0.22510307,\n",
       "          0.04510015, -0.08169384],\n",
       "        ...,\n",
       "        [-0.02314192,  0.04872175, -0.00892763, ..., -0.27759653,\n",
       "          0.01747997, -0.07386838],\n",
       "        [-0.01932829,  0.03519032, -0.01884543, ..., -0.23079047,\n",
       "          0.0420303 , -0.06300163],\n",
       "        [-0.01661851,  0.03265661, -0.01378395, ..., -0.23265077,\n",
       "          0.04166386, -0.06301965]]], dtype=float32)>), attentions=None)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class Trainer:\r\n",
    "    def __init__(self, args):\r\n",
    "        self.args = args\r\n",
    "        self.model = TFWav2Vec2ForCTC(args)\r\n",
    "        self.dataloader = DataLoader(args)\r\n",
    "    \r\n",
    "    def fit(self):\r\n",
    "        for epoch in range(self.args.epochs):\r\n",
    "            print(f\"Epoch {epoch+1}/{self.args.epochs}\")\r\n",
    "            for step, (X_train, y_train) in enumerate(self.dataloader.train):\r\n",
    "                with tf.GradientTape() as tape:\r\n",
    "                    t_logits = self.model(X_train, y_train, training=True)\r\n",
    "                    # t_loss = self.loss_fn(y_train, t_logits)\r\n",
    "                    print(t_logits)\r\n",
    "                # grads = \r\n",
    "\r\n",
    "Trainer(args).fit()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some layers from the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing TFWav2Vec2Model: ['dropout_50', 'lm_head']\n",
      "- This IS expected if you are initializing TFWav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFWav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFWav2Vec2Model were initialized from the model checkpoint at facebook/wav2vec2-base-960h.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFWav2Vec2Model for predictions without further training.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/30\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:Erf]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-08c772144c7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[1;31m# grads =\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-08c772144c7d>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                     \u001b[0mt_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                     \u001b[1;31m# t_loss = self.loss_fn(y_train, t_logits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_logits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-6ca8089bf55d>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, labels, training)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_tf_wav2vec2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[0;32m   1439\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"return_dict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"return_dict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"return_dict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         outputs = self.wav2vec2(\n\u001b[0m\u001b[0;32m   1442\u001b[0m             \u001b[0minput_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_values\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"attention_mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_tf_wav2vec2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[0;32m   1208\u001b[0m         )\n\u001b[0;32m   1209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1210\u001b[1;33m         hidden_states = self.feature_extractor(\n\u001b[0m\u001b[0;32m   1211\u001b[0m             \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_values\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"training\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m         )\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_tf_wav2vec2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_values)\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconv_layer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_tf_wav2vec2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36mgelu\u001b[1;34m(x, approximate)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;33m-\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mGaussian\u001b[0m \u001b[0mError\u001b[0m \u001b[0mLinear\u001b[0m \u001b[0mUnits\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mGELUs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1606.08415\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m   \"\"\"\n\u001b[1;32m--> 351\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapproximate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mgelu\u001b[1;34m(features, approximate, name)\u001b[0m\n\u001b[0;32m   3664\u001b[0m                               (features + coeff * math_ops.pow(features, 3))))\n\u001b[0;32m   3665\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3666\u001b[1;33m       return 0.5 * features * (1.0 + math_ops.erf(\n\u001b[0m\u001b[0;32m   3667\u001b[0m           features / math_ops.cast(1.4142135623730951, features.dtype)))\n\u001b[0;32m   3668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36merf\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   3276\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3278\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3280\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:Erf]"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('tf-gpu': conda)"
  },
  "interpreter": {
   "hash": "b851d2923cfa3a2562599062e05fd9893d86a7c009c64d8ad3756552e4dd5f41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}