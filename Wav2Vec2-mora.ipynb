{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import re\r\n",
    "import glob\r\n",
    "import json\r\n",
    "import random\r\n",
    "import argparse\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import librosa\r\n",
    "import librosa.display\r\n",
    "import soundfile as sf\r\n",
    "\r\n",
    "from tqdm import tqdm\r\n",
    "import subprocess\r\n",
    "from functools import partial\r\n",
    "from collections import Counter\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "import MeCab\r\n",
    "import cutlet\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split, KFold\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_io as tfio\r\n",
    "from tensorflow.keras.layers import *\r\n",
    "\r\n",
    "from transformers import (\r\n",
    "    Wav2Vec2CTCTokenizer,\r\n",
    "    TFWav2Vec2ForCTC,\r\n",
    "    Wav2Vec2Processor,\r\n",
    "    Wav2Vec2FeatureExtractor)\r\n",
    "\r\n",
    "def seed_everything(SEED):\r\n",
    "    random.seed(SEED)\r\n",
    "    np.random.seed(SEED)\r\n",
    "    tf.random.set_seed(SEED)\r\n",
    "    print(\"Random seed set.\")\r\n",
    "\r\n",
    "seed_everything(42)\r\n",
    "tf.get_logger().setLevel('FATAL')\r\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random seed set.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Dataset:\r\n",
    "    def __init__(self):\r\n",
    "        self.main_dir = \"E://Datasets/ASR-dataset\"\r\n",
    "        self.sample_rate = 16000\r\n",
    "        self.n_shards = 10\r\n",
    "        self.data = pd.concat([\r\n",
    "            self.get_kokoro(),\r\n",
    "            self.get_jsut(),\r\n",
    "            self.get_commonvoice()\r\n",
    "            ], \r\n",
    "            ignore_index=True)\r\n",
    "        self.katsu = cutlet.Cutlet()\r\n",
    "        self.wakati = MeCab.Tagger(\"-Owakati\")\r\n",
    "    \r\n",
    "        tqdm.pandas()\r\n",
    "        self.data['sentence'] = self.data['sentence'].progress_apply(self.clean_kanji)\r\n",
    "        self.data['romaji'] = self.data['sentence'].progress_apply(self.katsu.romaji)\r\n",
    "        self.data['romaji'] = self.data['romaji'].progress_apply(self.clean_romaji)\r\n",
    "        self.data['romaji'] = self.data['romaji'].str.lower()\r\n",
    "        self.data['length'] = self.data['path'].progress_apply(self.get_length)\r\n",
    "        self.data = self.data[self.data['sentence'].apply(list).apply(len)>=5]\r\n",
    "        self.data.query(\"(length >= 48000) & (length <= 80000)\", inplace=True)\r\n",
    "        self.data = self.data.dropna()\r\n",
    "        self.data = self.data.sample(n=2000, random_state=42, ignore_index=True)\r\n",
    "        self.data.sort_values(by=\"length\", axis=0, ascending=True, inplace=True, ignore_index=True)\r\n",
    "        self.data.to_csv(f\"{self.main_dir}/ASRDataset.csv\", encoding=\"utf-8\", index=False)\r\n",
    "\r\n",
    "    def get_kokoro(self):\r\n",
    "        in_dir = \"Datasets\\KOKORO-dataset\"\r\n",
    "\r\n",
    "        data = []\r\n",
    "        transcript_path = f\"{in_dir}/transcripts/*.metadata.txt\"\r\n",
    "        for transcript in glob.glob(transcript_path):\r\n",
    "            with open(transcript, \"r\", encoding=\"utf-8\") as f:\r\n",
    "                for line in f.readlines():\r\n",
    "                    data.append(line.split(\"|\"))\r\n",
    "\r\n",
    "        data = pd.DataFrame(\r\n",
    "            data, columns=[\r\n",
    "                'text_id', 'path', 'start_idx', \r\n",
    "                'end_idx', 'sentence', 'phonemes'])       \r\n",
    "\r\n",
    "        # paths = data['path'].unique()\r\n",
    "        # for path in tqdm(paths, total=len(paths)):\r\n",
    "        #     folder_name = path.split(\"_\", 1)[0]\r\n",
    "        #     in_path = os.path.join(in_dir, folder_name, path)\r\n",
    "        #     y, sr = librosa.load(in_path, sr=None)\r\n",
    "        #     for text_id in data.loc[data['path']==path, 'text_id']:\r\n",
    "        #         out_path = os.path.join(self.main_dir, 'wav_cleaned', text_id) + \".wav\"\r\n",
    "        #         if not os.path.exists(out_path):\r\n",
    "        #             start_idx = int(data.loc[data['text_id']==text_id, 'start_idx'].item())\r\n",
    "        #             end_idx = int(data.loc[data['text_id']==text_id, 'end_idx'].item())\r\n",
    "        #             y_slice = librosa.resample(\r\n",
    "        #                 y[start_idx:end_idx], orig_sr=sr, target_sr=self.sample_rate)\r\n",
    "        #             sf.write(out_path, y_slice, samplerate=self.sample_rate, subtype='PCM_16')\r\n",
    "\r\n",
    "        data = data[['text_id', 'sentence']]\r\n",
    "        data['text_id'] = data['text_id'].apply(lambda x: x + \".wav\")\r\n",
    "        data.columns = ['path', 'sentence']\r\n",
    "        data['corpus'] = ['kokoro'] * len(data)\r\n",
    "        return data\r\n",
    "\r\n",
    "    def get_jsut(self):\r\n",
    "        filenames, sentences = [], []\r\n",
    "        for transcript in glob.glob(r\"Datasets/JSUT-dataset/*/transcript_utf8.txt\"):\r\n",
    "            file_path = transcript.rsplit(\"\\\\\", 1)[0]\r\n",
    "            with open(transcript, \"r\", encoding=\"utf-8\") as f:\r\n",
    "                lines = f.readlines()\r\n",
    "                for line in lines: \r\n",
    "                    filename, sentence = line.split(\":\")\r\n",
    "                    filenames.append(os.path.join(file_path, \"wav\", filename) + \".wav\")\r\n",
    "                    sentences.append(sentence.strip(\"\\n\"))\r\n",
    "        data = pd.DataFrame({'path': filenames, 'sentence': sentences}) \r\n",
    "        data['corpus'] = ['jsut'] * len(data)\r\n",
    "        for i, in_path in tqdm(enumerate(data['path']), total=len(data['path'])):\r\n",
    "            in_path = in_path.replace(\"\\\\\", \"/\")\r\n",
    "            out_path = f\"{self.main_dir}\\wav_cleaned\"\r\n",
    "            filename = in_path.rsplit(\"/\", 1)[-1]\r\n",
    "            out_path = os.path.join(out_path, filename)\r\n",
    "            if not os.path.exists(out_path):\r\n",
    "                subprocess.call([\r\n",
    "                    \"ffmpeg\", \"-i\", in_path,\"-acodec\", \"pcm_s16le\", \r\n",
    "                    \"-ar\", str(self.sample_rate), out_path])\r\n",
    "            data['path'][i] = filename\r\n",
    "        return data\r\n",
    "\r\n",
    "    def get_commonvoice(self):\r\n",
    "        data = pd.read_csv(r\"Datasets/CommonVoice-dataset/validated.tsv\", sep=\"\\t\")\r\n",
    "        data = data[['path', 'sentence']]    \r\n",
    "        data['path'] = data['path'].apply(\r\n",
    "            lambda x: r\"Datasets/CommonVoice-dataset/mp3/\" + x)\r\n",
    "        data['corpus'] = ['common_voice'] * len(data)\r\n",
    "        for i, in_path in tqdm(enumerate(data['path']), total=len(data['path'])):\r\n",
    "            in_path = in_path.replace(\"\\\\\", \"/\")\r\n",
    "            out_path = f\"{self.main_dir}\\wav_cleaned\"\r\n",
    "            filename = in_path.rsplit(\"/\", 1)[-1]\r\n",
    "            filename = filename.replace(\"mp3\", \"wav\")\r\n",
    "            out_path = os.path.join(out_path, filename)\r\n",
    "            if not os.path.exists(out_path):\r\n",
    "                subprocess.call([\r\n",
    "                    \"ffmpeg\", \"-i\", in_path,\"-acodec\", \"pcm_s16le\", \r\n",
    "                    \"-ar\", str(self.sample_rate), out_path])\r\n",
    "            data['path'][i] = filename\r\n",
    "        return data\r\n",
    "\r\n",
    "    def clean_kanji(self, sentence):\r\n",
    "        symbols = r\"[（.*?）！-～.,;..._。、-〿・■（）：ㇰ-ㇿ㈠-㉃㊀-㋾㌀-㍿「」『』→ー -~‘–※π—ゐ’“”]\"\r\n",
    "        sentence = re.sub(symbols, \"\", sentence)\r\n",
    "        sentence = self.wakati.parse(sentence).strip(\"\\n\")          \r\n",
    "        return sentence\r\n",
    "\r\n",
    "    def clean_romaji(self, sentence):\r\n",
    "        return re.sub(r'[.,\"\\'\\/?]', \"\", sentence)\r\n",
    "\r\n",
    "    def get_length(self, path):\r\n",
    "        path = os.path.join(self.main_dir, 'wav_cleaned', path)\r\n",
    "        y, sr = librosa.load(path, sr=None)\r\n",
    "        return len(y)\r\n",
    "\r\n",
    "# data = Dataset().data\r\n",
    "# data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# fig, ax = plt.subplots(1,1,figsize=(10, 4))\r\n",
    "# sns.histplot(x=data['length'], hue=data['corpus'], ax=ax, palette=\"bright\")\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Arguments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def ArgParser():\r\n",
    "    parser = argparse.ArgumentParser()\r\n",
    "\r\n",
    "    # DataLoader\r\n",
    "    parser.add_argument(\"--main_dir\", default=\"E://Datasets/ASR-dataset\")\r\n",
    "    parser.add_argument(\"--sample_rate\", default=16000)\r\n",
    "    parser.add_argument(\"--test_size\", default=0.1)\r\n",
    "    parser.add_argument(\"--random_state\", default=42)\r\n",
    "    parser.add_argument(\"--batch_size\", default=4)\r\n",
    "    parser.add_argument(\"--n_shards\", default=10)\r\n",
    "    parser.add_argument(\"--buffer_size\", default=512)\r\n",
    "\r\n",
    "    # Trainer\r\n",
    "    parser.add_argument(\"--model_name\", default=\"facebook/wav2vec2-base\")\r\n",
    "    parser.add_argument(\"--epochs\", default=20)\r\n",
    "    parser.add_argument(\"--learning_rate\", default=5e-5)\r\n",
    "    parser.add_argument(\"--beam_width\", default=10)\r\n",
    "    parser.add_argument(\"--top_paths\", default=1)\r\n",
    "\r\n",
    "    # Scheduler\r\n",
    "    # parser.add_argument(\"--lr_start\", default=1e-3)\r\n",
    "    # parser.add_argument(\"--lr_min\", default=1e-3)\r\n",
    "    # parser.add_argument(\"--lr_max\", default=1e-3)\r\n",
    "    # parser.add_argument(\"--n_cycles\", default=0.5)\r\n",
    "    # parser.add_argument(\"--warmup_epochs\", default=4)\r\n",
    "    # parser.add_argument(\"--sustain_epochs\", default=0)    \r\n",
    "\r\n",
    "    args = parser.parse_known_args()[0]\r\n",
    "\r\n",
    "    with open(f\"{args.main_dir}/vocab.json\", \"r\") as f:\r\n",
    "        vocab_size = len(json.load(f))\r\n",
    "    \r\n",
    "    n_samples = len(pd.read_csv(os.path.join(args.main_dir, \"ASRDataset.csv\")))\r\n",
    "    n_train = int(n_samples * (1 - args.test_size))\r\n",
    "    n_val = int(n_samples * args.test_size)\r\n",
    "    train_steps = int(np.ceil(n_train / args.batch_size))\r\n",
    "\r\n",
    "    parser.add_argument(\"--vocab_size\", default=vocab_size)\r\n",
    "    parser.add_argument(\"--n_samples\", default=n_samples)\r\n",
    "    parser.add_argument(\"--n_train\", default=n_train)\r\n",
    "    parser.add_argument(\"--n_val\", default=n_val)\r\n",
    "    parser.add_argument(\"--train_steps\", default=train_steps)  \r\n",
    "\r\n",
    "    return parser.parse_known_args()[0]\r\n",
    "\r\n",
    "args = ArgParser()\r\n",
    "args"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Namespace(batch_size=4, beam_width=10, buffer_size=512, epochs=20, learning_rate=5e-05, main_dir='E://Datasets/ASR-dataset', model_name='facebook/wav2vec2-base', n_samples=2000, n_shards=10, n_train=1800, n_val=200, random_state=42, sample_rate=16000, test_size=0.1, top_paths=1, train_steps=450, vocab_size=37)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Config:\r\n",
    "    def __init__(self, args):\r\n",
    "        tokenizer = Wav2Vec2CTCTokenizer(\r\n",
    "            vocab_file=f\"{args.main_dir}/vocab.json\",\r\n",
    "            unk_token=\"<unk>\",\r\n",
    "            pad_token=\"<pad>\",\r\n",
    "            word_delimiter_token=\"|\",\r\n",
    "            do_lower_case=False\r\n",
    "        )\r\n",
    "\r\n",
    "        feature_extractor = Wav2Vec2FeatureExtractor(\r\n",
    "            feature_size=1,\r\n",
    "            sampling_rate=args.sample_rate,\r\n",
    "            padding_value=0.0,\r\n",
    "            do_normalize=True,\r\n",
    "            return_attention_mask=False\r\n",
    "        )\r\n",
    "\r\n",
    "        self.processor = Wav2Vec2Processor(\r\n",
    "            feature_extractor=feature_extractor, \r\n",
    "            tokenizer=tokenizer\r\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class TFRWriter():\r\n",
    "    def __init__(self, args):\r\n",
    "        self.data = pd.read_csv(os.path.join(args.main_dir, \"ASRDataset.csv\"))\r\n",
    "        self.args = args\r\n",
    "        self.tokenizer = Config(args).processor.tokenizer\r\n",
    "\r\n",
    "    def _bytes_feature(self, value):\r\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n",
    "        if isinstance(value, type(tf.constant(0))):\r\n",
    "            value = value.numpy()\r\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n",
    "\r\n",
    "    def _int64_feature(self, value):\r\n",
    "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\r\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n",
    "\r\n",
    "    def _float_feature(self, value):\r\n",
    "        \"\"\"Returns a float_list from a float / double.\"\"\"\r\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\r\n",
    "\r\n",
    "    def serialize_example(self, *args):\r\n",
    "        feature = {\r\n",
    "            'input_values': self._bytes_feature(args[0]),\r\n",
    "            'labels': self._bytes_feature(args[1]),\r\n",
    "            }\r\n",
    "\r\n",
    "        example_proto = tf.train.Example(\r\n",
    "            features=tf.train.Features(feature=feature))\r\n",
    "        return example_proto.SerializeToString()\r\n",
    "\r\n",
    "    def get_labels(self, sample):\r\n",
    "        labels = self.data.loc[self.data['path']==sample, \"romaji\"].item()\r\n",
    "        labels = (self.tokenizer.bos_token + labels + \r\n",
    "            self.tokenizer.eos_token)\r\n",
    "        labels = self.tokenizer(labels)['input_ids']\r\n",
    "        return tf.convert_to_tensor(labels, dtype=tf.int32)\r\n",
    "\r\n",
    "    def get_audio(self, sample):\r\n",
    "        path = os.path.join(self.args.main_dir, \"wav_cleaned\", sample)\r\n",
    "        audio = librosa.load(path, sr=None)[0]\r\n",
    "        return tf.convert_to_tensor(audio, dtype=tf.float32)\r\n",
    "\r\n",
    "    def get_shards(self):\r\n",
    "        skf = KFold(n_splits=self.args.n_shards, shuffle=False)\r\n",
    "        return [\r\n",
    "            list(map(lambda x: self.data['path'][x], j))\r\n",
    "            for i, j in skf.split(self.data['path'])]\r\n",
    "\r\n",
    "    def get_shard_data(self, samples):\r\n",
    "        for sample in samples:\r\n",
    "            audio = self.get_audio(sample)\r\n",
    "            labels = self.get_labels(sample)\r\n",
    "            yield {\r\n",
    "                'input_values': tf.io.serialize_tensor(audio),\r\n",
    "                'labels': tf.io.serialize_tensor(labels),\r\n",
    "            }\r\n",
    "\r\n",
    "    def write(self):\r\n",
    "        for shard, samples in tqdm(enumerate(self.get_shards()), total=self.args.n_shards):\r\n",
    "            with tf.io.TFRecordWriter(f\"{self.args.main_dir}/wav2vec2_tfrec/shard_{shard+1}.tfrec\") as f:\r\n",
    "                for sample in self.get_shard_data(samples):\r\n",
    "                    example = self.serialize_example(\r\n",
    "                        sample['input_values'], \r\n",
    "                        sample['labels'], \r\n",
    "                        )\r\n",
    "                    f.write(example)\r\n",
    "\r\n",
    "# TFRWriter(args).write()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class DataLoader:\r\n",
    "    def __init__(self, args):\r\n",
    "        self.files = glob.glob(args.main_dir + \"/wav2vec2_tfrec/*.tfrec\")\r\n",
    "        self.args = args\r\n",
    "        self.AUTOTUNE = tf.data.AUTOTUNE\r\n",
    "        self.train_files, self.val_files = train_test_split(\r\n",
    "            self.files, test_size=args.test_size, shuffle=True, \r\n",
    "            random_state=args.random_state)\r\n",
    "        self.train = self.get_train()\r\n",
    "        self.val = self.get_val()     \r\n",
    "\r\n",
    "    def read_tfrecord(self, example):\r\n",
    "        feature_description = {\r\n",
    "            'input_values': tf.io.FixedLenFeature([], tf.string),\r\n",
    "            'labels': tf.io.FixedLenFeature([], tf.string),\r\n",
    "            }\r\n",
    "        \r\n",
    "        example = tf.io.parse_single_example(example, feature_description)\r\n",
    "        example['input_values'] = tf.io.parse_tensor(\r\n",
    "            example['input_values'], out_type=tf.float32)\r\n",
    "        example['labels'] = tf.io.parse_tensor(\r\n",
    "            example['labels'], out_type=tf.int32)\r\n",
    "        return example\r\n",
    "\r\n",
    "    def load_dataset(self, files):\r\n",
    "        ignore_order = tf.data.Options()\r\n",
    "        ignore_order.experimental_deterministic = False\r\n",
    "        dataset = tf.data.TFRecordDataset(files)\r\n",
    "        dataset = dataset.with_options(ignore_order)\r\n",
    "        dataset = dataset.map(self.read_tfrecord, num_parallel_calls=self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "\r\n",
    "    def get_train(self):\r\n",
    "        dataset = self.load_dataset(self.train_files)\r\n",
    "        dataset = dataset.padded_batch(\r\n",
    "            self.args.batch_size,\r\n",
    "            padded_shapes={\r\n",
    "                'input_values': [None],\r\n",
    "                'labels': [None]\r\n",
    "            },\r\n",
    "            padding_values={\r\n",
    "                'input_values': tf.constant(0, dtype=tf.float32), \r\n",
    "                'labels': tf.constant(-100, dtype=tf.int32)\r\n",
    "            })\r\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "\r\n",
    "    def get_val(self):\r\n",
    "        dataset = self.load_dataset(self.val_files)\r\n",
    "        dataset = dataset.padded_batch(\r\n",
    "            self.args.batch_size,\r\n",
    "            padded_shapes={\r\n",
    "                'input_values': [None],\r\n",
    "                'labels': [None]\r\n",
    "            },\r\n",
    "            padding_values={\r\n",
    "                'input_values': tf.constant(0, dtype=tf.float32), \r\n",
    "                'labels': tf.constant(-100, dtype=tf.int32)\r\n",
    "            })\r\n",
    "        dataset = dataset.cache()\r\n",
    "        dataset = dataset.prefetch(self.AUTOTUNE)\r\n",
    "        return dataset\r\n",
    "\r\n",
    "train = DataLoader(args).train\r\n",
    "next(iter(train))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_values': <tf.Tensor: shape=(4, 76719), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  3.0517578e-05,  0.0000000e+00, ...,\n",
       "         -3.0517578e-05, -6.1035156e-05,  0.0000000e+00],\n",
       "        [ 2.4414062e-04,  2.4414062e-04,  0.0000000e+00, ...,\n",
       "          0.0000000e+00, -3.0517578e-05,  0.0000000e+00]], dtype=float32)>,\n",
       " 'labels': <tf.Tensor: shape=(4, 73), dtype=int32, numpy=\n",
       " array([[   1,   27,    6,   15,    8,   12,    6,    4,    9,    6,   14,\n",
       "            7,    9,    5,    3,    4,   17,   10,    4,   19,    5,    4,\n",
       "            6,   11,   11,    8,   15,    8,   28,    6,   17,    6,    4,\n",
       "           17,    5,    7,   18,    5,   11,    8,    4,   19,    5,   23,\n",
       "            8,    8,   24,    6,    8,    4,    6,   11,    8,    4,   15,\n",
       "            6,    9,    4,   12,    6,   30,    5,   11,    8,   15,    5,\n",
       "           13,   10,   14,    5,   15,    8,    2],\n",
       "        [   1,    3,    8,   12,    3,   10,   12,    4,    9,    6,    4,\n",
       "            9,    7,   11,    8,    4,   18,    5,    4,   21,    8,    5,\n",
       "           23,    8,   11,    8,   12,   10,    4,   11,    6,   13,    6,\n",
       "           14,    6,    4,   19,    5,    4,    8,   15,    8,   11,    8,\n",
       "           12,   10,    4,   15,    5,   11,    8,   15,    5,   11,    8,\n",
       "            2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100],\n",
       "        [   1,   17,    6,    8,    4,   14,    6,    4,    6,   14,    5,\n",
       "           10,    4,   19,    5,    4,   14,    8,   20,    5,   14,    7,\n",
       "            4,    9,    7,   16,    7,    9,   27,    5,    7,   15,   10,\n",
       "            7,    4,   17,   10,    4,    7,   11,   10,    9,    5,    7,\n",
       "           16,    7,    9,   27,    5,    7,    4,   14,    6,   16,    7,\n",
       "           14,    5,   15,    8,    4,   19,    5,    2, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100],\n",
       "        [   1,   12,    5,   23,    8,    4,    7,    7,   19,    5,   11,\n",
       "           10,    4,   19,    6,   23,    8,   11,    8,   13,    8,    4,\n",
       "            9,    7,    4,   19,    5,    4,   12,   10,    5,   12,   10,\n",
       "            4,   14,    6,   16,    7,    9,    5,   11,   10,   13,   10,\n",
       "           21,    5,    4,    9,    5,   13,    5,    9,    4,    7,   14,\n",
       "            5,    4,    9,    6,   32,    5,   11,    8,    4,   10,    9,\n",
       "            4,   19,    5,    2, -100, -100, -100]])>}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class PER(tf.keras.metrics.Metric):\r\n",
    "    \"\"\"Phone Error Rate\r\n",
    "\r\n",
    "    This metric calculates the normalized error rate based on phonemes.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        beam_width: (Optional)\r\n",
    "        top_paths: (Optional)\r\n",
    "        name: (Optional) string name of the metric instance\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, beam_width=100, top_paths=1, name=\"PER\", **kwargs):\r\n",
    "        super(PER, self).__init__(name=name,  **kwargs)\r\n",
    "        self.beam_width = beam_width\r\n",
    "        self.top_paths = top_paths\r\n",
    "        self.per_accumulator = self.add_weight(name=\"total_per\", initializer=\"zeros\")\r\n",
    "        self.counter = self.add_weight(name=\"per_count\", initializer=\"zeros\")\r\n",
    "\r\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\r\n",
    "        \"\"\"\r\n",
    "        Function takes in model output logits and target labels and updates\r\n",
    "        accumulator globally.\r\n",
    "\r\n",
    "        Args: \r\n",
    "            y_true shape: [batch_size, sequence_length]\r\n",
    "            y_pred shape: [batch_size, sequence_length, num_features]\r\n",
    "\r\n",
    "        Returns:\r\n",
    "            None\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        batch_size, sequence_length, num_features = tf.shape(y_pred)\r\n",
    "        y_pred = tf.reshape(y_pred, [sequence_length, batch_size, num_features])\r\n",
    "        sequence_length = tf.repeat(sequence_length, batch_size)\r\n",
    "\r\n",
    "        # Decode logits into sparse tensor using beam search decoder\r\n",
    "        hypothesis = tf.nn.ctc_beam_search_decoder(\r\n",
    "            y_pred, sequence_length=sequence_length, beam_width=self.beam_width,\r\n",
    "            top_paths=self.top_paths)[0][0]\r\n",
    "        hypothesis = tf.cast(hypothesis, dtype=tf.int32)\r\n",
    "\r\n",
    "        # Convert dense to sparse tensor for edit_distance function\r\n",
    "        truth = tf.sparse.from_dense(y_true)\r\n",
    "        \r\n",
    "        # Calculate Levenshtein distance\r\n",
    "        distance = tf.edit_distance(hypothesis, truth, normalize=True)\r\n",
    "        self.per_accumulator.assign_add(tf.reduce_mean(distance))\r\n",
    "        self.counter.assign_add(len(y_true))\r\n",
    "\r\n",
    "    def result(self):\r\n",
    "        return tf.math.divide_no_nan(self.per_accumulator, self.counter)\r\n",
    "    \r\n",
    "    def reset_states(self):\r\n",
    "        self.per_accumulator.assign(0.0)\r\n",
    "        self.counter.assign(0.0)\r\n",
    "\r\n",
    "class CosineDecaySchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n",
    "    def __init__(self, args):\r\n",
    "        self.args = args\r\n",
    "\r\n",
    "    def __call__(self, epoch):  \r\n",
    "        if epoch < self.args.warmup_epochs:\r\n",
    "            lr = ((self.args.lr_max - self.args.lr_start) / self.args.warmup_epochs) * epoch + self.args.lr_start\r\n",
    "        elif epoch < (self.args.warmup_epochs + self.args.sustain_epochs):\r\n",
    "            lr = self.args.lr_max\r\n",
    "        else:\r\n",
    "            progress = ((epoch - self.args.warmup_epochs - self.args.sustain_epochs) / \r\n",
    "            (self.args.epochs - self.args.warmup_epochs - self.args.sustain_epochs))\r\n",
    "            lr = (self.args.lr_max-self.args.lr_min) * (0.5 * (1.0 + tf.math.cos((22/7) * \r\n",
    "                self.args.n_cycles * 2.0 * progress)))\r\n",
    "            if self.args.lr_min is not None:\r\n",
    "                lr = tf.math.maximum(self.args.lr_min, lr)\r\n",
    "        return lr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class Trainer:\r\n",
    "    def __init__(self, args):\r\n",
    "        self.args = args\r\n",
    "        self.config = Config(args)\r\n",
    "        self.train_dataset = DataLoader(args).train\r\n",
    "        self.val_dataset = DataLoader(args).val\r\n",
    "        self.optimizer = tf.keras.optimizers.Adam(self.args.learning_rate)\r\n",
    "        self.metrics = PER(beam_width=args.beam_width, top_paths=args.top_paths)\r\n",
    "        self.model = TFWav2Vec2ForCTC.from_pretrained(\r\n",
    "            args.model_name,\r\n",
    "            from_pt=True,\r\n",
    "            ctc_loss_reduction=\"mean\",\r\n",
    "            pad_token_id=self.config.processor.tokenizer.pad_token_id,\r\n",
    "            vocab_size=len(self.config.processor.tokenizer))\r\n",
    "        self.model.freeze_feature_extractor()\r\n",
    "    \r\n",
    "    def train_step(self, batch):\r\n",
    "        X_train = batch['input_values']\r\n",
    "        y_train = batch['labels']\r\n",
    "        with tf.GradientTape() as tape:\r\n",
    "            loss, logits = self.model(\r\n",
    "                input_values=X_train, labels=y_train, training=True)[:2]\r\n",
    "        gradients = tape.gradient(loss, self.model.trainable_weights)\r\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_weights))\r\n",
    "        self.metrics.update_state(y_train, logits)\r\n",
    "        return loss\r\n",
    "\r\n",
    "    def val_step(self, batch):\r\n",
    "        X_val = batch['input_values']\r\n",
    "        y_val = batch['labels']\r\n",
    "        loss, logits = self.model(\r\n",
    "            input_values=X_val, labels=y_val, training=False)[:2]\r\n",
    "        self.metrics.update_state(y_val, logits)\r\n",
    "        return loss\r\n",
    "\r\n",
    "    def fit(self):\r\n",
    "        for epoch in range(self.args.epochs):\r\n",
    "            print(f\"Epoch {epoch+1}/{self.args.epochs}\")\r\n",
    "            stateful_metrics = [\"loss\", \"per\", \"val_loss\", \"val_per\"]\r\n",
    "            progbar = tf.keras.utils.Progbar(\r\n",
    "                self.args.train_steps, interval=0.05,\r\n",
    "                stateful_metrics=stateful_metrics\r\n",
    "            )\r\n",
    "            for step, t_batch in enumerate(self.train_dataset):\r\n",
    "                t_loss = self.train_step(t_batch)\r\n",
    "                t_per = self.metrics.result()\r\n",
    "                t_values = [(\"loss\", t_loss), (\"per\", t_per)]\r\n",
    "                progbar.update(step, values=t_values, finalize=False)\r\n",
    "                self.metrics.reset_states()\r\n",
    "            \r\n",
    "            for v_batch in self.val_dataset:\r\n",
    "                v_loss = self.val_step(v_batch)\r\n",
    "\r\n",
    "            v_per = self.metrics.result()\r\n",
    "            v_values = [\r\n",
    "                (\"loss\", t_loss), (\"per\", t_per), (\"val_loss\", v_loss),\r\n",
    "                (\"val_per\", v_per)]\r\n",
    "            progbar.update(self.args.train_steps, values=v_values, finalize=True)\r\n",
    "            self.metrics.reset_states()\r\n",
    "\r\n",
    "Trainer(args).fit()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFWav2Vec2ForCTC: ['quantizer.codevectors', 'project_hid.bias', 'project_q.bias', 'project_q.weight', 'quantizer.weight_proj.bias', 'quantizer.weight_proj.weight', 'project_hid.weight']\n",
      "- This IS expected if you are initializing TFWav2Vec2ForCTC from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFWav2Vec2ForCTC from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFWav2Vec2ForCTC were not initialized from the PyTorch model and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "  3/450 [..............................] - ETA: 17:04 - loss: 383.3486 - per: 0.2438"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('tf-gpu': conda)"
  },
  "interpreter": {
   "hash": "b851d2923cfa3a2562599062e05fd9893d86a7c009c64d8ad3756552e4dd5f41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}